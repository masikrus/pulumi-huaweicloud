# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities

__all__ = [
    'Cluster2AddJobArgs',
    'Cluster2AddJobArgsDict',
    'Cluster2ComponentListArgs',
    'Cluster2ComponentListArgsDict',
    'ClusterV1AddJobArgs',
    'ClusterV1AddJobArgsDict',
    'ClusterV1ComponentListArgs',
    'ClusterV1ComponentListArgsDict',
    'DataConnectionSourceInfoArgs',
    'DataConnectionSourceInfoArgsDict',
    'ScalingPolicyExecScriptArgs',
    'ScalingPolicyExecScriptArgsDict',
    'ScalingPolicyResourcesPlanArgs',
    'ScalingPolicyResourcesPlanArgsDict',
    'ScalingPolicyRuleArgs',
    'ScalingPolicyRuleArgsDict',
    'ScalingPolicyRuleTriggerArgs',
    'ScalingPolicyRuleTriggerArgsDict',
    'ClusterAnalysisCoreNodesArgs',
    'ClusterAnalysisCoreNodesArgsDict',
    'ClusterAnalysisTaskNodesArgs',
    'ClusterAnalysisTaskNodesArgsDict',
    'ClusterBootstrapScriptArgs',
    'ClusterBootstrapScriptArgsDict',
    'ClusterComponentConfigArgs',
    'ClusterComponentConfigArgsDict',
    'ClusterComponentConfigConfigArgs',
    'ClusterComponentConfigConfigArgsDict',
    'ClusterCustomNodeArgs',
    'ClusterCustomNodeArgsDict',
    'ClusterExternalDatasourceArgs',
    'ClusterExternalDatasourceArgsDict',
    'ClusterMasterNodesArgs',
    'ClusterMasterNodesArgsDict',
    'ClusterSmnNotifyArgs',
    'ClusterSmnNotifyArgsDict',
    'ClusterStreamingCoreNodesArgs',
    'ClusterStreamingCoreNodesArgsDict',
    'ClusterStreamingTaskNodesArgs',
    'ClusterStreamingTaskNodesArgsDict',
]

MYPY = False

if not MYPY:
    class Cluster2AddJobArgsDict(TypedDict):
        jar_path: pulumi.Input[_builtins.str]
        """
        Path of the **.jar** file or **.sql** file for program execution.  
        The parameter must meet the following requirements:
        + Contains a maximum of 1,023 characters, excluding special characters such as ;|&><'$. The parameter value cannot
        be empty or full of spaces.
        + Files can be stored in HDFS or OBS. The path varies depending on the file system. OBS: The path must start with
        s3a://. Files or programs encrypted by KMS are not supported. HDFS: The path starts with a slash (/).
        + Spark Script must end with .sql while MapReduce and Spark Jar must end with .jar. sql and jar are
        case-insensitive.
        """
        job_name: pulumi.Input[_builtins.str]
        """
        Job name. It contains `1` to `64` characters. Only letters, digits, hyphens (-),
        and underscores (_) are allowed. NOTE: Identical job names are allowed but not recommended.
        """
        job_type: pulumi.Input[_builtins.int]
        """
        Job type code.  
        + **1**: MapReduce
        + **2**: Spark
        + **3**: Hive Script
        + **4**: HiveQL (not supported currently)
        + **5**: DistCp, importing and exporting data (not supported currently)
        + **6**: Spark Script
        + **7**: Spark SQL, submitting Spark SQL statements (not supported currently)

        > NOTE: Spark and Hive jobs can be added to only clusters including Spark and Hive components.
        """
        submit_job_once_cluster_run: pulumi.Input[_builtins.bool]
        """
        Whether the job is submitted during the cluster creation or
        after the cluster is created.
        """
        arguments: NotRequired[pulumi.Input[_builtins.str]]
        """
        Key parameter for program execution. The parameter is specified by the
        function of the user's program. MRS is only responsible for loading the parameter. The parameter contains a maximum of
        `2,047` characters, excluding special characters such as `;|&>'<$`, and can be empty.
        """
        file_action: NotRequired[pulumi.Input[_builtins.str]]
        """
        Data import and export. Valid values include: import, export.
        """
        hive_script_path: NotRequired[pulumi.Input[_builtins.str]]
        """
        SQL program path This parameter is needed by Spark Script and Hive
        Script jobs only and must meet the following requirements:
        Contains a maximum of 1023 characters, excluding special characters such as `;|&><'$`. The address cannot be empty or
        full of spaces. Starts with / or s3a://. Ends with .sql. sql is case-insensitive.
        """
        hql: NotRequired[pulumi.Input[_builtins.str]]
        """
        HiveQL statement.
        """
        input: NotRequired[pulumi.Input[_builtins.str]]
        """
        Path for inputting data, which must start with / or s3a://. A correct OBS path
        is required. The parameter contains a maximum of 1023 characters, excluding special characters such as `;|&>'<$`, and
        can be empty.
        """
        job_log: NotRequired[pulumi.Input[_builtins.str]]
        """
        Path for storing job logs that record job running status. This path must
        start with / or s3a://. A correct OBS path is required. The parameter contains a maximum of 1023 characters, excluding
        special characters such as `;|&>'<$`, and can be empty.
        """
        output: NotRequired[pulumi.Input[_builtins.str]]
        """
        Path for outputting data, which must start with / or s3a://. A correct OBS
        path is required. If the path does not exist, the system automatically creates it. The parameter contains a maximum of
        1023 characters, excluding special characters such as `;|&>'<$`, and can be empty.
        """
        shutdown_cluster: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Whether to delete the cluster after the jobs are complete.
        """
elif False:
    Cluster2AddJobArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class Cluster2AddJobArgs:
    def __init__(__self__, *,
                 jar_path: pulumi.Input[_builtins.str],
                 job_name: pulumi.Input[_builtins.str],
                 job_type: pulumi.Input[_builtins.int],
                 submit_job_once_cluster_run: pulumi.Input[_builtins.bool],
                 arguments: Optional[pulumi.Input[_builtins.str]] = None,
                 file_action: Optional[pulumi.Input[_builtins.str]] = None,
                 hive_script_path: Optional[pulumi.Input[_builtins.str]] = None,
                 hql: Optional[pulumi.Input[_builtins.str]] = None,
                 input: Optional[pulumi.Input[_builtins.str]] = None,
                 job_log: Optional[pulumi.Input[_builtins.str]] = None,
                 output: Optional[pulumi.Input[_builtins.str]] = None,
                 shutdown_cluster: Optional[pulumi.Input[_builtins.bool]] = None):
        """
        :param pulumi.Input[_builtins.str] jar_path: Path of the **.jar** file or **.sql** file for program execution.  
               The parameter must meet the following requirements:
               + Contains a maximum of 1,023 characters, excluding special characters such as ;|&><'$. The parameter value cannot
               be empty or full of spaces.
               + Files can be stored in HDFS or OBS. The path varies depending on the file system. OBS: The path must start with
               s3a://. Files or programs encrypted by KMS are not supported. HDFS: The path starts with a slash (/).
               + Spark Script must end with .sql while MapReduce and Spark Jar must end with .jar. sql and jar are
               case-insensitive.
        :param pulumi.Input[_builtins.str] job_name: Job name. It contains `1` to `64` characters. Only letters, digits, hyphens (-),
               and underscores (_) are allowed. NOTE: Identical job names are allowed but not recommended.
        :param pulumi.Input[_builtins.int] job_type: Job type code.  
               + **1**: MapReduce
               + **2**: Spark
               + **3**: Hive Script
               + **4**: HiveQL (not supported currently)
               + **5**: DistCp, importing and exporting data (not supported currently)
               + **6**: Spark Script
               + **7**: Spark SQL, submitting Spark SQL statements (not supported currently)
               
               > NOTE: Spark and Hive jobs can be added to only clusters including Spark and Hive components.
        :param pulumi.Input[_builtins.bool] submit_job_once_cluster_run: Whether the job is submitted during the cluster creation or
               after the cluster is created.
        :param pulumi.Input[_builtins.str] arguments: Key parameter for program execution. The parameter is specified by the
               function of the user's program. MRS is only responsible for loading the parameter. The parameter contains a maximum of
               `2,047` characters, excluding special characters such as `;|&>'<$`, and can be empty.
        :param pulumi.Input[_builtins.str] file_action: Data import and export. Valid values include: import, export.
        :param pulumi.Input[_builtins.str] hive_script_path: SQL program path This parameter is needed by Spark Script and Hive
               Script jobs only and must meet the following requirements:
               Contains a maximum of 1023 characters, excluding special characters such as `;|&><'$`. The address cannot be empty or
               full of spaces. Starts with / or s3a://. Ends with .sql. sql is case-insensitive.
        :param pulumi.Input[_builtins.str] hql: HiveQL statement.
        :param pulumi.Input[_builtins.str] input: Path for inputting data, which must start with / or s3a://. A correct OBS path
               is required. The parameter contains a maximum of 1023 characters, excluding special characters such as `;|&>'<$`, and
               can be empty.
        :param pulumi.Input[_builtins.str] job_log: Path for storing job logs that record job running status. This path must
               start with / or s3a://. A correct OBS path is required. The parameter contains a maximum of 1023 characters, excluding
               special characters such as `;|&>'<$`, and can be empty.
        :param pulumi.Input[_builtins.str] output: Path for outputting data, which must start with / or s3a://. A correct OBS
               path is required. If the path does not exist, the system automatically creates it. The parameter contains a maximum of
               1023 characters, excluding special characters such as `;|&>'<$`, and can be empty.
        :param pulumi.Input[_builtins.bool] shutdown_cluster: Whether to delete the cluster after the jobs are complete.
        """
        pulumi.set(__self__, "jar_path", jar_path)
        pulumi.set(__self__, "job_name", job_name)
        pulumi.set(__self__, "job_type", job_type)
        pulumi.set(__self__, "submit_job_once_cluster_run", submit_job_once_cluster_run)
        if arguments is not None:
            pulumi.set(__self__, "arguments", arguments)
        if file_action is not None:
            pulumi.set(__self__, "file_action", file_action)
        if hive_script_path is not None:
            pulumi.set(__self__, "hive_script_path", hive_script_path)
        if hql is not None:
            pulumi.set(__self__, "hql", hql)
        if input is not None:
            pulumi.set(__self__, "input", input)
        if job_log is not None:
            pulumi.set(__self__, "job_log", job_log)
        if output is not None:
            pulumi.set(__self__, "output", output)
        if shutdown_cluster is not None:
            pulumi.set(__self__, "shutdown_cluster", shutdown_cluster)

    @_builtins.property
    @pulumi.getter(name="jarPath")
    def jar_path(self) -> pulumi.Input[_builtins.str]:
        """
        Path of the **.jar** file or **.sql** file for program execution.  
        The parameter must meet the following requirements:
        + Contains a maximum of 1,023 characters, excluding special characters such as ;|&><'$. The parameter value cannot
        be empty or full of spaces.
        + Files can be stored in HDFS or OBS. The path varies depending on the file system. OBS: The path must start with
        s3a://. Files or programs encrypted by KMS are not supported. HDFS: The path starts with a slash (/).
        + Spark Script must end with .sql while MapReduce and Spark Jar must end with .jar. sql and jar are
        case-insensitive.
        """
        return pulumi.get(self, "jar_path")

    @jar_path.setter
    def jar_path(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "jar_path", value)

    @_builtins.property
    @pulumi.getter(name="jobName")
    def job_name(self) -> pulumi.Input[_builtins.str]:
        """
        Job name. It contains `1` to `64` characters. Only letters, digits, hyphens (-),
        and underscores (_) are allowed. NOTE: Identical job names are allowed but not recommended.
        """
        return pulumi.get(self, "job_name")

    @job_name.setter
    def job_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "job_name", value)

    @_builtins.property
    @pulumi.getter(name="jobType")
    def job_type(self) -> pulumi.Input[_builtins.int]:
        """
        Job type code.  
        + **1**: MapReduce
        + **2**: Spark
        + **3**: Hive Script
        + **4**: HiveQL (not supported currently)
        + **5**: DistCp, importing and exporting data (not supported currently)
        + **6**: Spark Script
        + **7**: Spark SQL, submitting Spark SQL statements (not supported currently)

        > NOTE: Spark and Hive jobs can be added to only clusters including Spark and Hive components.
        """
        return pulumi.get(self, "job_type")

    @job_type.setter
    def job_type(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "job_type", value)

    @_builtins.property
    @pulumi.getter(name="submitJobOnceClusterRun")
    def submit_job_once_cluster_run(self) -> pulumi.Input[_builtins.bool]:
        """
        Whether the job is submitted during the cluster creation or
        after the cluster is created.
        """
        return pulumi.get(self, "submit_job_once_cluster_run")

    @submit_job_once_cluster_run.setter
    def submit_job_once_cluster_run(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "submit_job_once_cluster_run", value)

    @_builtins.property
    @pulumi.getter
    def arguments(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Key parameter for program execution. The parameter is specified by the
        function of the user's program. MRS is only responsible for loading the parameter. The parameter contains a maximum of
        `2,047` characters, excluding special characters such as `;|&>'<$`, and can be empty.
        """
        return pulumi.get(self, "arguments")

    @arguments.setter
    def arguments(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "arguments", value)

    @_builtins.property
    @pulumi.getter(name="fileAction")
    def file_action(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Data import and export. Valid values include: import, export.
        """
        return pulumi.get(self, "file_action")

    @file_action.setter
    def file_action(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "file_action", value)

    @_builtins.property
    @pulumi.getter(name="hiveScriptPath")
    def hive_script_path(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        SQL program path This parameter is needed by Spark Script and Hive
        Script jobs only and must meet the following requirements:
        Contains a maximum of 1023 characters, excluding special characters such as `;|&><'$`. The address cannot be empty or
        full of spaces. Starts with / or s3a://. Ends with .sql. sql is case-insensitive.
        """
        return pulumi.get(self, "hive_script_path")

    @hive_script_path.setter
    def hive_script_path(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "hive_script_path", value)

    @_builtins.property
    @pulumi.getter
    def hql(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        HiveQL statement.
        """
        return pulumi.get(self, "hql")

    @hql.setter
    def hql(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "hql", value)

    @_builtins.property
    @pulumi.getter
    def input(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Path for inputting data, which must start with / or s3a://. A correct OBS path
        is required. The parameter contains a maximum of 1023 characters, excluding special characters such as `;|&>'<$`, and
        can be empty.
        """
        return pulumi.get(self, "input")

    @input.setter
    def input(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "input", value)

    @_builtins.property
    @pulumi.getter(name="jobLog")
    def job_log(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Path for storing job logs that record job running status. This path must
        start with / or s3a://. A correct OBS path is required. The parameter contains a maximum of 1023 characters, excluding
        special characters such as `;|&>'<$`, and can be empty.
        """
        return pulumi.get(self, "job_log")

    @job_log.setter
    def job_log(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "job_log", value)

    @_builtins.property
    @pulumi.getter
    def output(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Path for outputting data, which must start with / or s3a://. A correct OBS
        path is required. If the path does not exist, the system automatically creates it. The parameter contains a maximum of
        1023 characters, excluding special characters such as `;|&>'<$`, and can be empty.
        """
        return pulumi.get(self, "output")

    @output.setter
    def output(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "output", value)

    @_builtins.property
    @pulumi.getter(name="shutdownCluster")
    def shutdown_cluster(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Whether to delete the cluster after the jobs are complete.
        """
        return pulumi.get(self, "shutdown_cluster")

    @shutdown_cluster.setter
    def shutdown_cluster(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "shutdown_cluster", value)


if not MYPY:
    class Cluster2ComponentListArgsDict(TypedDict):
        component_name: pulumi.Input[_builtins.str]
        """
        Component name.
        + MRS 2.1.0 supports: Presto, Hadoop, Spark, HBase, Hive, Tez, Hue, Loader, Flink, Impala, Kudu, Flume, Kafka, and
        Storm;
        + MRS 1.9.2 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Tez, Flink, Alluxio, Ranger, Flume,
        Kafka, KafkaManager, and Storm;
        + MRS 1.8.10 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Flink, Flume, Kafka, KafkaManager,
        and Storm;
        """
        component_desc: NotRequired[pulumi.Input[_builtins.str]]
        """
        Indicates the component description.
        """
        component_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        Indicates the component ID.
        """
        component_version: NotRequired[pulumi.Input[_builtins.str]]
        """
        Indicates the component version.
        """
elif False:
    Cluster2ComponentListArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class Cluster2ComponentListArgs:
    def __init__(__self__, *,
                 component_name: pulumi.Input[_builtins.str],
                 component_desc: Optional[pulumi.Input[_builtins.str]] = None,
                 component_id: Optional[pulumi.Input[_builtins.str]] = None,
                 component_version: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.str] component_name: Component name.
               + MRS 2.1.0 supports: Presto, Hadoop, Spark, HBase, Hive, Tez, Hue, Loader, Flink, Impala, Kudu, Flume, Kafka, and
               Storm;
               + MRS 1.9.2 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Tez, Flink, Alluxio, Ranger, Flume,
               Kafka, KafkaManager, and Storm;
               + MRS 1.8.10 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Flink, Flume, Kafka, KafkaManager,
               and Storm;
        :param pulumi.Input[_builtins.str] component_desc: Indicates the component description.
        :param pulumi.Input[_builtins.str] component_id: Indicates the component ID.
        :param pulumi.Input[_builtins.str] component_version: Indicates the component version.
        """
        pulumi.set(__self__, "component_name", component_name)
        if component_desc is not None:
            pulumi.set(__self__, "component_desc", component_desc)
        if component_id is not None:
            pulumi.set(__self__, "component_id", component_id)
        if component_version is not None:
            pulumi.set(__self__, "component_version", component_version)

    @_builtins.property
    @pulumi.getter(name="componentName")
    def component_name(self) -> pulumi.Input[_builtins.str]:
        """
        Component name.
        + MRS 2.1.0 supports: Presto, Hadoop, Spark, HBase, Hive, Tez, Hue, Loader, Flink, Impala, Kudu, Flume, Kafka, and
        Storm;
        + MRS 1.9.2 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Tez, Flink, Alluxio, Ranger, Flume,
        Kafka, KafkaManager, and Storm;
        + MRS 1.8.10 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Flink, Flume, Kafka, KafkaManager,
        and Storm;
        """
        return pulumi.get(self, "component_name")

    @component_name.setter
    def component_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "component_name", value)

    @_builtins.property
    @pulumi.getter(name="componentDesc")
    def component_desc(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Indicates the component description.
        """
        return pulumi.get(self, "component_desc")

    @component_desc.setter
    def component_desc(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "component_desc", value)

    @_builtins.property
    @pulumi.getter(name="componentId")
    def component_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Indicates the component ID.
        """
        return pulumi.get(self, "component_id")

    @component_id.setter
    def component_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "component_id", value)

    @_builtins.property
    @pulumi.getter(name="componentVersion")
    def component_version(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Indicates the component version.
        """
        return pulumi.get(self, "component_version")

    @component_version.setter
    def component_version(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "component_version", value)


if not MYPY:
    class ClusterV1AddJobArgsDict(TypedDict):
        jar_path: pulumi.Input[_builtins.str]
        job_name: pulumi.Input[_builtins.str]
        job_type: pulumi.Input[_builtins.int]
        submit_job_once_cluster_run: pulumi.Input[_builtins.bool]
        arguments: NotRequired[pulumi.Input[_builtins.str]]
        file_action: NotRequired[pulumi.Input[_builtins.str]]
        hive_script_path: NotRequired[pulumi.Input[_builtins.str]]
        hql: NotRequired[pulumi.Input[_builtins.str]]
        input: NotRequired[pulumi.Input[_builtins.str]]
        job_log: NotRequired[pulumi.Input[_builtins.str]]
        output: NotRequired[pulumi.Input[_builtins.str]]
        shutdown_cluster: NotRequired[pulumi.Input[_builtins.bool]]
elif False:
    ClusterV1AddJobArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterV1AddJobArgs:
    def __init__(__self__, *,
                 jar_path: pulumi.Input[_builtins.str],
                 job_name: pulumi.Input[_builtins.str],
                 job_type: pulumi.Input[_builtins.int],
                 submit_job_once_cluster_run: pulumi.Input[_builtins.bool],
                 arguments: Optional[pulumi.Input[_builtins.str]] = None,
                 file_action: Optional[pulumi.Input[_builtins.str]] = None,
                 hive_script_path: Optional[pulumi.Input[_builtins.str]] = None,
                 hql: Optional[pulumi.Input[_builtins.str]] = None,
                 input: Optional[pulumi.Input[_builtins.str]] = None,
                 job_log: Optional[pulumi.Input[_builtins.str]] = None,
                 output: Optional[pulumi.Input[_builtins.str]] = None,
                 shutdown_cluster: Optional[pulumi.Input[_builtins.bool]] = None):
        pulumi.set(__self__, "jar_path", jar_path)
        pulumi.set(__self__, "job_name", job_name)
        pulumi.set(__self__, "job_type", job_type)
        pulumi.set(__self__, "submit_job_once_cluster_run", submit_job_once_cluster_run)
        if arguments is not None:
            pulumi.set(__self__, "arguments", arguments)
        if file_action is not None:
            pulumi.set(__self__, "file_action", file_action)
        if hive_script_path is not None:
            pulumi.set(__self__, "hive_script_path", hive_script_path)
        if hql is not None:
            pulumi.set(__self__, "hql", hql)
        if input is not None:
            pulumi.set(__self__, "input", input)
        if job_log is not None:
            pulumi.set(__self__, "job_log", job_log)
        if output is not None:
            pulumi.set(__self__, "output", output)
        if shutdown_cluster is not None:
            pulumi.set(__self__, "shutdown_cluster", shutdown_cluster)

    @_builtins.property
    @pulumi.getter(name="jarPath")
    def jar_path(self) -> pulumi.Input[_builtins.str]:
        return pulumi.get(self, "jar_path")

    @jar_path.setter
    def jar_path(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "jar_path", value)

    @_builtins.property
    @pulumi.getter(name="jobName")
    def job_name(self) -> pulumi.Input[_builtins.str]:
        return pulumi.get(self, "job_name")

    @job_name.setter
    def job_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "job_name", value)

    @_builtins.property
    @pulumi.getter(name="jobType")
    def job_type(self) -> pulumi.Input[_builtins.int]:
        return pulumi.get(self, "job_type")

    @job_type.setter
    def job_type(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "job_type", value)

    @_builtins.property
    @pulumi.getter(name="submitJobOnceClusterRun")
    def submit_job_once_cluster_run(self) -> pulumi.Input[_builtins.bool]:
        return pulumi.get(self, "submit_job_once_cluster_run")

    @submit_job_once_cluster_run.setter
    def submit_job_once_cluster_run(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "submit_job_once_cluster_run", value)

    @_builtins.property
    @pulumi.getter
    def arguments(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "arguments")

    @arguments.setter
    def arguments(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "arguments", value)

    @_builtins.property
    @pulumi.getter(name="fileAction")
    def file_action(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "file_action")

    @file_action.setter
    def file_action(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "file_action", value)

    @_builtins.property
    @pulumi.getter(name="hiveScriptPath")
    def hive_script_path(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "hive_script_path")

    @hive_script_path.setter
    def hive_script_path(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "hive_script_path", value)

    @_builtins.property
    @pulumi.getter
    def hql(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "hql")

    @hql.setter
    def hql(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "hql", value)

    @_builtins.property
    @pulumi.getter
    def input(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "input")

    @input.setter
    def input(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "input", value)

    @_builtins.property
    @pulumi.getter(name="jobLog")
    def job_log(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "job_log")

    @job_log.setter
    def job_log(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "job_log", value)

    @_builtins.property
    @pulumi.getter
    def output(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "output")

    @output.setter
    def output(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "output", value)

    @_builtins.property
    @pulumi.getter(name="shutdownCluster")
    def shutdown_cluster(self) -> Optional[pulumi.Input[_builtins.bool]]:
        return pulumi.get(self, "shutdown_cluster")

    @shutdown_cluster.setter
    def shutdown_cluster(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "shutdown_cluster", value)


if not MYPY:
    class ClusterV1ComponentListArgsDict(TypedDict):
        component_name: pulumi.Input[_builtins.str]
        component_desc: NotRequired[pulumi.Input[_builtins.str]]
        component_id: NotRequired[pulumi.Input[_builtins.str]]
        component_version: NotRequired[pulumi.Input[_builtins.str]]
elif False:
    ClusterV1ComponentListArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterV1ComponentListArgs:
    def __init__(__self__, *,
                 component_name: pulumi.Input[_builtins.str],
                 component_desc: Optional[pulumi.Input[_builtins.str]] = None,
                 component_id: Optional[pulumi.Input[_builtins.str]] = None,
                 component_version: Optional[pulumi.Input[_builtins.str]] = None):
        pulumi.set(__self__, "component_name", component_name)
        if component_desc is not None:
            pulumi.set(__self__, "component_desc", component_desc)
        if component_id is not None:
            pulumi.set(__self__, "component_id", component_id)
        if component_version is not None:
            pulumi.set(__self__, "component_version", component_version)

    @_builtins.property
    @pulumi.getter(name="componentName")
    def component_name(self) -> pulumi.Input[_builtins.str]:
        return pulumi.get(self, "component_name")

    @component_name.setter
    def component_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "component_name", value)

    @_builtins.property
    @pulumi.getter(name="componentDesc")
    def component_desc(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "component_desc")

    @component_desc.setter
    def component_desc(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "component_desc", value)

    @_builtins.property
    @pulumi.getter(name="componentId")
    def component_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "component_id")

    @component_id.setter
    def component_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "component_id", value)

    @_builtins.property
    @pulumi.getter(name="componentVersion")
    def component_version(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "component_version")

    @component_version.setter
    def component_version(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "component_version", value)


if not MYPY:
    class DataConnectionSourceInfoArgsDict(TypedDict):
        db_instance_id: pulumi.Input[_builtins.str]
        """
        The instance ID of database.
        """
        db_name: pulumi.Input[_builtins.str]
        """
        The name of database.
        """
        password: pulumi.Input[_builtins.str]
        """
        The password for logging in to the database.
        """
        user_name: pulumi.Input[_builtins.str]
        """
        The user name for logging in to the database.
        """
elif False:
    DataConnectionSourceInfoArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class DataConnectionSourceInfoArgs:
    def __init__(__self__, *,
                 db_instance_id: pulumi.Input[_builtins.str],
                 db_name: pulumi.Input[_builtins.str],
                 password: pulumi.Input[_builtins.str],
                 user_name: pulumi.Input[_builtins.str]):
        """
        :param pulumi.Input[_builtins.str] db_instance_id: The instance ID of database.
        :param pulumi.Input[_builtins.str] db_name: The name of database.
        :param pulumi.Input[_builtins.str] password: The password for logging in to the database.
        :param pulumi.Input[_builtins.str] user_name: The user name for logging in to the database.
        """
        pulumi.set(__self__, "db_instance_id", db_instance_id)
        pulumi.set(__self__, "db_name", db_name)
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "user_name", user_name)

    @_builtins.property
    @pulumi.getter(name="dbInstanceId")
    def db_instance_id(self) -> pulumi.Input[_builtins.str]:
        """
        The instance ID of database.
        """
        return pulumi.get(self, "db_instance_id")

    @db_instance_id.setter
    def db_instance_id(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "db_instance_id", value)

    @_builtins.property
    @pulumi.getter(name="dbName")
    def db_name(self) -> pulumi.Input[_builtins.str]:
        """
        The name of database.
        """
        return pulumi.get(self, "db_name")

    @db_name.setter
    def db_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "db_name", value)

    @_builtins.property
    @pulumi.getter
    def password(self) -> pulumi.Input[_builtins.str]:
        """
        The password for logging in to the database.
        """
        return pulumi.get(self, "password")

    @password.setter
    def password(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "password", value)

    @_builtins.property
    @pulumi.getter(name="userName")
    def user_name(self) -> pulumi.Input[_builtins.str]:
        """
        The user name for logging in to the database.
        """
        return pulumi.get(self, "user_name")

    @user_name.setter
    def user_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "user_name", value)


if not MYPY:
    class ScalingPolicyExecScriptArgsDict(TypedDict):
        action_stage: pulumi.Input[_builtins.str]
        """
        Time when a script is executed.  
        The following options are supported:
        + **before_scale_out**: before scale-out.
        + **before_scale_in**: before scale-in.
        + **after_scale_out**: after scale-out.
        + **after_scale_in**: after scale-in.
        """
        fail_action: pulumi.Input[_builtins.str]
        """
        Whether to continue to execute subsequent scripts and create a cluster after
        the custom automation script fails to be executed.
        The following options are supported:
        + **continue**: Continue to execute subsequent scripts.
        + **errorout**: Stop the action.

        > You are advised to set this parameter to **continue** in the commissioning phase so that the cluster
        can continue to be installed and started no matter whether the custom automation script is executed successfully.
        The scale-in operation cannot be undone. Therefore, `fail_action` must be set to **continue** for the
        scripts that are executed after scale-in.
        """
        name: pulumi.Input[_builtins.str]
        """
        Name of a custom automation script.  
        The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
        Script names must be unique in a node group.
        """
        nodes: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]
        """
        Type of a node where the custom automation script is executed.  
        The node type can be **Master**, **Core**, or **Task**.
        """
        uri: pulumi.Input[_builtins.str]
        """
        Path of a custom automation script.  
        Set this parameter to an OBS bucket path or a local VM path.
        OBS bucket path: Enter a script path manually. for example, s3a://XXX/scale.sh.
        Local VM path: Enter a script path. The script path must start with a slash (/) and end with .sh.
        """
        active_master: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Whether the custom automation script runs only on the active Master node.  
        The default value is **false**, indicating that the custom automation script can run on all Master nodes.
        """
        parameters: NotRequired[pulumi.Input[_builtins.str]]
        """
        Parameters of a custom automation script.  
        Multiple parameters are separated by space.
        The following predefined system parameters can be transferred:
        + **${mrs_scale_node_num}**: Number of the nodes to be added or removed.
        + **${mrs_scale_type}**: Scaling type. The value can be **scale_out** or **scale_in**.
        + **${mrs_scale_node_hostnames}**: Host names of the nodes to be added or removed.
        + **${mrs_scale_node_ips}**: IP addresses of the nodes to be added or removed.
        + **${mrs_scale_rule_name}**: Name of the rule that triggers auto scaling.

        Other user-defined parameters are used in the same way as those of common shell scripts. Parameters are separated by space.
        """
elif False:
    ScalingPolicyExecScriptArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ScalingPolicyExecScriptArgs:
    def __init__(__self__, *,
                 action_stage: pulumi.Input[_builtins.str],
                 fail_action: pulumi.Input[_builtins.str],
                 name: pulumi.Input[_builtins.str],
                 nodes: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]],
                 uri: pulumi.Input[_builtins.str],
                 active_master: Optional[pulumi.Input[_builtins.bool]] = None,
                 parameters: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.str] action_stage: Time when a script is executed.  
               The following options are supported:
               + **before_scale_out**: before scale-out.
               + **before_scale_in**: before scale-in.
               + **after_scale_out**: after scale-out.
               + **after_scale_in**: after scale-in.
        :param pulumi.Input[_builtins.str] fail_action: Whether to continue to execute subsequent scripts and create a cluster after
               the custom automation script fails to be executed.
               The following options are supported:
               + **continue**: Continue to execute subsequent scripts.
               + **errorout**: Stop the action.
               
               > You are advised to set this parameter to **continue** in the commissioning phase so that the cluster
               can continue to be installed and started no matter whether the custom automation script is executed successfully.
               The scale-in operation cannot be undone. Therefore, `fail_action` must be set to **continue** for the
               scripts that are executed after scale-in.
        :param pulumi.Input[_builtins.str] name: Name of a custom automation script.  
               The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
               Script names must be unique in a node group.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] nodes: Type of a node where the custom automation script is executed.  
               The node type can be **Master**, **Core**, or **Task**.
        :param pulumi.Input[_builtins.str] uri: Path of a custom automation script.  
               Set this parameter to an OBS bucket path or a local VM path.
               OBS bucket path: Enter a script path manually. for example, s3a://XXX/scale.sh.
               Local VM path: Enter a script path. The script path must start with a slash (/) and end with .sh.
        :param pulumi.Input[_builtins.bool] active_master: Whether the custom automation script runs only on the active Master node.  
               The default value is **false**, indicating that the custom automation script can run on all Master nodes.
        :param pulumi.Input[_builtins.str] parameters: Parameters of a custom automation script.  
               Multiple parameters are separated by space.
               The following predefined system parameters can be transferred:
               + **${mrs_scale_node_num}**: Number of the nodes to be added or removed.
               + **${mrs_scale_type}**: Scaling type. The value can be **scale_out** or **scale_in**.
               + **${mrs_scale_node_hostnames}**: Host names of the nodes to be added or removed.
               + **${mrs_scale_node_ips}**: IP addresses of the nodes to be added or removed.
               + **${mrs_scale_rule_name}**: Name of the rule that triggers auto scaling.
               
               Other user-defined parameters are used in the same way as those of common shell scripts. Parameters are separated by space.
        """
        pulumi.set(__self__, "action_stage", action_stage)
        pulumi.set(__self__, "fail_action", fail_action)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "nodes", nodes)
        pulumi.set(__self__, "uri", uri)
        if active_master is not None:
            pulumi.set(__self__, "active_master", active_master)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @_builtins.property
    @pulumi.getter(name="actionStage")
    def action_stage(self) -> pulumi.Input[_builtins.str]:
        """
        Time when a script is executed.  
        The following options are supported:
        + **before_scale_out**: before scale-out.
        + **before_scale_in**: before scale-in.
        + **after_scale_out**: after scale-out.
        + **after_scale_in**: after scale-in.
        """
        return pulumi.get(self, "action_stage")

    @action_stage.setter
    def action_stage(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "action_stage", value)

    @_builtins.property
    @pulumi.getter(name="failAction")
    def fail_action(self) -> pulumi.Input[_builtins.str]:
        """
        Whether to continue to execute subsequent scripts and create a cluster after
        the custom automation script fails to be executed.
        The following options are supported:
        + **continue**: Continue to execute subsequent scripts.
        + **errorout**: Stop the action.

        > You are advised to set this parameter to **continue** in the commissioning phase so that the cluster
        can continue to be installed and started no matter whether the custom automation script is executed successfully.
        The scale-in operation cannot be undone. Therefore, `fail_action` must be set to **continue** for the
        scripts that are executed after scale-in.
        """
        return pulumi.get(self, "fail_action")

    @fail_action.setter
    def fail_action(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "fail_action", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        Name of a custom automation script.  
        The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
        Script names must be unique in a node group.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def nodes(self) -> pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]:
        """
        Type of a node where the custom automation script is executed.  
        The node type can be **Master**, **Core**, or **Task**.
        """
        return pulumi.get(self, "nodes")

    @nodes.setter
    def nodes(self, value: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]):
        pulumi.set(self, "nodes", value)

    @_builtins.property
    @pulumi.getter
    def uri(self) -> pulumi.Input[_builtins.str]:
        """
        Path of a custom automation script.  
        Set this parameter to an OBS bucket path or a local VM path.
        OBS bucket path: Enter a script path manually. for example, s3a://XXX/scale.sh.
        Local VM path: Enter a script path. The script path must start with a slash (/) and end with .sh.
        """
        return pulumi.get(self, "uri")

    @uri.setter
    def uri(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "uri", value)

    @_builtins.property
    @pulumi.getter(name="activeMaster")
    def active_master(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Whether the custom automation script runs only on the active Master node.  
        The default value is **false**, indicating that the custom automation script can run on all Master nodes.
        """
        return pulumi.get(self, "active_master")

    @active_master.setter
    def active_master(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "active_master", value)

    @_builtins.property
    @pulumi.getter
    def parameters(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Parameters of a custom automation script.  
        Multiple parameters are separated by space.
        The following predefined system parameters can be transferred:
        + **${mrs_scale_node_num}**: Number of the nodes to be added or removed.
        + **${mrs_scale_type}**: Scaling type. The value can be **scale_out** or **scale_in**.
        + **${mrs_scale_node_hostnames}**: Host names of the nodes to be added or removed.
        + **${mrs_scale_node_ips}**: IP addresses of the nodes to be added or removed.
        + **${mrs_scale_rule_name}**: Name of the rule that triggers auto scaling.

        Other user-defined parameters are used in the same way as those of common shell scripts. Parameters are separated by space.
        """
        return pulumi.get(self, "parameters")

    @parameters.setter
    def parameters(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "parameters", value)


if not MYPY:
    class ScalingPolicyResourcesPlanArgsDict(TypedDict):
        end_time: pulumi.Input[_builtins.str]
        """
        End time of a resource plan.  
        The value is in the format of **hour:minute**.
        The interval between end_time and start_time must be greater than or equal to 30 minutes.
        """
        max_capacity: pulumi.Input[_builtins.int]
        """
        Maximum number of the preserved nodes in a node group in a resource plan.
        Value range: 0 to 500.

        <a name="ScalingPolicy_Rule"></a>
        The `rules` block supports:
        """
        min_capacity: pulumi.Input[_builtins.int]
        """
        Minimum number of the preserved nodes in a node group in a resource plan.
        Value range: 0 to 500.
        """
        period_type: pulumi.Input[_builtins.str]
        """
        Cycle type of a resource plan.  
        Currently, only the following cycle type is supported: **daily**.
        """
        start_time: pulumi.Input[_builtins.str]
        """
        The start time of a resource plan.  
        The value is in the format of **hour:minute**, indicating that the time ranges from 00:00 to 23:59.
        """
elif False:
    ScalingPolicyResourcesPlanArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ScalingPolicyResourcesPlanArgs:
    def __init__(__self__, *,
                 end_time: pulumi.Input[_builtins.str],
                 max_capacity: pulumi.Input[_builtins.int],
                 min_capacity: pulumi.Input[_builtins.int],
                 period_type: pulumi.Input[_builtins.str],
                 start_time: pulumi.Input[_builtins.str]):
        """
        :param pulumi.Input[_builtins.str] end_time: End time of a resource plan.  
               The value is in the format of **hour:minute**.
               The interval between end_time and start_time must be greater than or equal to 30 minutes.
        :param pulumi.Input[_builtins.int] max_capacity: Maximum number of the preserved nodes in a node group in a resource plan.
               Value range: 0 to 500.
               
               <a name="ScalingPolicy_Rule"></a>
               The `rules` block supports:
        :param pulumi.Input[_builtins.int] min_capacity: Minimum number of the preserved nodes in a node group in a resource plan.
               Value range: 0 to 500.
        :param pulumi.Input[_builtins.str] period_type: Cycle type of a resource plan.  
               Currently, only the following cycle type is supported: **daily**.
        :param pulumi.Input[_builtins.str] start_time: The start time of a resource plan.  
               The value is in the format of **hour:minute**, indicating that the time ranges from 00:00 to 23:59.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "max_capacity", max_capacity)
        pulumi.set(__self__, "min_capacity", min_capacity)
        pulumi.set(__self__, "period_type", period_type)
        pulumi.set(__self__, "start_time", start_time)

    @_builtins.property
    @pulumi.getter(name="endTime")
    def end_time(self) -> pulumi.Input[_builtins.str]:
        """
        End time of a resource plan.  
        The value is in the format of **hour:minute**.
        The interval between end_time and start_time must be greater than or equal to 30 minutes.
        """
        return pulumi.get(self, "end_time")

    @end_time.setter
    def end_time(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "end_time", value)

    @_builtins.property
    @pulumi.getter(name="maxCapacity")
    def max_capacity(self) -> pulumi.Input[_builtins.int]:
        """
        Maximum number of the preserved nodes in a node group in a resource plan.
        Value range: 0 to 500.

        <a name="ScalingPolicy_Rule"></a>
        The `rules` block supports:
        """
        return pulumi.get(self, "max_capacity")

    @max_capacity.setter
    def max_capacity(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "max_capacity", value)

    @_builtins.property
    @pulumi.getter(name="minCapacity")
    def min_capacity(self) -> pulumi.Input[_builtins.int]:
        """
        Minimum number of the preserved nodes in a node group in a resource plan.
        Value range: 0 to 500.
        """
        return pulumi.get(self, "min_capacity")

    @min_capacity.setter
    def min_capacity(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "min_capacity", value)

    @_builtins.property
    @pulumi.getter(name="periodType")
    def period_type(self) -> pulumi.Input[_builtins.str]:
        """
        Cycle type of a resource plan.  
        Currently, only the following cycle type is supported: **daily**.
        """
        return pulumi.get(self, "period_type")

    @period_type.setter
    def period_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "period_type", value)

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> pulumi.Input[_builtins.str]:
        """
        The start time of a resource plan.  
        The value is in the format of **hour:minute**, indicating that the time ranges from 00:00 to 23:59.
        """
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "start_time", value)


if not MYPY:
    class ScalingPolicyRuleArgsDict(TypedDict):
        adjustment_type: pulumi.Input[_builtins.str]
        """
        Auto scaling rule adjustment type.  
        The following options are supported:
        + **scale_out**: cluster scale-out.
        + **scale_in**: cluster scale-in.
        """
        cool_down_minutes: pulumi.Input[_builtins.int]
        """
        Cluster cooling time after an auto scaling rule is triggered,
        when no auto scaling operation is performed.
        The unit is minute. Value range: 0 to 10,080. One week is equal to 10,080 minutes.
        """
        name: pulumi.Input[_builtins.str]
        """
        Name of a custom automation script.  
        The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
        Script names must be unique in a node group.
        """
        scaling_adjustment: pulumi.Input[_builtins.int]
        """
        Number of nodes that can be adjusted once. Value range: 1 to 100.
        """
        trigger: pulumi.Input['ScalingPolicyRuleTriggerArgsDict']
        """
        Condition for triggering a rule.  
        The trigger structure is documented below.
        """
        description: NotRequired[pulumi.Input[_builtins.str]]
        """
        Description about an auto scaling rule.  
        It contains a maximum of 1,024 characters.

        <a name="ScalingPolicy_Trigger"></a>
        The `trigger` block supports:
        """
elif False:
    ScalingPolicyRuleArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ScalingPolicyRuleArgs:
    def __init__(__self__, *,
                 adjustment_type: pulumi.Input[_builtins.str],
                 cool_down_minutes: pulumi.Input[_builtins.int],
                 name: pulumi.Input[_builtins.str],
                 scaling_adjustment: pulumi.Input[_builtins.int],
                 trigger: pulumi.Input['ScalingPolicyRuleTriggerArgs'],
                 description: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.str] adjustment_type: Auto scaling rule adjustment type.  
               The following options are supported:
               + **scale_out**: cluster scale-out.
               + **scale_in**: cluster scale-in.
        :param pulumi.Input[_builtins.int] cool_down_minutes: Cluster cooling time after an auto scaling rule is triggered,
               when no auto scaling operation is performed.
               The unit is minute. Value range: 0 to 10,080. One week is equal to 10,080 minutes.
        :param pulumi.Input[_builtins.str] name: Name of a custom automation script.  
               The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
               Script names must be unique in a node group.
        :param pulumi.Input[_builtins.int] scaling_adjustment: Number of nodes that can be adjusted once. Value range: 1 to 100.
        :param pulumi.Input['ScalingPolicyRuleTriggerArgs'] trigger: Condition for triggering a rule.  
               The trigger structure is documented below.
        :param pulumi.Input[_builtins.str] description: Description about an auto scaling rule.  
               It contains a maximum of 1,024 characters.
               
               <a name="ScalingPolicy_Trigger"></a>
               The `trigger` block supports:
        """
        pulumi.set(__self__, "adjustment_type", adjustment_type)
        pulumi.set(__self__, "cool_down_minutes", cool_down_minutes)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "scaling_adjustment", scaling_adjustment)
        pulumi.set(__self__, "trigger", trigger)
        if description is not None:
            pulumi.set(__self__, "description", description)

    @_builtins.property
    @pulumi.getter(name="adjustmentType")
    def adjustment_type(self) -> pulumi.Input[_builtins.str]:
        """
        Auto scaling rule adjustment type.  
        The following options are supported:
        + **scale_out**: cluster scale-out.
        + **scale_in**: cluster scale-in.
        """
        return pulumi.get(self, "adjustment_type")

    @adjustment_type.setter
    def adjustment_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "adjustment_type", value)

    @_builtins.property
    @pulumi.getter(name="coolDownMinutes")
    def cool_down_minutes(self) -> pulumi.Input[_builtins.int]:
        """
        Cluster cooling time after an auto scaling rule is triggered,
        when no auto scaling operation is performed.
        The unit is minute. Value range: 0 to 10,080. One week is equal to 10,080 minutes.
        """
        return pulumi.get(self, "cool_down_minutes")

    @cool_down_minutes.setter
    def cool_down_minutes(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "cool_down_minutes", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        Name of a custom automation script.  
        The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
        Script names must be unique in a node group.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter(name="scalingAdjustment")
    def scaling_adjustment(self) -> pulumi.Input[_builtins.int]:
        """
        Number of nodes that can be adjusted once. Value range: 1 to 100.
        """
        return pulumi.get(self, "scaling_adjustment")

    @scaling_adjustment.setter
    def scaling_adjustment(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "scaling_adjustment", value)

    @_builtins.property
    @pulumi.getter
    def trigger(self) -> pulumi.Input['ScalingPolicyRuleTriggerArgs']:
        """
        Condition for triggering a rule.  
        The trigger structure is documented below.
        """
        return pulumi.get(self, "trigger")

    @trigger.setter
    def trigger(self, value: pulumi.Input['ScalingPolicyRuleTriggerArgs']):
        pulumi.set(self, "trigger", value)

    @_builtins.property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Description about an auto scaling rule.  
        It contains a maximum of 1,024 characters.

        <a name="ScalingPolicy_Trigger"></a>
        The `trigger` block supports:
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "description", value)


if not MYPY:
    class ScalingPolicyRuleTriggerArgsDict(TypedDict):
        evaluation_periods: pulumi.Input[_builtins.int]
        """
        Number of consecutive five-minute periods,
        during which a metric threshold is reached.
        Value range: 1 to 288.

        <a name="ScalingPolicy_ExecScript"></a>
        The `exec_scripts` block supports:
        """
        metric_name: pulumi.Input[_builtins.str]
        """
        Metric name.  
        This triggering condition makes a judgment according to the value of the metric.
        A metric name contains a maximum of 64 characters.
        For details about metric names, see [Configuring Auto Scaling for an MRS Cluster](https://support.huaweicloud.com/intl/en-us/qs-mrs/mrs_09_0005.html).
        """
        metric_value: pulumi.Input[_builtins.str]
        """
        Metric threshold to trigger a rule.  
        The parameter value can only be an integer or number with two decimal places.
        The value type and range must correspond to the metric_name.
        """
        comparison_operator: NotRequired[pulumi.Input[_builtins.str]]
        """
        Metric judgment logic operator.  
        The following options are supported:
        + **LT**: less than.
        + **GT**: greater than.
        + **LTOE**: less than or equal to.
        + **GTOE**: greater than or equal to.
        """
elif False:
    ScalingPolicyRuleTriggerArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ScalingPolicyRuleTriggerArgs:
    def __init__(__self__, *,
                 evaluation_periods: pulumi.Input[_builtins.int],
                 metric_name: pulumi.Input[_builtins.str],
                 metric_value: pulumi.Input[_builtins.str],
                 comparison_operator: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.int] evaluation_periods: Number of consecutive five-minute periods,
               during which a metric threshold is reached.
               Value range: 1 to 288.
               
               <a name="ScalingPolicy_ExecScript"></a>
               The `exec_scripts` block supports:
        :param pulumi.Input[_builtins.str] metric_name: Metric name.  
               This triggering condition makes a judgment according to the value of the metric.
               A metric name contains a maximum of 64 characters.
               For details about metric names, see [Configuring Auto Scaling for an MRS Cluster](https://support.huaweicloud.com/intl/en-us/qs-mrs/mrs_09_0005.html).
        :param pulumi.Input[_builtins.str] metric_value: Metric threshold to trigger a rule.  
               The parameter value can only be an integer or number with two decimal places.
               The value type and range must correspond to the metric_name.
        :param pulumi.Input[_builtins.str] comparison_operator: Metric judgment logic operator.  
               The following options are supported:
               + **LT**: less than.
               + **GT**: greater than.
               + **LTOE**: less than or equal to.
               + **GTOE**: greater than or equal to.
        """
        pulumi.set(__self__, "evaluation_periods", evaluation_periods)
        pulumi.set(__self__, "metric_name", metric_name)
        pulumi.set(__self__, "metric_value", metric_value)
        if comparison_operator is not None:
            pulumi.set(__self__, "comparison_operator", comparison_operator)

    @_builtins.property
    @pulumi.getter(name="evaluationPeriods")
    def evaluation_periods(self) -> pulumi.Input[_builtins.int]:
        """
        Number of consecutive five-minute periods,
        during which a metric threshold is reached.
        Value range: 1 to 288.

        <a name="ScalingPolicy_ExecScript"></a>
        The `exec_scripts` block supports:
        """
        return pulumi.get(self, "evaluation_periods")

    @evaluation_periods.setter
    def evaluation_periods(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "evaluation_periods", value)

    @_builtins.property
    @pulumi.getter(name="metricName")
    def metric_name(self) -> pulumi.Input[_builtins.str]:
        """
        Metric name.  
        This triggering condition makes a judgment according to the value of the metric.
        A metric name contains a maximum of 64 characters.
        For details about metric names, see [Configuring Auto Scaling for an MRS Cluster](https://support.huaweicloud.com/intl/en-us/qs-mrs/mrs_09_0005.html).
        """
        return pulumi.get(self, "metric_name")

    @metric_name.setter
    def metric_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "metric_name", value)

    @_builtins.property
    @pulumi.getter(name="metricValue")
    def metric_value(self) -> pulumi.Input[_builtins.str]:
        """
        Metric threshold to trigger a rule.  
        The parameter value can only be an integer or number with two decimal places.
        The value type and range must correspond to the metric_name.
        """
        return pulumi.get(self, "metric_value")

    @metric_value.setter
    def metric_value(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "metric_value", value)

    @_builtins.property
    @pulumi.getter(name="comparisonOperator")
    def comparison_operator(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Metric judgment logic operator.  
        The following options are supported:
        + **LT**: less than.
        + **GT**: greater than.
        + **LTOE**: less than or equal to.
        + **GTOE**: greater than or equal to.
        """
        return pulumi.get(self, "comparison_operator")

    @comparison_operator.setter
    def comparison_operator(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "comparison_operator", value)


if not MYPY:
    class ClusterAnalysisCoreNodesArgsDict(TypedDict):
        data_volume_count: pulumi.Input[_builtins.int]
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        flavor: pulumi.Input[_builtins.str]
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        node_number: pulumi.Input[_builtins.int]
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        root_volume_size: pulumi.Input[_builtins.int]
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        root_volume_type: pulumi.Input[_builtins.str]
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        assigned_roles: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        auto_renew: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        charging_mode: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        data_volume_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        data_volume_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        host_ips: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        period: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        period_unit: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
elif False:
    ClusterAnalysisCoreNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAnalysisCoreNodesArgs:
    def __init__(__self__, *,
                 data_volume_count: pulumi.Input[_builtins.int],
                 flavor: pulumi.Input[_builtins.str],
                 node_number: pulumi.Input[_builtins.int],
                 root_volume_size: pulumi.Input[_builtins.int],
                 root_volume_type: pulumi.Input[_builtins.str],
                 assigned_roles: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 auto_renew: Optional[pulumi.Input[_builtins.str]] = None,
                 charging_mode: Optional[pulumi.Input[_builtins.str]] = None,
                 data_volume_size: Optional[pulumi.Input[_builtins.int]] = None,
                 data_volume_type: Optional[pulumi.Input[_builtins.str]] = None,
                 host_ips: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 period: Optional[pulumi.Input[_builtins.int]] = None,
                 period_unit: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.int] data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param pulumi.Input[_builtins.str] auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param pulumi.Input[_builtins.str] charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param pulumi.Input[_builtins.str] data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param pulumi.Input[_builtins.int] period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @data_volume_count.setter
    def data_volume_count(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "data_volume_count", value)

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @flavor.setter
    def flavor(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "flavor", value)

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @node_number.setter
    def node_number(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "node_number", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @root_volume_size.setter
    def root_volume_size(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "root_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @root_volume_type.setter
    def root_volume_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "root_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @assigned_roles.setter
    def assigned_roles(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "assigned_roles", value)

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @auto_renew.setter
    def auto_renew(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "auto_renew", value)

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @charging_mode.setter
    def charging_mode(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "charging_mode", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @data_volume_size.setter
    def data_volume_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "data_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @data_volume_type.setter
    def data_volume_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "data_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @host_ips.setter
    def host_ips(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "host_ips", value)

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @period.setter
    def period(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "period", value)

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")

    @period_unit.setter
    def period_unit(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "period_unit", value)


if not MYPY:
    class ClusterAnalysisTaskNodesArgsDict(TypedDict):
        data_volume_count: pulumi.Input[_builtins.int]
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        flavor: pulumi.Input[_builtins.str]
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        node_number: pulumi.Input[_builtins.int]
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        root_volume_size: pulumi.Input[_builtins.int]
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        root_volume_type: pulumi.Input[_builtins.str]
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        assigned_roles: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        data_volume_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        data_volume_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        host_ips: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
elif False:
    ClusterAnalysisTaskNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterAnalysisTaskNodesArgs:
    def __init__(__self__, *,
                 data_volume_count: pulumi.Input[_builtins.int],
                 flavor: pulumi.Input[_builtins.str],
                 node_number: pulumi.Input[_builtins.int],
                 root_volume_size: pulumi.Input[_builtins.int],
                 root_volume_type: pulumi.Input[_builtins.str],
                 assigned_roles: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 data_volume_size: Optional[pulumi.Input[_builtins.int]] = None,
                 data_volume_type: Optional[pulumi.Input[_builtins.str]] = None,
                 host_ips: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        :param pulumi.Input[_builtins.int] data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param pulumi.Input[_builtins.int] data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param pulumi.Input[_builtins.str] data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @data_volume_count.setter
    def data_volume_count(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "data_volume_count", value)

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @flavor.setter
    def flavor(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "flavor", value)

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @node_number.setter
    def node_number(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "node_number", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @root_volume_size.setter
    def root_volume_size(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "root_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @root_volume_type.setter
    def root_volume_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "root_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @assigned_roles.setter
    def assigned_roles(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "assigned_roles", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @data_volume_size.setter
    def data_volume_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "data_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @data_volume_type.setter
    def data_volume_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "data_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @host_ips.setter
    def host_ips(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "host_ips", value)


if not MYPY:
    class ClusterBootstrapScriptArgsDict(TypedDict):
        fail_action: pulumi.Input[_builtins.str]
        """
        Specifies the action after the bootstrap action script fails to be executed.
        The options are as follows:
        + **continue**: Continue to execute subsequent scripts.
        + **errorout**: Stop the action.

        The default value is **errorout**, indicating that the action is stopped.
        Changing this will create a new MapReduce cluster resource.

        > You are advised to set this parameter to continue in the commissioning phase so that the cluster can
        continue to be installed and started no matter whether the bootstrap action is successful.
        """
        name: pulumi.Input[_builtins.str]
        """
        Specifies the name of a bootstrap action script.
        Changing this will create a new MapReduce cluster resource.
        """
        nodes: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]
        """
        Specifies names of the node group where the bootstrap action script is executed.
        """
        uri: pulumi.Input[_builtins.str]
        """
        Specifies the path of a bootstrap action script.
        Set this parameter to an OBS bucket path or a local VM path.
        + **OBS bucket path**: The path of an OBS file system starts with *s3a://* or *obs://* and end with *.sh*.
        + **Local VM path**: The script path must start with a slash (/) and end with *.sh*.

        Changing this will create a new MapReduce cluster resource.
        """
        active_master: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Specifies whether the bootstrap action script runs only on active master nodes.
        The default value is **false**, indicating that the bootstrap action script can run on all master nodes.
        """
        before_component_start: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Specifies whether the bootstrap action script is executed
        before component start.
        The options are as follows:
        + **false**: After component start. The default value is **false**.
        + **true**: Before component start.

        Changing this will create a new MapReduce cluster resource.
        """
        execute_need_sudo_root: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Specifies whether the bootstrap action script involves root user
        operations.
        Changing this will create a new MapReduce cluster resource.

        <a name="SMNNotify"></a>
        The `smn_notify` block supports:
        """
        parameters: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies bootstrap action script parameters.
        """
        start_time: NotRequired[pulumi.Input[_builtins.str]]
        """
        The execution time of one bootstrap action script, in RFC-3339 format.
        """
        state: NotRequired[pulumi.Input[_builtins.str]]
        """
        The status of one bootstrap action script.
        """
elif False:
    ClusterBootstrapScriptArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterBootstrapScriptArgs:
    def __init__(__self__, *,
                 fail_action: pulumi.Input[_builtins.str],
                 name: pulumi.Input[_builtins.str],
                 nodes: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]],
                 uri: pulumi.Input[_builtins.str],
                 active_master: Optional[pulumi.Input[_builtins.bool]] = None,
                 before_component_start: Optional[pulumi.Input[_builtins.bool]] = None,
                 execute_need_sudo_root: Optional[pulumi.Input[_builtins.bool]] = None,
                 parameters: Optional[pulumi.Input[_builtins.str]] = None,
                 start_time: Optional[pulumi.Input[_builtins.str]] = None,
                 state: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.str] fail_action: Specifies the action after the bootstrap action script fails to be executed.
               The options are as follows:
               + **continue**: Continue to execute subsequent scripts.
               + **errorout**: Stop the action.
               
               The default value is **errorout**, indicating that the action is stopped.
               Changing this will create a new MapReduce cluster resource.
               
               > You are advised to set this parameter to continue in the commissioning phase so that the cluster can
               continue to be installed and started no matter whether the bootstrap action is successful.
        :param pulumi.Input[_builtins.str] name: Specifies the name of a bootstrap action script.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] nodes: Specifies names of the node group where the bootstrap action script is executed.
        :param pulumi.Input[_builtins.str] uri: Specifies the path of a bootstrap action script.
               Set this parameter to an OBS bucket path or a local VM path.
               + **OBS bucket path**: The path of an OBS file system starts with *s3a://* or *obs://* and end with *.sh*.
               + **Local VM path**: The script path must start with a slash (/) and end with *.sh*.
               
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.bool] active_master: Specifies whether the bootstrap action script runs only on active master nodes.
               The default value is **false**, indicating that the bootstrap action script can run on all master nodes.
        :param pulumi.Input[_builtins.bool] before_component_start: Specifies whether the bootstrap action script is executed
               before component start.
               The options are as follows:
               + **false**: After component start. The default value is **false**.
               + **true**: Before component start.
               
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.bool] execute_need_sudo_root: Specifies whether the bootstrap action script involves root user
               operations.
               Changing this will create a new MapReduce cluster resource.
               
               <a name="SMNNotify"></a>
               The `smn_notify` block supports:
        :param pulumi.Input[_builtins.str] parameters: Specifies bootstrap action script parameters.
        :param pulumi.Input[_builtins.str] start_time: The execution time of one bootstrap action script, in RFC-3339 format.
        :param pulumi.Input[_builtins.str] state: The status of one bootstrap action script.
        """
        pulumi.set(__self__, "fail_action", fail_action)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "nodes", nodes)
        pulumi.set(__self__, "uri", uri)
        if active_master is not None:
            pulumi.set(__self__, "active_master", active_master)
        if before_component_start is not None:
            pulumi.set(__self__, "before_component_start", before_component_start)
        if execute_need_sudo_root is not None:
            pulumi.set(__self__, "execute_need_sudo_root", execute_need_sudo_root)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if start_time is not None:
            pulumi.set(__self__, "start_time", start_time)
        if state is not None:
            pulumi.set(__self__, "state", state)

    @_builtins.property
    @pulumi.getter(name="failAction")
    def fail_action(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the action after the bootstrap action script fails to be executed.
        The options are as follows:
        + **continue**: Continue to execute subsequent scripts.
        + **errorout**: Stop the action.

        The default value is **errorout**, indicating that the action is stopped.
        Changing this will create a new MapReduce cluster resource.

        > You are advised to set this parameter to continue in the commissioning phase so that the cluster can
        continue to be installed and started no matter whether the bootstrap action is successful.
        """
        return pulumi.get(self, "fail_action")

    @fail_action.setter
    def fail_action(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "fail_action", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the name of a bootstrap action script.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def nodes(self) -> pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]:
        """
        Specifies names of the node group where the bootstrap action script is executed.
        """
        return pulumi.get(self, "nodes")

    @nodes.setter
    def nodes(self, value: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]):
        pulumi.set(self, "nodes", value)

    @_builtins.property
    @pulumi.getter
    def uri(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the path of a bootstrap action script.
        Set this parameter to an OBS bucket path or a local VM path.
        + **OBS bucket path**: The path of an OBS file system starts with *s3a://* or *obs://* and end with *.sh*.
        + **Local VM path**: The script path must start with a slash (/) and end with *.sh*.

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "uri")

    @uri.setter
    def uri(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "uri", value)

    @_builtins.property
    @pulumi.getter(name="activeMaster")
    def active_master(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Specifies whether the bootstrap action script runs only on active master nodes.
        The default value is **false**, indicating that the bootstrap action script can run on all master nodes.
        """
        return pulumi.get(self, "active_master")

    @active_master.setter
    def active_master(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "active_master", value)

    @_builtins.property
    @pulumi.getter(name="beforeComponentStart")
    def before_component_start(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Specifies whether the bootstrap action script is executed
        before component start.
        The options are as follows:
        + **false**: After component start. The default value is **false**.
        + **true**: Before component start.

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "before_component_start")

    @before_component_start.setter
    def before_component_start(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "before_component_start", value)

    @_builtins.property
    @pulumi.getter(name="executeNeedSudoRoot")
    def execute_need_sudo_root(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Specifies whether the bootstrap action script involves root user
        operations.
        Changing this will create a new MapReduce cluster resource.

        <a name="SMNNotify"></a>
        The `smn_notify` block supports:
        """
        return pulumi.get(self, "execute_need_sudo_root")

    @execute_need_sudo_root.setter
    def execute_need_sudo_root(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "execute_need_sudo_root", value)

    @_builtins.property
    @pulumi.getter
    def parameters(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies bootstrap action script parameters.
        """
        return pulumi.get(self, "parameters")

    @parameters.setter
    def parameters(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "parameters", value)

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The execution time of one bootstrap action script, in RFC-3339 format.
        """
        return pulumi.get(self, "start_time")

    @start_time.setter
    def start_time(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "start_time", value)

    @_builtins.property
    @pulumi.getter
    def state(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The status of one bootstrap action script.
        """
        return pulumi.get(self, "state")

    @state.setter
    def state(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "state", value)


if not MYPY:
    class ClusterComponentConfigArgsDict(TypedDict):
        configs: pulumi.Input[Sequence[pulumi.Input['ClusterComponentConfigConfigArgsDict']]]
        """
        Specifies the configuration of component installed.
        The object structure is documented below.

        <a name="component_configuration"></a>
        The `configs` block supports:
        """
        name: pulumi.Input[_builtins.str]
        """
        Specifies the name of a bootstrap action script.
        Changing this will create a new MapReduce cluster resource.
        """
elif False:
    ClusterComponentConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterComponentConfigArgs:
    def __init__(__self__, *,
                 configs: pulumi.Input[Sequence[pulumi.Input['ClusterComponentConfigConfigArgs']]],
                 name: pulumi.Input[_builtins.str]):
        """
        :param pulumi.Input[Sequence[pulumi.Input['ClusterComponentConfigConfigArgs']]] configs: Specifies the configuration of component installed.
               The object structure is documented below.
               
               <a name="component_configuration"></a>
               The `configs` block supports:
        :param pulumi.Input[_builtins.str] name: Specifies the name of a bootstrap action script.
               Changing this will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "configs", configs)
        pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter
    def configs(self) -> pulumi.Input[Sequence[pulumi.Input['ClusterComponentConfigConfigArgs']]]:
        """
        Specifies the configuration of component installed.
        The object structure is documented below.

        <a name="component_configuration"></a>
        The `configs` block supports:
        """
        return pulumi.get(self, "configs")

    @configs.setter
    def configs(self, value: pulumi.Input[Sequence[pulumi.Input['ClusterComponentConfigConfigArgs']]]):
        pulumi.set(self, "configs", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the name of a bootstrap action script.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)


if not MYPY:
    class ClusterComponentConfigConfigArgsDict(TypedDict):
        config_file_name: pulumi.Input[_builtins.str]
        """
        Specifies the configuration file name of component installed.
        Changing this will create a new MapReduce cluster resource.

        <a name="ExternalDatasources"></a>
        The `external_datasources` block supports:
        """
        key: pulumi.Input[_builtins.str]
        """
        Specifies the configuration item key of component installed.
        Changing this will create a new MapReduce cluster resource.
        """
        value: pulumi.Input[_builtins.str]
        """
        Specifies the configuration item value of component installed.
        Changing this will create a new MapReduce cluster resource.
        """
elif False:
    ClusterComponentConfigConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterComponentConfigConfigArgs:
    def __init__(__self__, *,
                 config_file_name: pulumi.Input[_builtins.str],
                 key: pulumi.Input[_builtins.str],
                 value: pulumi.Input[_builtins.str]):
        """
        :param pulumi.Input[_builtins.str] config_file_name: Specifies the configuration file name of component installed.
               Changing this will create a new MapReduce cluster resource.
               
               <a name="ExternalDatasources"></a>
               The `external_datasources` block supports:
        :param pulumi.Input[_builtins.str] key: Specifies the configuration item key of component installed.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] value: Specifies the configuration item value of component installed.
               Changing this will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "config_file_name", config_file_name)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter(name="configFileName")
    def config_file_name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the configuration file name of component installed.
        Changing this will create a new MapReduce cluster resource.

        <a name="ExternalDatasources"></a>
        The `external_datasources` block supports:
        """
        return pulumi.get(self, "config_file_name")

    @config_file_name.setter
    def config_file_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "config_file_name", value)

    @_builtins.property
    @pulumi.getter
    def key(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the configuration item key of component installed.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "key", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the configuration item value of component installed.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ClusterCustomNodeArgsDict(TypedDict):
        data_volume_count: pulumi.Input[_builtins.int]
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        flavor: pulumi.Input[_builtins.str]
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        group_name: pulumi.Input[_builtins.str]
        """
        Specifies the name of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        node_number: pulumi.Input[_builtins.int]
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        root_volume_size: pulumi.Input[_builtins.int]
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        root_volume_type: pulumi.Input[_builtins.str]
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        assigned_roles: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        auto_renew: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        charging_mode: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        data_volume_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        data_volume_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        host_ips: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        period: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        period_unit: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
elif False:
    ClusterCustomNodeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterCustomNodeArgs:
    def __init__(__self__, *,
                 data_volume_count: pulumi.Input[_builtins.int],
                 flavor: pulumi.Input[_builtins.str],
                 group_name: pulumi.Input[_builtins.str],
                 node_number: pulumi.Input[_builtins.int],
                 root_volume_size: pulumi.Input[_builtins.int],
                 root_volume_type: pulumi.Input[_builtins.str],
                 assigned_roles: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 auto_renew: Optional[pulumi.Input[_builtins.str]] = None,
                 charging_mode: Optional[pulumi.Input[_builtins.str]] = None,
                 data_volume_size: Optional[pulumi.Input[_builtins.int]] = None,
                 data_volume_type: Optional[pulumi.Input[_builtins.str]] = None,
                 host_ips: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 period: Optional[pulumi.Input[_builtins.int]] = None,
                 period_unit: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.int] data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] group_name: Specifies the name of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param pulumi.Input[_builtins.str] auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param pulumi.Input[_builtins.str] charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param pulumi.Input[_builtins.str] data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param pulumi.Input[_builtins.int] period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "group_name", group_name)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @data_volume_count.setter
    def data_volume_count(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "data_volume_count", value)

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @flavor.setter
    def flavor(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "flavor", value)

    @_builtins.property
    @pulumi.getter(name="groupName")
    def group_name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the name of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "group_name")

    @group_name.setter
    def group_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "group_name", value)

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @node_number.setter
    def node_number(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "node_number", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @root_volume_size.setter
    def root_volume_size(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "root_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @root_volume_type.setter
    def root_volume_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "root_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @assigned_roles.setter
    def assigned_roles(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "assigned_roles", value)

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @auto_renew.setter
    def auto_renew(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "auto_renew", value)

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @charging_mode.setter
    def charging_mode(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "charging_mode", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @data_volume_size.setter
    def data_volume_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "data_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @data_volume_type.setter
    def data_volume_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "data_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @host_ips.setter
    def host_ips(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "host_ips", value)

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @period.setter
    def period(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "period", value)

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")

    @period_unit.setter
    def period_unit(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "period_unit", value)


if not MYPY:
    class ClusterExternalDatasourceArgsDict(TypedDict):
        component_name: pulumi.Input[_builtins.str]
        """
        Specifies the component name. The valid values are `Hive` and `Ranger`.
        Changing this will create a new MapReduce cluster resource.
        """
        role_type: pulumi.Input[_builtins.str]
        """
        Specifies the component role type.
        The options are as follows:
        + **hive_metastore**: Hive Metastore role.
        + **ranger_data**: Ranger role.

        Changing this will create a new MapReduce cluster resource.
        """
        source_type: pulumi.Input[_builtins.str]
        """
        Specifies the data connection type.
        The options are as follows:
        + **LOCAL_DB**: Local metadata.
        + **RDS_POSTGRES**: RDS PostgreSQL database.
        + **RDS_MYSQL**: RDS MySQL database.
        + **gaussdb-mysql**: GaussDB(for MySQL).

        Changing this will create a new MapReduce cluster resource.
        """
        data_connection_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the data connection ID.
        This parameter is mandatory if `source_type` is not **LOCAL_DB**.
        Changing this will create a new MapReduce cluster resource.

        <a name="BootstrapScripts"></a>
        The `bootstrap_scripts` block supports:
        """
elif False:
    ClusterExternalDatasourceArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterExternalDatasourceArgs:
    def __init__(__self__, *,
                 component_name: pulumi.Input[_builtins.str],
                 role_type: pulumi.Input[_builtins.str],
                 source_type: pulumi.Input[_builtins.str],
                 data_connection_id: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.str] component_name: Specifies the component name. The valid values are `Hive` and `Ranger`.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] role_type: Specifies the component role type.
               The options are as follows:
               + **hive_metastore**: Hive Metastore role.
               + **ranger_data**: Ranger role.
               
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] source_type: Specifies the data connection type.
               The options are as follows:
               + **LOCAL_DB**: Local metadata.
               + **RDS_POSTGRES**: RDS PostgreSQL database.
               + **RDS_MYSQL**: RDS MySQL database.
               + **gaussdb-mysql**: GaussDB(for MySQL).
               
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] data_connection_id: Specifies the data connection ID.
               This parameter is mandatory if `source_type` is not **LOCAL_DB**.
               Changing this will create a new MapReduce cluster resource.
               
               <a name="BootstrapScripts"></a>
               The `bootstrap_scripts` block supports:
        """
        pulumi.set(__self__, "component_name", component_name)
        pulumi.set(__self__, "role_type", role_type)
        pulumi.set(__self__, "source_type", source_type)
        if data_connection_id is not None:
            pulumi.set(__self__, "data_connection_id", data_connection_id)

    @_builtins.property
    @pulumi.getter(name="componentName")
    def component_name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the component name. The valid values are `Hive` and `Ranger`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "component_name")

    @component_name.setter
    def component_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "component_name", value)

    @_builtins.property
    @pulumi.getter(name="roleType")
    def role_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the component role type.
        The options are as follows:
        + **hive_metastore**: Hive Metastore role.
        + **ranger_data**: Ranger role.

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "role_type")

    @role_type.setter
    def role_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "role_type", value)

    @_builtins.property
    @pulumi.getter(name="sourceType")
    def source_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the data connection type.
        The options are as follows:
        + **LOCAL_DB**: Local metadata.
        + **RDS_POSTGRES**: RDS PostgreSQL database.
        + **RDS_MYSQL**: RDS MySQL database.
        + **gaussdb-mysql**: GaussDB(for MySQL).

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "source_type")

    @source_type.setter
    def source_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "source_type", value)

    @_builtins.property
    @pulumi.getter(name="dataConnectionId")
    def data_connection_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the data connection ID.
        This parameter is mandatory if `source_type` is not **LOCAL_DB**.
        Changing this will create a new MapReduce cluster resource.

        <a name="BootstrapScripts"></a>
        The `bootstrap_scripts` block supports:
        """
        return pulumi.get(self, "data_connection_id")

    @data_connection_id.setter
    def data_connection_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "data_connection_id", value)


if not MYPY:
    class ClusterMasterNodesArgsDict(TypedDict):
        data_volume_count: pulumi.Input[_builtins.int]
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        flavor: pulumi.Input[_builtins.str]
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        node_number: pulumi.Input[_builtins.int]
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        root_volume_size: pulumi.Input[_builtins.int]
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        root_volume_type: pulumi.Input[_builtins.str]
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        assigned_roles: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        auto_renew: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        charging_mode: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        data_volume_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        data_volume_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        host_ips: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        period: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        period_unit: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
elif False:
    ClusterMasterNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterMasterNodesArgs:
    def __init__(__self__, *,
                 data_volume_count: pulumi.Input[_builtins.int],
                 flavor: pulumi.Input[_builtins.str],
                 node_number: pulumi.Input[_builtins.int],
                 root_volume_size: pulumi.Input[_builtins.int],
                 root_volume_type: pulumi.Input[_builtins.str],
                 assigned_roles: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 auto_renew: Optional[pulumi.Input[_builtins.str]] = None,
                 charging_mode: Optional[pulumi.Input[_builtins.str]] = None,
                 data_volume_size: Optional[pulumi.Input[_builtins.int]] = None,
                 data_volume_type: Optional[pulumi.Input[_builtins.str]] = None,
                 host_ips: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 period: Optional[pulumi.Input[_builtins.int]] = None,
                 period_unit: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.int] data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param pulumi.Input[_builtins.str] auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param pulumi.Input[_builtins.str] charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param pulumi.Input[_builtins.str] data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param pulumi.Input[_builtins.int] period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @data_volume_count.setter
    def data_volume_count(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "data_volume_count", value)

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @flavor.setter
    def flavor(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "flavor", value)

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @node_number.setter
    def node_number(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "node_number", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @root_volume_size.setter
    def root_volume_size(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "root_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @root_volume_type.setter
    def root_volume_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "root_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @assigned_roles.setter
    def assigned_roles(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "assigned_roles", value)

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @auto_renew.setter
    def auto_renew(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "auto_renew", value)

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @charging_mode.setter
    def charging_mode(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "charging_mode", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @data_volume_size.setter
    def data_volume_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "data_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @data_volume_type.setter
    def data_volume_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "data_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @host_ips.setter
    def host_ips(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "host_ips", value)

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @period.setter
    def period(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "period", value)

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")

    @period_unit.setter
    def period_unit(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "period_unit", value)


if not MYPY:
    class ClusterSmnNotifyArgsDict(TypedDict):
        subscription_name: pulumi.Input[_builtins.str]
        """
        Specifies the subscription rule name.
        Changing this will create a new MapReduce cluster resource.
        """
        topic_urn: pulumi.Input[_builtins.str]
        """
        Specifies the Uniform Resource Name (URN) of the topic.
        Changing this will create a new MapReduce cluster resource.
        """
elif False:
    ClusterSmnNotifyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterSmnNotifyArgs:
    def __init__(__self__, *,
                 subscription_name: pulumi.Input[_builtins.str],
                 topic_urn: pulumi.Input[_builtins.str]):
        """
        :param pulumi.Input[_builtins.str] subscription_name: Specifies the subscription rule name.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] topic_urn: Specifies the Uniform Resource Name (URN) of the topic.
               Changing this will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "subscription_name", subscription_name)
        pulumi.set(__self__, "topic_urn", topic_urn)

    @_builtins.property
    @pulumi.getter(name="subscriptionName")
    def subscription_name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the subscription rule name.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "subscription_name")

    @subscription_name.setter
    def subscription_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "subscription_name", value)

    @_builtins.property
    @pulumi.getter(name="topicUrn")
    def topic_urn(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the Uniform Resource Name (URN) of the topic.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "topic_urn")

    @topic_urn.setter
    def topic_urn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "topic_urn", value)


if not MYPY:
    class ClusterStreamingCoreNodesArgsDict(TypedDict):
        data_volume_count: pulumi.Input[_builtins.int]
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        flavor: pulumi.Input[_builtins.str]
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        node_number: pulumi.Input[_builtins.int]
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        root_volume_size: pulumi.Input[_builtins.int]
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        root_volume_type: pulumi.Input[_builtins.str]
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        assigned_roles: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        auto_renew: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        charging_mode: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        data_volume_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        data_volume_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        host_ips: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        period: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        period_unit: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
elif False:
    ClusterStreamingCoreNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterStreamingCoreNodesArgs:
    def __init__(__self__, *,
                 data_volume_count: pulumi.Input[_builtins.int],
                 flavor: pulumi.Input[_builtins.str],
                 node_number: pulumi.Input[_builtins.int],
                 root_volume_size: pulumi.Input[_builtins.int],
                 root_volume_type: pulumi.Input[_builtins.str],
                 assigned_roles: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 auto_renew: Optional[pulumi.Input[_builtins.str]] = None,
                 charging_mode: Optional[pulumi.Input[_builtins.str]] = None,
                 data_volume_size: Optional[pulumi.Input[_builtins.int]] = None,
                 data_volume_type: Optional[pulumi.Input[_builtins.str]] = None,
                 host_ips: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 period: Optional[pulumi.Input[_builtins.int]] = None,
                 period_unit: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.int] data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param pulumi.Input[_builtins.str] auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param pulumi.Input[_builtins.str] charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param pulumi.Input[_builtins.str] data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param pulumi.Input[_builtins.int] period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @data_volume_count.setter
    def data_volume_count(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "data_volume_count", value)

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @flavor.setter
    def flavor(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "flavor", value)

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @node_number.setter
    def node_number(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "node_number", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @root_volume_size.setter
    def root_volume_size(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "root_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @root_volume_type.setter
    def root_volume_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "root_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @assigned_roles.setter
    def assigned_roles(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "assigned_roles", value)

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @auto_renew.setter
    def auto_renew(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "auto_renew", value)

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @charging_mode.setter
    def charging_mode(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "charging_mode", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @data_volume_size.setter
    def data_volume_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "data_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @data_volume_type.setter
    def data_volume_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "data_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @host_ips.setter
    def host_ips(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "host_ips", value)

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @period.setter
    def period(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "period", value)

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")

    @period_unit.setter
    def period_unit(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "period_unit", value)


if not MYPY:
    class ClusterStreamingTaskNodesArgsDict(TypedDict):
        data_volume_count: pulumi.Input[_builtins.int]
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        flavor: pulumi.Input[_builtins.str]
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        node_number: pulumi.Input[_builtins.int]
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        root_volume_size: pulumi.Input[_builtins.int]
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        root_volume_type: pulumi.Input[_builtins.str]
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        assigned_roles: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        data_volume_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        data_volume_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        host_ips: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
elif False:
    ClusterStreamingTaskNodesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterStreamingTaskNodesArgs:
    def __init__(__self__, *,
                 data_volume_count: pulumi.Input[_builtins.int],
                 flavor: pulumi.Input[_builtins.str],
                 node_number: pulumi.Input[_builtins.int],
                 root_volume_size: pulumi.Input[_builtins.int],
                 root_volume_type: pulumi.Input[_builtins.str],
                 assigned_roles: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 data_volume_size: Optional[pulumi.Input[_builtins.int]] = None,
                 data_volume_type: Optional[pulumi.Input[_builtins.str]] = None,
                 host_ips: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        :param pulumi.Input[_builtins.int] data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.int] root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param pulumi.Input[_builtins.str] root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param pulumi.Input[_builtins.int] data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param pulumi.Input[_builtins.str] data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @data_volume_count.setter
    def data_volume_count(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "data_volume_count", value)

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @flavor.setter
    def flavor(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "flavor", value)

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @node_number.setter
    def node_number(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "node_number", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> pulumi.Input[_builtins.int]:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @root_volume_size.setter
    def root_volume_size(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "root_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @root_volume_type.setter
    def root_volume_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "root_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @assigned_roles.setter
    def assigned_roles(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "assigned_roles", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @data_volume_size.setter
    def data_volume_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "data_volume_size", value)

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @data_volume_type.setter
    def data_volume_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "data_volume_type", value)

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @host_ips.setter
    def host_ips(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "host_ips", value)


