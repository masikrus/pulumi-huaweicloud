# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs

__all__ = [
    'Cluster2AddJob',
    'Cluster2ComponentList',
    'ClusterV1AddJob',
    'ClusterV1ComponentList',
    'DataConnectionSourceInfo',
    'ScalingPolicyExecScript',
    'ScalingPolicyResourcesPlan',
    'ScalingPolicyRule',
    'ScalingPolicyRuleTrigger',
    'ClusterAnalysisCoreNodes',
    'ClusterAnalysisTaskNodes',
    'ClusterBootstrapScript',
    'ClusterComponentConfig',
    'ClusterComponentConfigConfig',
    'ClusterCustomNode',
    'ClusterExternalDatasource',
    'ClusterMasterNodes',
    'ClusterSmnNotify',
    'ClusterStreamingCoreNodes',
    'ClusterStreamingTaskNodes',
    'GetClustersClusterResult',
    'GetClustersClusterComponentListResult',
    'GetClustersClusterNodeGroupResult',
    'GetClustersClusterTaskNodeGroupResult',
]

@pulumi.output_type
class Cluster2AddJob(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarPath":
            suggest = "jar_path"
        elif key == "jobName":
            suggest = "job_name"
        elif key == "jobType":
            suggest = "job_type"
        elif key == "submitJobOnceClusterRun":
            suggest = "submit_job_once_cluster_run"
        elif key == "fileAction":
            suggest = "file_action"
        elif key == "hiveScriptPath":
            suggest = "hive_script_path"
        elif key == "jobLog":
            suggest = "job_log"
        elif key == "shutdownCluster":
            suggest = "shutdown_cluster"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in Cluster2AddJob. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        Cluster2AddJob.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        Cluster2AddJob.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_path: _builtins.str,
                 job_name: _builtins.str,
                 job_type: _builtins.int,
                 submit_job_once_cluster_run: _builtins.bool,
                 arguments: Optional[_builtins.str] = None,
                 file_action: Optional[_builtins.str] = None,
                 hive_script_path: Optional[_builtins.str] = None,
                 hql: Optional[_builtins.str] = None,
                 input: Optional[_builtins.str] = None,
                 job_log: Optional[_builtins.str] = None,
                 output: Optional[_builtins.str] = None,
                 shutdown_cluster: Optional[_builtins.bool] = None):
        """
        :param _builtins.str jar_path: Path of the **.jar** file or **.sql** file for program execution.  
               The parameter must meet the following requirements:
               + Contains a maximum of 1,023 characters, excluding special characters such as ;|&><'$. The parameter value cannot
               be empty or full of spaces.
               + Files can be stored in HDFS or OBS. The path varies depending on the file system. OBS: The path must start with
               s3a://. Files or programs encrypted by KMS are not supported. HDFS: The path starts with a slash (/).
               + Spark Script must end with .sql while MapReduce and Spark Jar must end with .jar. sql and jar are
               case-insensitive.
        :param _builtins.str job_name: Job name. It contains `1` to `64` characters. Only letters, digits, hyphens (-),
               and underscores (_) are allowed. NOTE: Identical job names are allowed but not recommended.
        :param _builtins.int job_type: Job type code.  
               + **1**: MapReduce
               + **2**: Spark
               + **3**: Hive Script
               + **4**: HiveQL (not supported currently)
               + **5**: DistCp, importing and exporting data (not supported currently)
               + **6**: Spark Script
               + **7**: Spark SQL, submitting Spark SQL statements (not supported currently)
               
               > NOTE: Spark and Hive jobs can be added to only clusters including Spark and Hive components.
        :param _builtins.bool submit_job_once_cluster_run: Whether the job is submitted during the cluster creation or
               after the cluster is created.
        :param _builtins.str arguments: Key parameter for program execution. The parameter is specified by the
               function of the user's program. MRS is only responsible for loading the parameter. The parameter contains a maximum of
               `2,047` characters, excluding special characters such as `;|&>'<$`, and can be empty.
        :param _builtins.str file_action: Data import and export. Valid values include: import, export.
        :param _builtins.str hive_script_path: SQL program path This parameter is needed by Spark Script and Hive
               Script jobs only and must meet the following requirements:
               Contains a maximum of 1023 characters, excluding special characters such as `;|&><'$`. The address cannot be empty or
               full of spaces. Starts with / or s3a://. Ends with .sql. sql is case-insensitive.
        :param _builtins.str hql: HiveQL statement.
        :param _builtins.str input: Path for inputting data, which must start with / or s3a://. A correct OBS path
               is required. The parameter contains a maximum of 1023 characters, excluding special characters such as `;|&>'<$`, and
               can be empty.
        :param _builtins.str job_log: Path for storing job logs that record job running status. This path must
               start with / or s3a://. A correct OBS path is required. The parameter contains a maximum of 1023 characters, excluding
               special characters such as `;|&>'<$`, and can be empty.
        :param _builtins.str output: Path for outputting data, which must start with / or s3a://. A correct OBS
               path is required. If the path does not exist, the system automatically creates it. The parameter contains a maximum of
               1023 characters, excluding special characters such as `;|&>'<$`, and can be empty.
        :param _builtins.bool shutdown_cluster: Whether to delete the cluster after the jobs are complete.
        """
        pulumi.set(__self__, "jar_path", jar_path)
        pulumi.set(__self__, "job_name", job_name)
        pulumi.set(__self__, "job_type", job_type)
        pulumi.set(__self__, "submit_job_once_cluster_run", submit_job_once_cluster_run)
        if arguments is not None:
            pulumi.set(__self__, "arguments", arguments)
        if file_action is not None:
            pulumi.set(__self__, "file_action", file_action)
        if hive_script_path is not None:
            pulumi.set(__self__, "hive_script_path", hive_script_path)
        if hql is not None:
            pulumi.set(__self__, "hql", hql)
        if input is not None:
            pulumi.set(__self__, "input", input)
        if job_log is not None:
            pulumi.set(__self__, "job_log", job_log)
        if output is not None:
            pulumi.set(__self__, "output", output)
        if shutdown_cluster is not None:
            pulumi.set(__self__, "shutdown_cluster", shutdown_cluster)

    @_builtins.property
    @pulumi.getter(name="jarPath")
    def jar_path(self) -> _builtins.str:
        """
        Path of the **.jar** file or **.sql** file for program execution.  
        The parameter must meet the following requirements:
        + Contains a maximum of 1,023 characters, excluding special characters such as ;|&><'$. The parameter value cannot
        be empty or full of spaces.
        + Files can be stored in HDFS or OBS. The path varies depending on the file system. OBS: The path must start with
        s3a://. Files or programs encrypted by KMS are not supported. HDFS: The path starts with a slash (/).
        + Spark Script must end with .sql while MapReduce and Spark Jar must end with .jar. sql and jar are
        case-insensitive.
        """
        return pulumi.get(self, "jar_path")

    @_builtins.property
    @pulumi.getter(name="jobName")
    def job_name(self) -> _builtins.str:
        """
        Job name. It contains `1` to `64` characters. Only letters, digits, hyphens (-),
        and underscores (_) are allowed. NOTE: Identical job names are allowed but not recommended.
        """
        return pulumi.get(self, "job_name")

    @_builtins.property
    @pulumi.getter(name="jobType")
    def job_type(self) -> _builtins.int:
        """
        Job type code.  
        + **1**: MapReduce
        + **2**: Spark
        + **3**: Hive Script
        + **4**: HiveQL (not supported currently)
        + **5**: DistCp, importing and exporting data (not supported currently)
        + **6**: Spark Script
        + **7**: Spark SQL, submitting Spark SQL statements (not supported currently)

        > NOTE: Spark and Hive jobs can be added to only clusters including Spark and Hive components.
        """
        return pulumi.get(self, "job_type")

    @_builtins.property
    @pulumi.getter(name="submitJobOnceClusterRun")
    def submit_job_once_cluster_run(self) -> _builtins.bool:
        """
        Whether the job is submitted during the cluster creation or
        after the cluster is created.
        """
        return pulumi.get(self, "submit_job_once_cluster_run")

    @_builtins.property
    @pulumi.getter
    def arguments(self) -> Optional[_builtins.str]:
        """
        Key parameter for program execution. The parameter is specified by the
        function of the user's program. MRS is only responsible for loading the parameter. The parameter contains a maximum of
        `2,047` characters, excluding special characters such as `;|&>'<$`, and can be empty.
        """
        return pulumi.get(self, "arguments")

    @_builtins.property
    @pulumi.getter(name="fileAction")
    def file_action(self) -> Optional[_builtins.str]:
        """
        Data import and export. Valid values include: import, export.
        """
        return pulumi.get(self, "file_action")

    @_builtins.property
    @pulumi.getter(name="hiveScriptPath")
    def hive_script_path(self) -> Optional[_builtins.str]:
        """
        SQL program path This parameter is needed by Spark Script and Hive
        Script jobs only and must meet the following requirements:
        Contains a maximum of 1023 characters, excluding special characters such as `;|&><'$`. The address cannot be empty or
        full of spaces. Starts with / or s3a://. Ends with .sql. sql is case-insensitive.
        """
        return pulumi.get(self, "hive_script_path")

    @_builtins.property
    @pulumi.getter
    def hql(self) -> Optional[_builtins.str]:
        """
        HiveQL statement.
        """
        return pulumi.get(self, "hql")

    @_builtins.property
    @pulumi.getter
    def input(self) -> Optional[_builtins.str]:
        """
        Path for inputting data, which must start with / or s3a://. A correct OBS path
        is required. The parameter contains a maximum of 1023 characters, excluding special characters such as `;|&>'<$`, and
        can be empty.
        """
        return pulumi.get(self, "input")

    @_builtins.property
    @pulumi.getter(name="jobLog")
    def job_log(self) -> Optional[_builtins.str]:
        """
        Path for storing job logs that record job running status. This path must
        start with / or s3a://. A correct OBS path is required. The parameter contains a maximum of 1023 characters, excluding
        special characters such as `;|&>'<$`, and can be empty.
        """
        return pulumi.get(self, "job_log")

    @_builtins.property
    @pulumi.getter
    def output(self) -> Optional[_builtins.str]:
        """
        Path for outputting data, which must start with / or s3a://. A correct OBS
        path is required. If the path does not exist, the system automatically creates it. The parameter contains a maximum of
        1023 characters, excluding special characters such as `;|&>'<$`, and can be empty.
        """
        return pulumi.get(self, "output")

    @_builtins.property
    @pulumi.getter(name="shutdownCluster")
    def shutdown_cluster(self) -> Optional[_builtins.bool]:
        """
        Whether to delete the cluster after the jobs are complete.
        """
        return pulumi.get(self, "shutdown_cluster")


@pulumi.output_type
class Cluster2ComponentList(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentName":
            suggest = "component_name"
        elif key == "componentDesc":
            suggest = "component_desc"
        elif key == "componentId":
            suggest = "component_id"
        elif key == "componentVersion":
            suggest = "component_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in Cluster2ComponentList. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        Cluster2ComponentList.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        Cluster2ComponentList.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_name: _builtins.str,
                 component_desc: Optional[_builtins.str] = None,
                 component_id: Optional[_builtins.str] = None,
                 component_version: Optional[_builtins.str] = None):
        """
        :param _builtins.str component_name: Component name.
               + MRS 2.1.0 supports: Presto, Hadoop, Spark, HBase, Hive, Tez, Hue, Loader, Flink, Impala, Kudu, Flume, Kafka, and
               Storm;
               + MRS 1.9.2 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Tez, Flink, Alluxio, Ranger, Flume,
               Kafka, KafkaManager, and Storm;
               + MRS 1.8.10 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Flink, Flume, Kafka, KafkaManager,
               and Storm;
        :param _builtins.str component_desc: Indicates the component description.
        :param _builtins.str component_id: Indicates the component ID.
        :param _builtins.str component_version: Indicates the component version.
        """
        pulumi.set(__self__, "component_name", component_name)
        if component_desc is not None:
            pulumi.set(__self__, "component_desc", component_desc)
        if component_id is not None:
            pulumi.set(__self__, "component_id", component_id)
        if component_version is not None:
            pulumi.set(__self__, "component_version", component_version)

    @_builtins.property
    @pulumi.getter(name="componentName")
    def component_name(self) -> _builtins.str:
        """
        Component name.
        + MRS 2.1.0 supports: Presto, Hadoop, Spark, HBase, Hive, Tez, Hue, Loader, Flink, Impala, Kudu, Flume, Kafka, and
        Storm;
        + MRS 1.9.2 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Tez, Flink, Alluxio, Ranger, Flume,
        Kafka, KafkaManager, and Storm;
        + MRS 1.8.10 supports: Presto, Hadoop, Spark, HBase, OpenTSDB, Hive, Hue, Loader, Flink, Flume, Kafka, KafkaManager,
        and Storm;
        """
        return pulumi.get(self, "component_name")

    @_builtins.property
    @pulumi.getter(name="componentDesc")
    def component_desc(self) -> Optional[_builtins.str]:
        """
        Indicates the component description.
        """
        return pulumi.get(self, "component_desc")

    @_builtins.property
    @pulumi.getter(name="componentId")
    def component_id(self) -> Optional[_builtins.str]:
        """
        Indicates the component ID.
        """
        return pulumi.get(self, "component_id")

    @_builtins.property
    @pulumi.getter(name="componentVersion")
    def component_version(self) -> Optional[_builtins.str]:
        """
        Indicates the component version.
        """
        return pulumi.get(self, "component_version")


@pulumi.output_type
class ClusterV1AddJob(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarPath":
            suggest = "jar_path"
        elif key == "jobName":
            suggest = "job_name"
        elif key == "jobType":
            suggest = "job_type"
        elif key == "submitJobOnceClusterRun":
            suggest = "submit_job_once_cluster_run"
        elif key == "fileAction":
            suggest = "file_action"
        elif key == "hiveScriptPath":
            suggest = "hive_script_path"
        elif key == "jobLog":
            suggest = "job_log"
        elif key == "shutdownCluster":
            suggest = "shutdown_cluster"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterV1AddJob. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterV1AddJob.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterV1AddJob.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_path: _builtins.str,
                 job_name: _builtins.str,
                 job_type: _builtins.int,
                 submit_job_once_cluster_run: _builtins.bool,
                 arguments: Optional[_builtins.str] = None,
                 file_action: Optional[_builtins.str] = None,
                 hive_script_path: Optional[_builtins.str] = None,
                 hql: Optional[_builtins.str] = None,
                 input: Optional[_builtins.str] = None,
                 job_log: Optional[_builtins.str] = None,
                 output: Optional[_builtins.str] = None,
                 shutdown_cluster: Optional[_builtins.bool] = None):
        pulumi.set(__self__, "jar_path", jar_path)
        pulumi.set(__self__, "job_name", job_name)
        pulumi.set(__self__, "job_type", job_type)
        pulumi.set(__self__, "submit_job_once_cluster_run", submit_job_once_cluster_run)
        if arguments is not None:
            pulumi.set(__self__, "arguments", arguments)
        if file_action is not None:
            pulumi.set(__self__, "file_action", file_action)
        if hive_script_path is not None:
            pulumi.set(__self__, "hive_script_path", hive_script_path)
        if hql is not None:
            pulumi.set(__self__, "hql", hql)
        if input is not None:
            pulumi.set(__self__, "input", input)
        if job_log is not None:
            pulumi.set(__self__, "job_log", job_log)
        if output is not None:
            pulumi.set(__self__, "output", output)
        if shutdown_cluster is not None:
            pulumi.set(__self__, "shutdown_cluster", shutdown_cluster)

    @_builtins.property
    @pulumi.getter(name="jarPath")
    def jar_path(self) -> _builtins.str:
        return pulumi.get(self, "jar_path")

    @_builtins.property
    @pulumi.getter(name="jobName")
    def job_name(self) -> _builtins.str:
        return pulumi.get(self, "job_name")

    @_builtins.property
    @pulumi.getter(name="jobType")
    def job_type(self) -> _builtins.int:
        return pulumi.get(self, "job_type")

    @_builtins.property
    @pulumi.getter(name="submitJobOnceClusterRun")
    def submit_job_once_cluster_run(self) -> _builtins.bool:
        return pulumi.get(self, "submit_job_once_cluster_run")

    @_builtins.property
    @pulumi.getter
    def arguments(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "arguments")

    @_builtins.property
    @pulumi.getter(name="fileAction")
    def file_action(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "file_action")

    @_builtins.property
    @pulumi.getter(name="hiveScriptPath")
    def hive_script_path(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "hive_script_path")

    @_builtins.property
    @pulumi.getter
    def hql(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "hql")

    @_builtins.property
    @pulumi.getter
    def input(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "input")

    @_builtins.property
    @pulumi.getter(name="jobLog")
    def job_log(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "job_log")

    @_builtins.property
    @pulumi.getter
    def output(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "output")

    @_builtins.property
    @pulumi.getter(name="shutdownCluster")
    def shutdown_cluster(self) -> Optional[_builtins.bool]:
        return pulumi.get(self, "shutdown_cluster")


@pulumi.output_type
class ClusterV1ComponentList(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentName":
            suggest = "component_name"
        elif key == "componentDesc":
            suggest = "component_desc"
        elif key == "componentId":
            suggest = "component_id"
        elif key == "componentVersion":
            suggest = "component_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterV1ComponentList. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterV1ComponentList.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterV1ComponentList.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_name: _builtins.str,
                 component_desc: Optional[_builtins.str] = None,
                 component_id: Optional[_builtins.str] = None,
                 component_version: Optional[_builtins.str] = None):
        pulumi.set(__self__, "component_name", component_name)
        if component_desc is not None:
            pulumi.set(__self__, "component_desc", component_desc)
        if component_id is not None:
            pulumi.set(__self__, "component_id", component_id)
        if component_version is not None:
            pulumi.set(__self__, "component_version", component_version)

    @_builtins.property
    @pulumi.getter(name="componentName")
    def component_name(self) -> _builtins.str:
        return pulumi.get(self, "component_name")

    @_builtins.property
    @pulumi.getter(name="componentDesc")
    def component_desc(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "component_desc")

    @_builtins.property
    @pulumi.getter(name="componentId")
    def component_id(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "component_id")

    @_builtins.property
    @pulumi.getter(name="componentVersion")
    def component_version(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "component_version")


@pulumi.output_type
class DataConnectionSourceInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dbInstanceId":
            suggest = "db_instance_id"
        elif key == "dbName":
            suggest = "db_name"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in DataConnectionSourceInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        DataConnectionSourceInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        DataConnectionSourceInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 db_instance_id: _builtins.str,
                 db_name: _builtins.str,
                 password: _builtins.str,
                 user_name: _builtins.str):
        """
        :param _builtins.str db_instance_id: The instance ID of database.
        :param _builtins.str db_name: The name of database.
        :param _builtins.str password: The password for logging in to the database.
        :param _builtins.str user_name: The user name for logging in to the database.
        """
        pulumi.set(__self__, "db_instance_id", db_instance_id)
        pulumi.set(__self__, "db_name", db_name)
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "user_name", user_name)

    @_builtins.property
    @pulumi.getter(name="dbInstanceId")
    def db_instance_id(self) -> _builtins.str:
        """
        The instance ID of database.
        """
        return pulumi.get(self, "db_instance_id")

    @_builtins.property
    @pulumi.getter(name="dbName")
    def db_name(self) -> _builtins.str:
        """
        The name of database.
        """
        return pulumi.get(self, "db_name")

    @_builtins.property
    @pulumi.getter
    def password(self) -> _builtins.str:
        """
        The password for logging in to the database.
        """
        return pulumi.get(self, "password")

    @_builtins.property
    @pulumi.getter(name="userName")
    def user_name(self) -> _builtins.str:
        """
        The user name for logging in to the database.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class ScalingPolicyExecScript(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "actionStage":
            suggest = "action_stage"
        elif key == "failAction":
            suggest = "fail_action"
        elif key == "activeMaster":
            suggest = "active_master"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ScalingPolicyExecScript. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ScalingPolicyExecScript.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ScalingPolicyExecScript.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 action_stage: _builtins.str,
                 fail_action: _builtins.str,
                 name: _builtins.str,
                 nodes: Sequence[_builtins.str],
                 uri: _builtins.str,
                 active_master: Optional[_builtins.bool] = None,
                 parameters: Optional[_builtins.str] = None):
        """
        :param _builtins.str action_stage: Time when a script is executed.  
               The following options are supported:
               + **before_scale_out**: before scale-out.
               + **before_scale_in**: before scale-in.
               + **after_scale_out**: after scale-out.
               + **after_scale_in**: after scale-in.
        :param _builtins.str fail_action: Whether to continue to execute subsequent scripts and create a cluster after
               the custom automation script fails to be executed.
               The following options are supported:
               + **continue**: Continue to execute subsequent scripts.
               + **errorout**: Stop the action.
               
               > You are advised to set this parameter to **continue** in the commissioning phase so that the cluster
               can continue to be installed and started no matter whether the custom automation script is executed successfully.
               The scale-in operation cannot be undone. Therefore, `fail_action` must be set to **continue** for the
               scripts that are executed after scale-in.
        :param _builtins.str name: Name of a custom automation script.  
               The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
               Script names must be unique in a node group.
        :param Sequence[_builtins.str] nodes: Type of a node where the custom automation script is executed.  
               The node type can be **Master**, **Core**, or **Task**.
        :param _builtins.str uri: Path of a custom automation script.  
               Set this parameter to an OBS bucket path or a local VM path.
               OBS bucket path: Enter a script path manually. for example, s3a://XXX/scale.sh.
               Local VM path: Enter a script path. The script path must start with a slash (/) and end with .sh.
        :param _builtins.bool active_master: Whether the custom automation script runs only on the active Master node.  
               The default value is **false**, indicating that the custom automation script can run on all Master nodes.
        :param _builtins.str parameters: Parameters of a custom automation script.  
               Multiple parameters are separated by space.
               The following predefined system parameters can be transferred:
               + **${mrs_scale_node_num}**: Number of the nodes to be added or removed.
               + **${mrs_scale_type}**: Scaling type. The value can be **scale_out** or **scale_in**.
               + **${mrs_scale_node_hostnames}**: Host names of the nodes to be added or removed.
               + **${mrs_scale_node_ips}**: IP addresses of the nodes to be added or removed.
               + **${mrs_scale_rule_name}**: Name of the rule that triggers auto scaling.
               
               Other user-defined parameters are used in the same way as those of common shell scripts. Parameters are separated by space.
        """
        pulumi.set(__self__, "action_stage", action_stage)
        pulumi.set(__self__, "fail_action", fail_action)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "nodes", nodes)
        pulumi.set(__self__, "uri", uri)
        if active_master is not None:
            pulumi.set(__self__, "active_master", active_master)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @_builtins.property
    @pulumi.getter(name="actionStage")
    def action_stage(self) -> _builtins.str:
        """
        Time when a script is executed.  
        The following options are supported:
        + **before_scale_out**: before scale-out.
        + **before_scale_in**: before scale-in.
        + **after_scale_out**: after scale-out.
        + **after_scale_in**: after scale-in.
        """
        return pulumi.get(self, "action_stage")

    @_builtins.property
    @pulumi.getter(name="failAction")
    def fail_action(self) -> _builtins.str:
        """
        Whether to continue to execute subsequent scripts and create a cluster after
        the custom automation script fails to be executed.
        The following options are supported:
        + **continue**: Continue to execute subsequent scripts.
        + **errorout**: Stop the action.

        > You are advised to set this parameter to **continue** in the commissioning phase so that the cluster
        can continue to be installed and started no matter whether the custom automation script is executed successfully.
        The scale-in operation cannot be undone. Therefore, `fail_action` must be set to **continue** for the
        scripts that are executed after scale-in.
        """
        return pulumi.get(self, "fail_action")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Name of a custom automation script.  
        The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
        Script names must be unique in a node group.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def nodes(self) -> Sequence[_builtins.str]:
        """
        Type of a node where the custom automation script is executed.  
        The node type can be **Master**, **Core**, or **Task**.
        """
        return pulumi.get(self, "nodes")

    @_builtins.property
    @pulumi.getter
    def uri(self) -> _builtins.str:
        """
        Path of a custom automation script.  
        Set this parameter to an OBS bucket path or a local VM path.
        OBS bucket path: Enter a script path manually. for example, s3a://XXX/scale.sh.
        Local VM path: Enter a script path. The script path must start with a slash (/) and end with .sh.
        """
        return pulumi.get(self, "uri")

    @_builtins.property
    @pulumi.getter(name="activeMaster")
    def active_master(self) -> Optional[_builtins.bool]:
        """
        Whether the custom automation script runs only on the active Master node.  
        The default value is **false**, indicating that the custom automation script can run on all Master nodes.
        """
        return pulumi.get(self, "active_master")

    @_builtins.property
    @pulumi.getter
    def parameters(self) -> Optional[_builtins.str]:
        """
        Parameters of a custom automation script.  
        Multiple parameters are separated by space.
        The following predefined system parameters can be transferred:
        + **${mrs_scale_node_num}**: Number of the nodes to be added or removed.
        + **${mrs_scale_type}**: Scaling type. The value can be **scale_out** or **scale_in**.
        + **${mrs_scale_node_hostnames}**: Host names of the nodes to be added or removed.
        + **${mrs_scale_node_ips}**: IP addresses of the nodes to be added or removed.
        + **${mrs_scale_rule_name}**: Name of the rule that triggers auto scaling.

        Other user-defined parameters are used in the same way as those of common shell scripts. Parameters are separated by space.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class ScalingPolicyResourcesPlan(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endTime":
            suggest = "end_time"
        elif key == "maxCapacity":
            suggest = "max_capacity"
        elif key == "minCapacity":
            suggest = "min_capacity"
        elif key == "periodType":
            suggest = "period_type"
        elif key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ScalingPolicyResourcesPlan. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ScalingPolicyResourcesPlan.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ScalingPolicyResourcesPlan.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 end_time: _builtins.str,
                 max_capacity: _builtins.int,
                 min_capacity: _builtins.int,
                 period_type: _builtins.str,
                 start_time: _builtins.str):
        """
        :param _builtins.str end_time: End time of a resource plan.  
               The value is in the format of **hour:minute**.
               The interval between end_time and start_time must be greater than or equal to 30 minutes.
        :param _builtins.int max_capacity: Maximum number of the preserved nodes in a node group in a resource plan.
               Value range: 0 to 500.
               
               <a name="ScalingPolicy_Rule"></a>
               The `rules` block supports:
        :param _builtins.int min_capacity: Minimum number of the preserved nodes in a node group in a resource plan.
               Value range: 0 to 500.
        :param _builtins.str period_type: Cycle type of a resource plan.  
               Currently, only the following cycle type is supported: **daily**.
        :param _builtins.str start_time: The start time of a resource plan.  
               The value is in the format of **hour:minute**, indicating that the time ranges from 00:00 to 23:59.
        """
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "max_capacity", max_capacity)
        pulumi.set(__self__, "min_capacity", min_capacity)
        pulumi.set(__self__, "period_type", period_type)
        pulumi.set(__self__, "start_time", start_time)

    @_builtins.property
    @pulumi.getter(name="endTime")
    def end_time(self) -> _builtins.str:
        """
        End time of a resource plan.  
        The value is in the format of **hour:minute**.
        The interval between end_time and start_time must be greater than or equal to 30 minutes.
        """
        return pulumi.get(self, "end_time")

    @_builtins.property
    @pulumi.getter(name="maxCapacity")
    def max_capacity(self) -> _builtins.int:
        """
        Maximum number of the preserved nodes in a node group in a resource plan.
        Value range: 0 to 500.

        <a name="ScalingPolicy_Rule"></a>
        The `rules` block supports:
        """
        return pulumi.get(self, "max_capacity")

    @_builtins.property
    @pulumi.getter(name="minCapacity")
    def min_capacity(self) -> _builtins.int:
        """
        Minimum number of the preserved nodes in a node group in a resource plan.
        Value range: 0 to 500.
        """
        return pulumi.get(self, "min_capacity")

    @_builtins.property
    @pulumi.getter(name="periodType")
    def period_type(self) -> _builtins.str:
        """
        Cycle type of a resource plan.  
        Currently, only the following cycle type is supported: **daily**.
        """
        return pulumi.get(self, "period_type")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        """
        The start time of a resource plan.  
        The value is in the format of **hour:minute**, indicating that the time ranges from 00:00 to 23:59.
        """
        return pulumi.get(self, "start_time")


@pulumi.output_type
class ScalingPolicyRule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adjustmentType":
            suggest = "adjustment_type"
        elif key == "coolDownMinutes":
            suggest = "cool_down_minutes"
        elif key == "scalingAdjustment":
            suggest = "scaling_adjustment"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ScalingPolicyRule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ScalingPolicyRule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ScalingPolicyRule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 adjustment_type: _builtins.str,
                 cool_down_minutes: _builtins.int,
                 name: _builtins.str,
                 scaling_adjustment: _builtins.int,
                 trigger: 'outputs.ScalingPolicyRuleTrigger',
                 description: Optional[_builtins.str] = None):
        """
        :param _builtins.str adjustment_type: Auto scaling rule adjustment type.  
               The following options are supported:
               + **scale_out**: cluster scale-out.
               + **scale_in**: cluster scale-in.
        :param _builtins.int cool_down_minutes: Cluster cooling time after an auto scaling rule is triggered,
               when no auto scaling operation is performed.
               The unit is minute. Value range: 0 to 10,080. One week is equal to 10,080 minutes.
        :param _builtins.str name: Name of a custom automation script.  
               The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
               Script names must be unique in a node group.
        :param _builtins.int scaling_adjustment: Number of nodes that can be adjusted once. Value range: 1 to 100.
        :param 'ScalingPolicyRuleTriggerArgs' trigger: Condition for triggering a rule.  
               The trigger structure is documented below.
        :param _builtins.str description: Description about an auto scaling rule.  
               It contains a maximum of 1,024 characters.
               
               <a name="ScalingPolicy_Trigger"></a>
               The `trigger` block supports:
        """
        pulumi.set(__self__, "adjustment_type", adjustment_type)
        pulumi.set(__self__, "cool_down_minutes", cool_down_minutes)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "scaling_adjustment", scaling_adjustment)
        pulumi.set(__self__, "trigger", trigger)
        if description is not None:
            pulumi.set(__self__, "description", description)

    @_builtins.property
    @pulumi.getter(name="adjustmentType")
    def adjustment_type(self) -> _builtins.str:
        """
        Auto scaling rule adjustment type.  
        The following options are supported:
        + **scale_out**: cluster scale-out.
        + **scale_in**: cluster scale-in.
        """
        return pulumi.get(self, "adjustment_type")

    @_builtins.property
    @pulumi.getter(name="coolDownMinutes")
    def cool_down_minutes(self) -> _builtins.int:
        """
        Cluster cooling time after an auto scaling rule is triggered,
        when no auto scaling operation is performed.
        The unit is minute. Value range: 0 to 10,080. One week is equal to 10,080 minutes.
        """
        return pulumi.get(self, "cool_down_minutes")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Name of a custom automation script.  
        The name can contain only 1 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are allowed.
        Script names must be unique in a node group.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="scalingAdjustment")
    def scaling_adjustment(self) -> _builtins.int:
        """
        Number of nodes that can be adjusted once. Value range: 1 to 100.
        """
        return pulumi.get(self, "scaling_adjustment")

    @_builtins.property
    @pulumi.getter
    def trigger(self) -> 'outputs.ScalingPolicyRuleTrigger':
        """
        Condition for triggering a rule.  
        The trigger structure is documented below.
        """
        return pulumi.get(self, "trigger")

    @_builtins.property
    @pulumi.getter
    def description(self) -> Optional[_builtins.str]:
        """
        Description about an auto scaling rule.  
        It contains a maximum of 1,024 characters.

        <a name="ScalingPolicy_Trigger"></a>
        The `trigger` block supports:
        """
        return pulumi.get(self, "description")


@pulumi.output_type
class ScalingPolicyRuleTrigger(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "evaluationPeriods":
            suggest = "evaluation_periods"
        elif key == "metricName":
            suggest = "metric_name"
        elif key == "metricValue":
            suggest = "metric_value"
        elif key == "comparisonOperator":
            suggest = "comparison_operator"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ScalingPolicyRuleTrigger. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ScalingPolicyRuleTrigger.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ScalingPolicyRuleTrigger.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 evaluation_periods: _builtins.int,
                 metric_name: _builtins.str,
                 metric_value: _builtins.str,
                 comparison_operator: Optional[_builtins.str] = None):
        """
        :param _builtins.int evaluation_periods: Number of consecutive five-minute periods,
               during which a metric threshold is reached.
               Value range: 1 to 288.
               
               <a name="ScalingPolicy_ExecScript"></a>
               The `exec_scripts` block supports:
        :param _builtins.str metric_name: Metric name.  
               This triggering condition makes a judgment according to the value of the metric.
               A metric name contains a maximum of 64 characters.
               For details about metric names, see [Configuring Auto Scaling for an MRS Cluster](https://support.huaweicloud.com/intl/en-us/qs-mrs/mrs_09_0005.html).
        :param _builtins.str metric_value: Metric threshold to trigger a rule.  
               The parameter value can only be an integer or number with two decimal places.
               The value type and range must correspond to the metric_name.
        :param _builtins.str comparison_operator: Metric judgment logic operator.  
               The following options are supported:
               + **LT**: less than.
               + **GT**: greater than.
               + **LTOE**: less than or equal to.
               + **GTOE**: greater than or equal to.
        """
        pulumi.set(__self__, "evaluation_periods", evaluation_periods)
        pulumi.set(__self__, "metric_name", metric_name)
        pulumi.set(__self__, "metric_value", metric_value)
        if comparison_operator is not None:
            pulumi.set(__self__, "comparison_operator", comparison_operator)

    @_builtins.property
    @pulumi.getter(name="evaluationPeriods")
    def evaluation_periods(self) -> _builtins.int:
        """
        Number of consecutive five-minute periods,
        during which a metric threshold is reached.
        Value range: 1 to 288.

        <a name="ScalingPolicy_ExecScript"></a>
        The `exec_scripts` block supports:
        """
        return pulumi.get(self, "evaluation_periods")

    @_builtins.property
    @pulumi.getter(name="metricName")
    def metric_name(self) -> _builtins.str:
        """
        Metric name.  
        This triggering condition makes a judgment according to the value of the metric.
        A metric name contains a maximum of 64 characters.
        For details about metric names, see [Configuring Auto Scaling for an MRS Cluster](https://support.huaweicloud.com/intl/en-us/qs-mrs/mrs_09_0005.html).
        """
        return pulumi.get(self, "metric_name")

    @_builtins.property
    @pulumi.getter(name="metricValue")
    def metric_value(self) -> _builtins.str:
        """
        Metric threshold to trigger a rule.  
        The parameter value can only be an integer or number with two decimal places.
        The value type and range must correspond to the metric_name.
        """
        return pulumi.get(self, "metric_value")

    @_builtins.property
    @pulumi.getter(name="comparisonOperator")
    def comparison_operator(self) -> Optional[_builtins.str]:
        """
        Metric judgment logic operator.  
        The following options are supported:
        + **LT**: less than.
        + **GT**: greater than.
        + **LTOE**: less than or equal to.
        + **GTOE**: greater than or equal to.
        """
        return pulumi.get(self, "comparison_operator")


@pulumi.output_type
class ClusterAnalysisCoreNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataVolumeCount":
            suggest = "data_volume_count"
        elif key == "nodeNumber":
            suggest = "node_number"
        elif key == "rootVolumeSize":
            suggest = "root_volume_size"
        elif key == "rootVolumeType":
            suggest = "root_volume_type"
        elif key == "assignedRoles":
            suggest = "assigned_roles"
        elif key == "autoRenew":
            suggest = "auto_renew"
        elif key == "chargingMode":
            suggest = "charging_mode"
        elif key == "dataVolumeSize":
            suggest = "data_volume_size"
        elif key == "dataVolumeType":
            suggest = "data_volume_type"
        elif key == "hostIps":
            suggest = "host_ips"
        elif key == "periodUnit":
            suggest = "period_unit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAnalysisCoreNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAnalysisCoreNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAnalysisCoreNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 flavor: _builtins.str,
                 node_number: _builtins.int,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 assigned_roles: Optional[Sequence[_builtins.str]] = None,
                 auto_renew: Optional[_builtins.str] = None,
                 charging_mode: Optional[_builtins.str] = None,
                 data_volume_size: Optional[_builtins.int] = None,
                 data_volume_type: Optional[_builtins.str] = None,
                 host_ips: Optional[Sequence[_builtins.str]] = None,
                 period: Optional[_builtins.int] = None,
                 period_unit: Optional[_builtins.str] = None):
        """
        :param _builtins.int data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param _builtins.str root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param Sequence[_builtins.str] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param _builtins.str auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param _builtins.str charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.int data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param _builtins.str data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param Sequence[_builtins.str] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param _builtins.int period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.str period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> _builtins.str:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> _builtins.int:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[Sequence[_builtins.str]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[_builtins.str]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[_builtins.str]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[_builtins.int]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[_builtins.str]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[Sequence[_builtins.str]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[_builtins.int]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[_builtins.str]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")


@pulumi.output_type
class ClusterAnalysisTaskNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataVolumeCount":
            suggest = "data_volume_count"
        elif key == "nodeNumber":
            suggest = "node_number"
        elif key == "rootVolumeSize":
            suggest = "root_volume_size"
        elif key == "rootVolumeType":
            suggest = "root_volume_type"
        elif key == "assignedRoles":
            suggest = "assigned_roles"
        elif key == "dataVolumeSize":
            suggest = "data_volume_size"
        elif key == "dataVolumeType":
            suggest = "data_volume_type"
        elif key == "hostIps":
            suggest = "host_ips"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAnalysisTaskNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAnalysisTaskNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAnalysisTaskNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 flavor: _builtins.str,
                 node_number: _builtins.int,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 assigned_roles: Optional[Sequence[_builtins.str]] = None,
                 data_volume_size: Optional[_builtins.int] = None,
                 data_volume_type: Optional[_builtins.str] = None,
                 host_ips: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.int data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param _builtins.str root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param Sequence[_builtins.str] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param _builtins.int data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param _builtins.str data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param Sequence[_builtins.str] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> _builtins.str:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> _builtins.int:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[Sequence[_builtins.str]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[_builtins.int]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[_builtins.str]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[Sequence[_builtins.str]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")


@pulumi.output_type
class ClusterBootstrapScript(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "failAction":
            suggest = "fail_action"
        elif key == "activeMaster":
            suggest = "active_master"
        elif key == "beforeComponentStart":
            suggest = "before_component_start"
        elif key == "executeNeedSudoRoot":
            suggest = "execute_need_sudo_root"
        elif key == "startTime":
            suggest = "start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterBootstrapScript. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterBootstrapScript.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterBootstrapScript.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 fail_action: _builtins.str,
                 name: _builtins.str,
                 nodes: Sequence[_builtins.str],
                 uri: _builtins.str,
                 active_master: Optional[_builtins.bool] = None,
                 before_component_start: Optional[_builtins.bool] = None,
                 execute_need_sudo_root: Optional[_builtins.bool] = None,
                 parameters: Optional[_builtins.str] = None,
                 start_time: Optional[_builtins.str] = None,
                 state: Optional[_builtins.str] = None):
        """
        :param _builtins.str fail_action: Specifies the action after the bootstrap action script fails to be executed.
               The options are as follows:
               + **continue**: Continue to execute subsequent scripts.
               + **errorout**: Stop the action.
               
               The default value is **errorout**, indicating that the action is stopped.
               Changing this will create a new MapReduce cluster resource.
               
               > You are advised to set this parameter to continue in the commissioning phase so that the cluster can
               continue to be installed and started no matter whether the bootstrap action is successful.
        :param _builtins.str name: Specifies the name of a bootstrap action script.
               Changing this will create a new MapReduce cluster resource.
        :param Sequence[_builtins.str] nodes: Specifies names of the node group where the bootstrap action script is executed.
        :param _builtins.str uri: Specifies the path of a bootstrap action script.
               Set this parameter to an OBS bucket path or a local VM path.
               + **OBS bucket path**: The path of an OBS file system starts with *s3a://* or *obs://* and end with *.sh*.
               + **Local VM path**: The script path must start with a slash (/) and end with *.sh*.
               
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.bool active_master: Specifies whether the bootstrap action script runs only on active master nodes.
               The default value is **false**, indicating that the bootstrap action script can run on all master nodes.
        :param _builtins.bool before_component_start: Specifies whether the bootstrap action script is executed
               before component start.
               The options are as follows:
               + **false**: After component start. The default value is **false**.
               + **true**: Before component start.
               
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.bool execute_need_sudo_root: Specifies whether the bootstrap action script involves root user
               operations.
               Changing this will create a new MapReduce cluster resource.
               
               <a name="SMNNotify"></a>
               The `smn_notify` block supports:
        :param _builtins.str parameters: Specifies bootstrap action script parameters.
        :param _builtins.str start_time: The execution time of one bootstrap action script, in RFC-3339 format.
        :param _builtins.str state: The status of one bootstrap action script.
        """
        pulumi.set(__self__, "fail_action", fail_action)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "nodes", nodes)
        pulumi.set(__self__, "uri", uri)
        if active_master is not None:
            pulumi.set(__self__, "active_master", active_master)
        if before_component_start is not None:
            pulumi.set(__self__, "before_component_start", before_component_start)
        if execute_need_sudo_root is not None:
            pulumi.set(__self__, "execute_need_sudo_root", execute_need_sudo_root)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if start_time is not None:
            pulumi.set(__self__, "start_time", start_time)
        if state is not None:
            pulumi.set(__self__, "state", state)

    @_builtins.property
    @pulumi.getter(name="failAction")
    def fail_action(self) -> _builtins.str:
        """
        Specifies the action after the bootstrap action script fails to be executed.
        The options are as follows:
        + **continue**: Continue to execute subsequent scripts.
        + **errorout**: Stop the action.

        The default value is **errorout**, indicating that the action is stopped.
        Changing this will create a new MapReduce cluster resource.

        > You are advised to set this parameter to continue in the commissioning phase so that the cluster can
        continue to be installed and started no matter whether the bootstrap action is successful.
        """
        return pulumi.get(self, "fail_action")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of a bootstrap action script.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def nodes(self) -> Sequence[_builtins.str]:
        """
        Specifies names of the node group where the bootstrap action script is executed.
        """
        return pulumi.get(self, "nodes")

    @_builtins.property
    @pulumi.getter
    def uri(self) -> _builtins.str:
        """
        Specifies the path of a bootstrap action script.
        Set this parameter to an OBS bucket path or a local VM path.
        + **OBS bucket path**: The path of an OBS file system starts with *s3a://* or *obs://* and end with *.sh*.
        + **Local VM path**: The script path must start with a slash (/) and end with *.sh*.

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "uri")

    @_builtins.property
    @pulumi.getter(name="activeMaster")
    def active_master(self) -> Optional[_builtins.bool]:
        """
        Specifies whether the bootstrap action script runs only on active master nodes.
        The default value is **false**, indicating that the bootstrap action script can run on all master nodes.
        """
        return pulumi.get(self, "active_master")

    @_builtins.property
    @pulumi.getter(name="beforeComponentStart")
    def before_component_start(self) -> Optional[_builtins.bool]:
        """
        Specifies whether the bootstrap action script is executed
        before component start.
        The options are as follows:
        + **false**: After component start. The default value is **false**.
        + **true**: Before component start.

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "before_component_start")

    @_builtins.property
    @pulumi.getter(name="executeNeedSudoRoot")
    def execute_need_sudo_root(self) -> Optional[_builtins.bool]:
        """
        Specifies whether the bootstrap action script involves root user
        operations.
        Changing this will create a new MapReduce cluster resource.

        <a name="SMNNotify"></a>
        The `smn_notify` block supports:
        """
        return pulumi.get(self, "execute_need_sudo_root")

    @_builtins.property
    @pulumi.getter
    def parameters(self) -> Optional[_builtins.str]:
        """
        Specifies bootstrap action script parameters.
        """
        return pulumi.get(self, "parameters")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> Optional[_builtins.str]:
        """
        The execution time of one bootstrap action script, in RFC-3339 format.
        """
        return pulumi.get(self, "start_time")

    @_builtins.property
    @pulumi.getter
    def state(self) -> Optional[_builtins.str]:
        """
        The status of one bootstrap action script.
        """
        return pulumi.get(self, "state")


@pulumi.output_type
class ClusterComponentConfig(dict):
    def __init__(__self__, *,
                 configs: Sequence['outputs.ClusterComponentConfigConfig'],
                 name: _builtins.str):
        """
        :param Sequence['ClusterComponentConfigConfigArgs'] configs: Specifies the configuration of component installed.
               The object structure is documented below.
               
               <a name="component_configuration"></a>
               The `configs` block supports:
        :param _builtins.str name: Specifies the name of a bootstrap action script.
               Changing this will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "configs", configs)
        pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter
    def configs(self) -> Sequence['outputs.ClusterComponentConfigConfig']:
        """
        Specifies the configuration of component installed.
        The object structure is documented below.

        <a name="component_configuration"></a>
        The `configs` block supports:
        """
        return pulumi.get(self, "configs")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of a bootstrap action script.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class ClusterComponentConfigConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "configFileName":
            suggest = "config_file_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterComponentConfigConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterComponentConfigConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterComponentConfigConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 config_file_name: _builtins.str,
                 key: _builtins.str,
                 value: _builtins.str):
        """
        :param _builtins.str config_file_name: Specifies the configuration file name of component installed.
               Changing this will create a new MapReduce cluster resource.
               
               <a name="ExternalDatasources"></a>
               The `external_datasources` block supports:
        :param _builtins.str key: Specifies the configuration item key of component installed.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str value: Specifies the configuration item value of component installed.
               Changing this will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "config_file_name", config_file_name)
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter(name="configFileName")
    def config_file_name(self) -> _builtins.str:
        """
        Specifies the configuration file name of component installed.
        Changing this will create a new MapReduce cluster resource.

        <a name="ExternalDatasources"></a>
        The `external_datasources` block supports:
        """
        return pulumi.get(self, "config_file_name")

    @_builtins.property
    @pulumi.getter
    def key(self) -> _builtins.str:
        """
        Specifies the configuration item key of component installed.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "key")

    @_builtins.property
    @pulumi.getter
    def value(self) -> _builtins.str:
        """
        Specifies the configuration item value of component installed.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ClusterCustomNode(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataVolumeCount":
            suggest = "data_volume_count"
        elif key == "groupName":
            suggest = "group_name"
        elif key == "nodeNumber":
            suggest = "node_number"
        elif key == "rootVolumeSize":
            suggest = "root_volume_size"
        elif key == "rootVolumeType":
            suggest = "root_volume_type"
        elif key == "assignedRoles":
            suggest = "assigned_roles"
        elif key == "autoRenew":
            suggest = "auto_renew"
        elif key == "chargingMode":
            suggest = "charging_mode"
        elif key == "dataVolumeSize":
            suggest = "data_volume_size"
        elif key == "dataVolumeType":
            suggest = "data_volume_type"
        elif key == "hostIps":
            suggest = "host_ips"
        elif key == "periodUnit":
            suggest = "period_unit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterCustomNode. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterCustomNode.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterCustomNode.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 flavor: _builtins.str,
                 group_name: _builtins.str,
                 node_number: _builtins.int,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 assigned_roles: Optional[Sequence[_builtins.str]] = None,
                 auto_renew: Optional[_builtins.str] = None,
                 charging_mode: Optional[_builtins.str] = None,
                 data_volume_size: Optional[_builtins.int] = None,
                 data_volume_type: Optional[_builtins.str] = None,
                 host_ips: Optional[Sequence[_builtins.str]] = None,
                 period: Optional[_builtins.int] = None,
                 period_unit: Optional[_builtins.str] = None):
        """
        :param _builtins.int data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str group_name: Specifies the name of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param _builtins.str root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param Sequence[_builtins.str] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param _builtins.str auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param _builtins.str charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.int data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param _builtins.str data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param Sequence[_builtins.str] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param _builtins.int period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.str period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "group_name", group_name)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> _builtins.str:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @_builtins.property
    @pulumi.getter(name="groupName")
    def group_name(self) -> _builtins.str:
        """
        Specifies the name of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "group_name")

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> _builtins.int:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[Sequence[_builtins.str]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[_builtins.str]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[_builtins.str]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[_builtins.int]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[_builtins.str]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[Sequence[_builtins.str]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[_builtins.int]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[_builtins.str]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")


@pulumi.output_type
class ClusterExternalDatasource(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "componentName":
            suggest = "component_name"
        elif key == "roleType":
            suggest = "role_type"
        elif key == "sourceType":
            suggest = "source_type"
        elif key == "dataConnectionId":
            suggest = "data_connection_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterExternalDatasource. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterExternalDatasource.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterExternalDatasource.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component_name: _builtins.str,
                 role_type: _builtins.str,
                 source_type: _builtins.str,
                 data_connection_id: Optional[_builtins.str] = None):
        """
        :param _builtins.str component_name: Specifies the component name. The valid values are `Hive` and `Ranger`.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str role_type: Specifies the component role type.
               The options are as follows:
               + **hive_metastore**: Hive Metastore role.
               + **ranger_data**: Ranger role.
               
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str source_type: Specifies the data connection type.
               The options are as follows:
               + **LOCAL_DB**: Local metadata.
               + **RDS_POSTGRES**: RDS PostgreSQL database.
               + **RDS_MYSQL**: RDS MySQL database.
               + **gaussdb-mysql**: GaussDB(for MySQL).
               
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str data_connection_id: Specifies the data connection ID.
               This parameter is mandatory if `source_type` is not **LOCAL_DB**.
               Changing this will create a new MapReduce cluster resource.
               
               <a name="BootstrapScripts"></a>
               The `bootstrap_scripts` block supports:
        """
        pulumi.set(__self__, "component_name", component_name)
        pulumi.set(__self__, "role_type", role_type)
        pulumi.set(__self__, "source_type", source_type)
        if data_connection_id is not None:
            pulumi.set(__self__, "data_connection_id", data_connection_id)

    @_builtins.property
    @pulumi.getter(name="componentName")
    def component_name(self) -> _builtins.str:
        """
        Specifies the component name. The valid values are `Hive` and `Ranger`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "component_name")

    @_builtins.property
    @pulumi.getter(name="roleType")
    def role_type(self) -> _builtins.str:
        """
        Specifies the component role type.
        The options are as follows:
        + **hive_metastore**: Hive Metastore role.
        + **ranger_data**: Ranger role.

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "role_type")

    @_builtins.property
    @pulumi.getter(name="sourceType")
    def source_type(self) -> _builtins.str:
        """
        Specifies the data connection type.
        The options are as follows:
        + **LOCAL_DB**: Local metadata.
        + **RDS_POSTGRES**: RDS PostgreSQL database.
        + **RDS_MYSQL**: RDS MySQL database.
        + **gaussdb-mysql**: GaussDB(for MySQL).

        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "source_type")

    @_builtins.property
    @pulumi.getter(name="dataConnectionId")
    def data_connection_id(self) -> Optional[_builtins.str]:
        """
        Specifies the data connection ID.
        This parameter is mandatory if `source_type` is not **LOCAL_DB**.
        Changing this will create a new MapReduce cluster resource.

        <a name="BootstrapScripts"></a>
        The `bootstrap_scripts` block supports:
        """
        return pulumi.get(self, "data_connection_id")


@pulumi.output_type
class ClusterMasterNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataVolumeCount":
            suggest = "data_volume_count"
        elif key == "nodeNumber":
            suggest = "node_number"
        elif key == "rootVolumeSize":
            suggest = "root_volume_size"
        elif key == "rootVolumeType":
            suggest = "root_volume_type"
        elif key == "assignedRoles":
            suggest = "assigned_roles"
        elif key == "autoRenew":
            suggest = "auto_renew"
        elif key == "chargingMode":
            suggest = "charging_mode"
        elif key == "dataVolumeSize":
            suggest = "data_volume_size"
        elif key == "dataVolumeType":
            suggest = "data_volume_type"
        elif key == "hostIps":
            suggest = "host_ips"
        elif key == "periodUnit":
            suggest = "period_unit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterMasterNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterMasterNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterMasterNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 flavor: _builtins.str,
                 node_number: _builtins.int,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 assigned_roles: Optional[Sequence[_builtins.str]] = None,
                 auto_renew: Optional[_builtins.str] = None,
                 charging_mode: Optional[_builtins.str] = None,
                 data_volume_size: Optional[_builtins.int] = None,
                 data_volume_type: Optional[_builtins.str] = None,
                 host_ips: Optional[Sequence[_builtins.str]] = None,
                 period: Optional[_builtins.int] = None,
                 period_unit: Optional[_builtins.str] = None):
        """
        :param _builtins.int data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param _builtins.str root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param Sequence[_builtins.str] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param _builtins.str auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param _builtins.str charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.int data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param _builtins.str data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param Sequence[_builtins.str] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param _builtins.int period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.str period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> _builtins.str:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> _builtins.int:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[Sequence[_builtins.str]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[_builtins.str]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[_builtins.str]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[_builtins.int]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[_builtins.str]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[Sequence[_builtins.str]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[_builtins.int]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[_builtins.str]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")


@pulumi.output_type
class ClusterSmnNotify(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "subscriptionName":
            suggest = "subscription_name"
        elif key == "topicUrn":
            suggest = "topic_urn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterSmnNotify. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterSmnNotify.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterSmnNotify.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 subscription_name: _builtins.str,
                 topic_urn: _builtins.str):
        """
        :param _builtins.str subscription_name: Specifies the subscription rule name.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str topic_urn: Specifies the Uniform Resource Name (URN) of the topic.
               Changing this will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "subscription_name", subscription_name)
        pulumi.set(__self__, "topic_urn", topic_urn)

    @_builtins.property
    @pulumi.getter(name="subscriptionName")
    def subscription_name(self) -> _builtins.str:
        """
        Specifies the subscription rule name.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "subscription_name")

    @_builtins.property
    @pulumi.getter(name="topicUrn")
    def topic_urn(self) -> _builtins.str:
        """
        Specifies the Uniform Resource Name (URN) of the topic.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "topic_urn")


@pulumi.output_type
class ClusterStreamingCoreNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataVolumeCount":
            suggest = "data_volume_count"
        elif key == "nodeNumber":
            suggest = "node_number"
        elif key == "rootVolumeSize":
            suggest = "root_volume_size"
        elif key == "rootVolumeType":
            suggest = "root_volume_type"
        elif key == "assignedRoles":
            suggest = "assigned_roles"
        elif key == "autoRenew":
            suggest = "auto_renew"
        elif key == "chargingMode":
            suggest = "charging_mode"
        elif key == "dataVolumeSize":
            suggest = "data_volume_size"
        elif key == "dataVolumeType":
            suggest = "data_volume_type"
        elif key == "hostIps":
            suggest = "host_ips"
        elif key == "periodUnit":
            suggest = "period_unit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterStreamingCoreNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterStreamingCoreNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterStreamingCoreNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 flavor: _builtins.str,
                 node_number: _builtins.int,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 assigned_roles: Optional[Sequence[_builtins.str]] = None,
                 auto_renew: Optional[_builtins.str] = None,
                 charging_mode: Optional[_builtins.str] = None,
                 data_volume_size: Optional[_builtins.int] = None,
                 data_volume_type: Optional[_builtins.str] = None,
                 host_ips: Optional[Sequence[_builtins.str]] = None,
                 period: Optional[_builtins.int] = None,
                 period_unit: Optional[_builtins.str] = None):
        """
        :param _builtins.int data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param _builtins.str root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param Sequence[_builtins.str] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param _builtins.str auto_renew: Specifies whether auto renew is enabled, defaults to **false**.  
               This parameter is available if `charging_mode` is set to **prePaid**.
               The valid values are **true** and **false**.
               
               > The `period_unit` must be used together with the `period` parameter.
               
               <a name="component_configurations"></a>
               The `component_configs` block supports:
        :param _builtins.str charging_mode: Specifies the charging mode of the cluster.  
               Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.int data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param _builtins.str data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param Sequence[_builtins.str] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        :param _builtins.int period: Specifies the charging period of the cluster.  
               If `period_unit` is set to **month**, the value ranges from `1` to `9`.
               If `period_unit` is set to **year**, the value ranges from `1` to `3`.
               This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        :param _builtins.str period_unit: Specifies the charging period unit of the cluster.  
               Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
               Changing this parameter will create a new MapReduce cluster resource.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if auto_renew is not None:
            pulumi.set(__self__, "auto_renew", auto_renew)
        if charging_mode is not None:
            pulumi.set(__self__, "charging_mode", charging_mode)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)
        if period is not None:
            pulumi.set(__self__, "period", period)
        if period_unit is not None:
            pulumi.set(__self__, "period_unit", period_unit)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> _builtins.str:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> _builtins.int:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[Sequence[_builtins.str]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @_builtins.property
    @pulumi.getter(name="autoRenew")
    def auto_renew(self) -> Optional[_builtins.str]:
        """
        Specifies whether auto renew is enabled, defaults to **false**.  
        This parameter is available if `charging_mode` is set to **prePaid**.
        The valid values are **true** and **false**.

        > The `period_unit` must be used together with the `period` parameter.

        <a name="component_configurations"></a>
        The `component_configs` block supports:
        """
        return pulumi.get(self, "auto_renew")

    @_builtins.property
    @pulumi.getter(name="chargingMode")
    def charging_mode(self) -> Optional[_builtins.str]:
        """
        Specifies the charging mode of the cluster.  
        Valid values are **prePaid** and **postPaid**, defaults to **postPaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "charging_mode")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[_builtins.int]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[_builtins.str]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[Sequence[_builtins.str]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")

    @_builtins.property
    @pulumi.getter
    def period(self) -> Optional[_builtins.int]:
        """
        Specifies the charging period of the cluster.  
        If `period_unit` is set to **month**, the value ranges from `1` to `9`.
        If `period_unit` is set to **year**, the value ranges from `1` to `3`.
        This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period")

    @_builtins.property
    @pulumi.getter(name="periodUnit")
    def period_unit(self) -> Optional[_builtins.str]:
        """
        Specifies the charging period unit of the cluster.  
        Valid values are **month** and **year**. This parameter is mandatory if `charging_mode` is set to **prePaid**.
        Changing this parameter will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "period_unit")


@pulumi.output_type
class ClusterStreamingTaskNodes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataVolumeCount":
            suggest = "data_volume_count"
        elif key == "nodeNumber":
            suggest = "node_number"
        elif key == "rootVolumeSize":
            suggest = "root_volume_size"
        elif key == "rootVolumeType":
            suggest = "root_volume_type"
        elif key == "assignedRoles":
            suggest = "assigned_roles"
        elif key == "dataVolumeSize":
            suggest = "data_volume_size"
        elif key == "dataVolumeType":
            suggest = "data_volume_type"
        elif key == "hostIps":
            suggest = "host_ips"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterStreamingTaskNodes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterStreamingTaskNodes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterStreamingTaskNodes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 flavor: _builtins.str,
                 node_number: _builtins.int,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 assigned_roles: Optional[Sequence[_builtins.str]] = None,
                 data_volume_size: Optional[_builtins.int] = None,
                 data_volume_type: Optional[_builtins.str] = None,
                 host_ips: Optional[Sequence[_builtins.str]] = None):
        """
        :param _builtins.int data_volume_count: Specifies the data disk number of the nodes.  
               The valid value is `1`.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.str flavor: Specifies the instance specifications for each nodes in node group.
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int node_number: Specifies the number of nodes for the node group.  
               Changing this will create a new MapReduce cluster resource.
        :param _builtins.int root_volume_size: Specifies the system disk size of the nodes. Changing this will create
               a new MapReduce cluster resource.
        :param _builtins.str root_volume_type: Specifies the system disk flavor of the nodes. Changing this will
               create a new MapReduce cluster resource.
        :param Sequence[_builtins.str] assigned_roles: Specifies the roles deployed in a node group.This argument is mandatory
               when the cluster type is **CUSTOM**. Each character string represents a role expression.
               
               **Role expression definition:**
               
               + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
               + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
               for example: `DataNode:1,2`. The subscript starts from 1.
               + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
               role_name[instance_count], for example: `EsNode[9]`.
               
               [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)
               
               [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)
               
               > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
               store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        :param _builtins.int data_volume_size: Specifies the data disk size of the nodes,in GB. The value range is 10
               to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
               cluster resource.
        :param _builtins.str data_volume_type: Specifies the data disk flavor of the nodes.
               Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
               The following disk types are supported:
               + **SATA**: common I/O disk.
               + **SAS**: high I/O disk.
               + **SSD**: ultra-high I/O disk.
        :param Sequence[_builtins.str] host_ips: The host list of this nodes group in the cluster.
               * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
               * `bootstrap_scripts/state` - The status of one bootstrap action script.
               The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "flavor", flavor)
        pulumi.set(__self__, "node_number", node_number)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        if assigned_roles is not None:
            pulumi.set(__self__, "assigned_roles", assigned_roles)
        if data_volume_size is not None:
            pulumi.set(__self__, "data_volume_size", data_volume_size)
        if data_volume_type is not None:
            pulumi.set(__self__, "data_volume_type", data_volume_type)
        if host_ips is not None:
            pulumi.set(__self__, "host_ips", host_ips)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Specifies the data disk number of the nodes.  
        The valid value is `1`.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter
    def flavor(self) -> _builtins.str:
        """
        Specifies the instance specifications for each nodes in node group.
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "flavor")

    @_builtins.property
    @pulumi.getter(name="nodeNumber")
    def node_number(self) -> _builtins.int:
        """
        Specifies the number of nodes for the node group.  
        Changing this will create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "node_number")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Specifies the system disk size of the nodes. Changing this will create
        a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Specifies the system disk flavor of the nodes. Changing this will
        create a new MapReduce cluster resource.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="assignedRoles")
    def assigned_roles(self) -> Optional[Sequence[_builtins.str]]:
        """
        Specifies the roles deployed in a node group.This argument is mandatory
        when the cluster type is **CUSTOM**. Each character string represents a role expression.

        **Role expression definition:**

        + If the role is deployed on all nodes in the node group, set this parameter to role_name, for example: `DataNode`.
        + If the role is deployed on a specified subscript node in the node group: role_name:index1,index2..., indexN,
        for example: `DataNode:1,2`. The subscript starts from 1.
        + Some roles support multi-instance deployment (that is, multiple instances of the same role are deployed on a node):
        role_name[instance_count], for example: `EsNode[9]`.

        [For details about components](https://support.huaweicloud.com/intl/en-us/productdesc-mrs/mrs_08_0005.html)

        [Mapping between roles and components](https://support.huaweicloud.com/intl/en-us/api-mrs/mrs_02_0106.html)

        > `DBService` is a basic component of a cluster. Components such as Hive, Hue, Oozie, Loader, and Redis, and Loader
        store their metadata in DBService, and provide the metadata backup and restoration functions by using DBService.
        """
        return pulumi.get(self, "assigned_roles")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> Optional[_builtins.int]:
        """
        Specifies the data disk size of the nodes,in GB. The value range is 10
        to 32768. Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce
        cluster resource.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> Optional[_builtins.str]:
        """
        Specifies the data disk flavor of the nodes.
        Required if `data_volume_count` is greater than zero. Changing this will create a new MapReduce cluster resource.
        The following disk types are supported:
        + **SATA**: common I/O disk.
        + **SAS**: high I/O disk.
        + **SSD**: ultra-high I/O disk.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="hostIps")
    def host_ips(self) -> Optional[Sequence[_builtins.str]]:
        """
        The host list of this nodes group in the cluster.
        * `bootstrap_scripts/start_time` - The execution time of one bootstrap action script, in RFC-3339 format.
        * `bootstrap_scripts/state` - The status of one bootstrap action script.
        The valid value are **PENDING**, **IN_PROGRESS**, **SUCCESS**, and **FAILURE**.
        """
        return pulumi.get(self, "host_ips")


@pulumi.output_type
class GetClustersClusterResult(dict):
    def __init__(__self__, *,
                 availability_zone: _builtins.str,
                 billing_type: _builtins.str,
                 component_lists: Sequence['outputs.GetClustersClusterComponentListResult'],
                 core_data_volume_count: _builtins.int,
                 core_data_volume_size: _builtins.int,
                 core_data_volume_type: _builtins.str,
                 core_node_num: _builtins.str,
                 core_node_product_id: _builtins.str,
                 core_node_size: _builtins.str,
                 core_node_spec_id: _builtins.str,
                 deployment_id: _builtins.str,
                 description: _builtins.str,
                 duration: _builtins.str,
                 eip_address: _builtins.str,
                 eip_id: _builtins.str,
                 eipv6_address: _builtins.str,
                 enterprise_project_id: _builtins.str,
                 external_alternate_ip: _builtins.str,
                 external_ip: _builtins.str,
                 fee: _builtins.str,
                 hadoop_version: _builtins.str,
                 id: _builtins.str,
                 internal_ip: _builtins.str,
                 log_collection: _builtins.int,
                 master_data_volume_count: _builtins.int,
                 master_data_volume_size: _builtins.int,
                 master_data_volume_type: _builtins.str,
                 master_node_ip: _builtins.str,
                 master_node_num: _builtins.str,
                 master_node_product_id: _builtins.str,
                 master_node_size: _builtins.str,
                 master_node_spec_id: _builtins.str,
                 name: _builtins.str,
                 node_groups: Sequence['outputs.GetClustersClusterNodeGroupResult'],
                 node_public_cert_name: _builtins.str,
                 order_id: _builtins.str,
                 period_type: _builtins.int,
                 private_ip_first: _builtins.str,
                 safe_mode: _builtins.int,
                 scale: _builtins.str,
                 security_group_id: _builtins.str,
                 slave_security_group_id: _builtins.str,
                 stage_desc: _builtins.str,
                 status: _builtins.str,
                 subnet_id: _builtins.str,
                 tags: Mapping[str, _builtins.str],
                 task_node_groups: Sequence['outputs.GetClustersClusterTaskNodeGroupResult'],
                 total_node_num: _builtins.str,
                 type: _builtins.int,
                 version: _builtins.str,
                 vnc: _builtins.str,
                 volume_size: _builtins.int,
                 volume_type: _builtins.str,
                 vpc_id: _builtins.str):
        """
        :param _builtins.str availability_zone: The AZ.
        :param _builtins.str billing_type: Cluster billing mode.  
               The following options are supported:
               + **11**: Yearly/Monthly.
               + **12**: Pay-per-use.
        :param Sequence['GetClustersClusterComponentListArgs'] component_lists: Component list.
               The component_list structure is documented below.
        :param _builtins.int core_data_volume_count: Number of data disks of the Core node.
        :param _builtins.int core_data_volume_size: Data disk storage space of the Core node.  
               To increase data storage capacity, you can add disks at the same time when creating a cluster.
               Value range: 100 GB to 32,000 GB
        :param _builtins.str core_data_volume_type: Data disk storage type of the Core node.  
               Currently, **SATA**, **SAS**, and **SSD** are supported.
        :param _builtins.str core_node_num: Number of Core nodes deployed in a cluster.
        :param _builtins.str core_node_product_id: Product ID of a Core node.
        :param _builtins.str core_node_size: Instance specifications of a Core node.
        :param _builtins.str core_node_spec_id: Specification ID of a Core node.
        :param _builtins.str deployment_id: Cluster deployment ID.
        :param _builtins.str description: Cluster description.
        :param _builtins.str duration: Cluster subscription duration.
        :param _builtins.str eip_address: IPv4 address of the cluster EIP.
        :param _builtins.str eip_id: Unique ID of the cluster EIP.
        :param _builtins.str eipv6_address: IPv6 address of the cluster EIP.  
               This parameter is not returned when an IPv4 address is used.
        :param _builtins.str enterprise_project_id: The enterprise project ID used to query clusters in a specified
               enterprise project.
               The default value is **0**, indicating the default enterprise project.
        :param _builtins.str external_alternate_ip: Backup external IP address.
        :param _builtins.str external_ip: External IP address.
        :param _builtins.str fee: Cluster creation fee, which is automatically calculated.
        :param _builtins.str hadoop_version: Hadoop version.
        :param _builtins.str id: Cluster ID.
        :param _builtins.str internal_ip: Internal IP address.
        :param _builtins.int log_collection: Whether to collect logs when cluster installation fails.  
               The following options are supported:
               + **0**: Do not collect logs.
               + **1**: Collect logs.
        :param _builtins.int master_data_volume_count: Number of data disks of the Master node  
               The value can be set to 1 only.
        :param _builtins.int master_data_volume_size: Data disk storage space of the Master node  
               To increase data storage capacity, you can add disks at the same time when creating a cluster.
               Value range: 100 GB to 32,000 GB
        :param _builtins.str master_data_volume_type: Data disk storage type of the Master node.  
               Currently, **SATA**, **SAS**, and **SSD** are supported.
        :param _builtins.str master_node_ip: IP address of a Master node.
        :param _builtins.str master_node_num: Number of Master nodes deployed in a cluster.
        :param _builtins.str master_node_product_id: Product ID of a Master node.
        :param _builtins.str master_node_size: Instance specifications of a Master node.
        :param _builtins.str master_node_spec_id: Specification ID of a Master node.
        :param _builtins.str name: The name of cluster.
        :param Sequence['GetClustersClusterNodeGroupArgs'] node_groups: List of Master, Core and Task nodes.
               The NodeGroup structure is documented below.
        :param _builtins.str node_public_cert_name: Name of the key file.
        :param _builtins.str order_id: Cluster creation order ID.
        :param _builtins.int period_type: Whether the subscription type is yearly or monthly.  
               The following options are supported:
               + **0**: monthly subscription.
               + **1**: yearly subscription.
        :param _builtins.str private_ip_first: Preferred private IP address.
        :param _builtins.int safe_mode: Running mode of an MRS cluster.  
               The following options are supported:
               + **0**: Normal cluster.
               + **1**: Security cluster.
        :param _builtins.str scale: Status of node changes  
               If this parameter is left blank, no change operation is performed on a cluster node.
               The options are as follows:
               + **Scaling-out**: The cluster is being scaled out.
               + **Scaling-in**: The cluster is being scaled in.
               + **scaling-error**: The cluster is in the running state and fails to be scaled in or out or the specifications
               fail to be scaled up for the last time.
               + **scaling-up**: The master node specifications are being scaled up.
               + **scaling_up_first**: The standby master node specifications are being scaled up.
               + **scaled_up_first**: The standby master node specifications have been scaled up.
               + **scaled-up-success**: The master node specifications have been scaled up.
        :param _builtins.str security_group_id: Security group ID.
        :param _builtins.str slave_security_group_id: Security group ID of a non-Master node.  
               Currently, one MRS cluster uses only one security group. Therefore, this field has been discarded.
        :param _builtins.str stage_desc: Cluster progress description.  
               The cluster installation progress includes:
               + **Verifying cluster parameters**: Cluster parameters are being verified.
               + **Applying for cluster resources**: Cluster resources are being applied for.
               + **Creating VMs**: The VMs are being created.
               + **Initializing VMs**: The VMs are being initialized.
               + **Installing MRS Manager**: MRS Manager is being installed.
               + **Deploying the cluster**: The cluster is being deployed.
               + **Cluster installation failed**: Failed to install the cluster.
        :param _builtins.str status: The status of cluster.  
               The following options are supported:
               + **existing**: Query existing clusters, including all clusters except those in the deleted state
               and the yearly/monthly clusters in the Order processing or preparing state.
               + **history**: Quer historical clusters, including all the deleted clusters, clusters that fail to delete,
               clusters whose VMs fail to delete, and clusters whose database updates fail to delete.
               + **starting**: Query a list of clusters that are being started.
               + **running**: Query a list of running clusters.
               + **terminated**: Query a list of terminated clusters.
               + **failed**: Query a list of failed clusters.
               + **abnormal**: Query a list of abnormal clusters.
               + **terminating**: Query a list of clusters that are being terminated.
               + **frozen**: Query a list of frozen clusters.
               + **scaling-out**: Query a list of clusters that are being scaled out.
               + **scaling-in**: Query a list of clusters that are being scaled in.
        :param _builtins.str subnet_id: Subnet ID.
        :param Mapping[str, _builtins.str] tags: You can search for a cluster by its tags.  
               If you specify multiple tags, the relationship between them is **AND**.
               The format of the tags parameter is **tags=k1\\*v1,k2\\*v2,k3\\*v3**.
               When the values of some tags are null, the format is **tags=k1,k2,k3\\*v3**.
        :param Sequence['GetClustersClusterTaskNodeGroupArgs'] task_node_groups: List of Task nodes.
               The NodeGroup structure is documented below.
        :param _builtins.str total_node_num: Total number of nodes deployed in a cluster.
        :param _builtins.int type: Cluster type.  
               The following options are supported:
               + **0**: analysis cluster.
               + **1**: streaming cluster.
               + **2**: hybrid cluster.
               + **3**: custom cluster.
               + **4**: Offline cluster.
        :param _builtins.str version: Cluster version.
        :param _builtins.str vnc: URI for remotely logging in to an ECS.
        :param _builtins.int volume_size: Disk storage space.
        :param _builtins.str volume_type: Disk type.
        :param _builtins.str vpc_id: VPC ID.
        """
        pulumi.set(__self__, "availability_zone", availability_zone)
        pulumi.set(__self__, "billing_type", billing_type)
        pulumi.set(__self__, "component_lists", component_lists)
        pulumi.set(__self__, "core_data_volume_count", core_data_volume_count)
        pulumi.set(__self__, "core_data_volume_size", core_data_volume_size)
        pulumi.set(__self__, "core_data_volume_type", core_data_volume_type)
        pulumi.set(__self__, "core_node_num", core_node_num)
        pulumi.set(__self__, "core_node_product_id", core_node_product_id)
        pulumi.set(__self__, "core_node_size", core_node_size)
        pulumi.set(__self__, "core_node_spec_id", core_node_spec_id)
        pulumi.set(__self__, "deployment_id", deployment_id)
        pulumi.set(__self__, "description", description)
        pulumi.set(__self__, "duration", duration)
        pulumi.set(__self__, "eip_address", eip_address)
        pulumi.set(__self__, "eip_id", eip_id)
        pulumi.set(__self__, "eipv6_address", eipv6_address)
        pulumi.set(__self__, "enterprise_project_id", enterprise_project_id)
        pulumi.set(__self__, "external_alternate_ip", external_alternate_ip)
        pulumi.set(__self__, "external_ip", external_ip)
        pulumi.set(__self__, "fee", fee)
        pulumi.set(__self__, "hadoop_version", hadoop_version)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "internal_ip", internal_ip)
        pulumi.set(__self__, "log_collection", log_collection)
        pulumi.set(__self__, "master_data_volume_count", master_data_volume_count)
        pulumi.set(__self__, "master_data_volume_size", master_data_volume_size)
        pulumi.set(__self__, "master_data_volume_type", master_data_volume_type)
        pulumi.set(__self__, "master_node_ip", master_node_ip)
        pulumi.set(__self__, "master_node_num", master_node_num)
        pulumi.set(__self__, "master_node_product_id", master_node_product_id)
        pulumi.set(__self__, "master_node_size", master_node_size)
        pulumi.set(__self__, "master_node_spec_id", master_node_spec_id)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "node_groups", node_groups)
        pulumi.set(__self__, "node_public_cert_name", node_public_cert_name)
        pulumi.set(__self__, "order_id", order_id)
        pulumi.set(__self__, "period_type", period_type)
        pulumi.set(__self__, "private_ip_first", private_ip_first)
        pulumi.set(__self__, "safe_mode", safe_mode)
        pulumi.set(__self__, "scale", scale)
        pulumi.set(__self__, "security_group_id", security_group_id)
        pulumi.set(__self__, "slave_security_group_id", slave_security_group_id)
        pulumi.set(__self__, "stage_desc", stage_desc)
        pulumi.set(__self__, "status", status)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "task_node_groups", task_node_groups)
        pulumi.set(__self__, "total_node_num", total_node_num)
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "version", version)
        pulumi.set(__self__, "vnc", vnc)
        pulumi.set(__self__, "volume_size", volume_size)
        pulumi.set(__self__, "volume_type", volume_type)
        pulumi.set(__self__, "vpc_id", vpc_id)

    @_builtins.property
    @pulumi.getter(name="availabilityZone")
    def availability_zone(self) -> _builtins.str:
        """
        The AZ.
        """
        return pulumi.get(self, "availability_zone")

    @_builtins.property
    @pulumi.getter(name="billingType")
    def billing_type(self) -> _builtins.str:
        """
        Cluster billing mode.  
        The following options are supported:
        + **11**: Yearly/Monthly.
        + **12**: Pay-per-use.
        """
        return pulumi.get(self, "billing_type")

    @_builtins.property
    @pulumi.getter(name="componentLists")
    def component_lists(self) -> Sequence['outputs.GetClustersClusterComponentListResult']:
        """
        Component list.
        The component_list structure is documented below.
        """
        return pulumi.get(self, "component_lists")

    @_builtins.property
    @pulumi.getter(name="coreDataVolumeCount")
    def core_data_volume_count(self) -> _builtins.int:
        """
        Number of data disks of the Core node.
        """
        return pulumi.get(self, "core_data_volume_count")

    @_builtins.property
    @pulumi.getter(name="coreDataVolumeSize")
    def core_data_volume_size(self) -> _builtins.int:
        """
        Data disk storage space of the Core node.  
        To increase data storage capacity, you can add disks at the same time when creating a cluster.
        Value range: 100 GB to 32,000 GB
        """
        return pulumi.get(self, "core_data_volume_size")

    @_builtins.property
    @pulumi.getter(name="coreDataVolumeType")
    def core_data_volume_type(self) -> _builtins.str:
        """
        Data disk storage type of the Core node.  
        Currently, **SATA**, **SAS**, and **SSD** are supported.
        """
        return pulumi.get(self, "core_data_volume_type")

    @_builtins.property
    @pulumi.getter(name="coreNodeNum")
    def core_node_num(self) -> _builtins.str:
        """
        Number of Core nodes deployed in a cluster.
        """
        return pulumi.get(self, "core_node_num")

    @_builtins.property
    @pulumi.getter(name="coreNodeProductId")
    def core_node_product_id(self) -> _builtins.str:
        """
        Product ID of a Core node.
        """
        return pulumi.get(self, "core_node_product_id")

    @_builtins.property
    @pulumi.getter(name="coreNodeSize")
    def core_node_size(self) -> _builtins.str:
        """
        Instance specifications of a Core node.
        """
        return pulumi.get(self, "core_node_size")

    @_builtins.property
    @pulumi.getter(name="coreNodeSpecId")
    def core_node_spec_id(self) -> _builtins.str:
        """
        Specification ID of a Core node.
        """
        return pulumi.get(self, "core_node_spec_id")

    @_builtins.property
    @pulumi.getter(name="deploymentId")
    def deployment_id(self) -> _builtins.str:
        """
        Cluster deployment ID.
        """
        return pulumi.get(self, "deployment_id")

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        Cluster description.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter
    def duration(self) -> _builtins.str:
        """
        Cluster subscription duration.
        """
        return pulumi.get(self, "duration")

    @_builtins.property
    @pulumi.getter(name="eipAddress")
    def eip_address(self) -> _builtins.str:
        """
        IPv4 address of the cluster EIP.
        """
        return pulumi.get(self, "eip_address")

    @_builtins.property
    @pulumi.getter(name="eipId")
    def eip_id(self) -> _builtins.str:
        """
        Unique ID of the cluster EIP.
        """
        return pulumi.get(self, "eip_id")

    @_builtins.property
    @pulumi.getter(name="eipv6Address")
    def eipv6_address(self) -> _builtins.str:
        """
        IPv6 address of the cluster EIP.  
        This parameter is not returned when an IPv4 address is used.
        """
        return pulumi.get(self, "eipv6_address")

    @_builtins.property
    @pulumi.getter(name="enterpriseProjectId")
    def enterprise_project_id(self) -> _builtins.str:
        """
        The enterprise project ID used to query clusters in a specified
        enterprise project.
        The default value is **0**, indicating the default enterprise project.
        """
        return pulumi.get(self, "enterprise_project_id")

    @_builtins.property
    @pulumi.getter(name="externalAlternateIp")
    def external_alternate_ip(self) -> _builtins.str:
        """
        Backup external IP address.
        """
        return pulumi.get(self, "external_alternate_ip")

    @_builtins.property
    @pulumi.getter(name="externalIp")
    def external_ip(self) -> _builtins.str:
        """
        External IP address.
        """
        return pulumi.get(self, "external_ip")

    @_builtins.property
    @pulumi.getter
    def fee(self) -> _builtins.str:
        """
        Cluster creation fee, which is automatically calculated.
        """
        return pulumi.get(self, "fee")

    @_builtins.property
    @pulumi.getter(name="hadoopVersion")
    def hadoop_version(self) -> _builtins.str:
        """
        Hadoop version.
        """
        return pulumi.get(self, "hadoop_version")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        Cluster ID.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter(name="internalIp")
    def internal_ip(self) -> _builtins.str:
        """
        Internal IP address.
        """
        return pulumi.get(self, "internal_ip")

    @_builtins.property
    @pulumi.getter(name="logCollection")
    def log_collection(self) -> _builtins.int:
        """
        Whether to collect logs when cluster installation fails.  
        The following options are supported:
        + **0**: Do not collect logs.
        + **1**: Collect logs.
        """
        return pulumi.get(self, "log_collection")

    @_builtins.property
    @pulumi.getter(name="masterDataVolumeCount")
    def master_data_volume_count(self) -> _builtins.int:
        """
        Number of data disks of the Master node  
        The value can be set to 1 only.
        """
        return pulumi.get(self, "master_data_volume_count")

    @_builtins.property
    @pulumi.getter(name="masterDataVolumeSize")
    def master_data_volume_size(self) -> _builtins.int:
        """
        Data disk storage space of the Master node  
        To increase data storage capacity, you can add disks at the same time when creating a cluster.
        Value range: 100 GB to 32,000 GB
        """
        return pulumi.get(self, "master_data_volume_size")

    @_builtins.property
    @pulumi.getter(name="masterDataVolumeType")
    def master_data_volume_type(self) -> _builtins.str:
        """
        Data disk storage type of the Master node.  
        Currently, **SATA**, **SAS**, and **SSD** are supported.
        """
        return pulumi.get(self, "master_data_volume_type")

    @_builtins.property
    @pulumi.getter(name="masterNodeIp")
    def master_node_ip(self) -> _builtins.str:
        """
        IP address of a Master node.
        """
        return pulumi.get(self, "master_node_ip")

    @_builtins.property
    @pulumi.getter(name="masterNodeNum")
    def master_node_num(self) -> _builtins.str:
        """
        Number of Master nodes deployed in a cluster.
        """
        return pulumi.get(self, "master_node_num")

    @_builtins.property
    @pulumi.getter(name="masterNodeProductId")
    def master_node_product_id(self) -> _builtins.str:
        """
        Product ID of a Master node.
        """
        return pulumi.get(self, "master_node_product_id")

    @_builtins.property
    @pulumi.getter(name="masterNodeSize")
    def master_node_size(self) -> _builtins.str:
        """
        Instance specifications of a Master node.
        """
        return pulumi.get(self, "master_node_size")

    @_builtins.property
    @pulumi.getter(name="masterNodeSpecId")
    def master_node_spec_id(self) -> _builtins.str:
        """
        Specification ID of a Master node.
        """
        return pulumi.get(self, "master_node_spec_id")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        The name of cluster.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="nodeGroups")
    def node_groups(self) -> Sequence['outputs.GetClustersClusterNodeGroupResult']:
        """
        List of Master, Core and Task nodes.
        The NodeGroup structure is documented below.
        """
        return pulumi.get(self, "node_groups")

    @_builtins.property
    @pulumi.getter(name="nodePublicCertName")
    def node_public_cert_name(self) -> _builtins.str:
        """
        Name of the key file.
        """
        return pulumi.get(self, "node_public_cert_name")

    @_builtins.property
    @pulumi.getter(name="orderId")
    def order_id(self) -> _builtins.str:
        """
        Cluster creation order ID.
        """
        return pulumi.get(self, "order_id")

    @_builtins.property
    @pulumi.getter(name="periodType")
    def period_type(self) -> _builtins.int:
        """
        Whether the subscription type is yearly or monthly.  
        The following options are supported:
        + **0**: monthly subscription.
        + **1**: yearly subscription.
        """
        return pulumi.get(self, "period_type")

    @_builtins.property
    @pulumi.getter(name="privateIpFirst")
    def private_ip_first(self) -> _builtins.str:
        """
        Preferred private IP address.
        """
        return pulumi.get(self, "private_ip_first")

    @_builtins.property
    @pulumi.getter(name="safeMode")
    def safe_mode(self) -> _builtins.int:
        """
        Running mode of an MRS cluster.  
        The following options are supported:
        + **0**: Normal cluster.
        + **1**: Security cluster.
        """
        return pulumi.get(self, "safe_mode")

    @_builtins.property
    @pulumi.getter
    def scale(self) -> _builtins.str:
        """
        Status of node changes  
        If this parameter is left blank, no change operation is performed on a cluster node.
        The options are as follows:
        + **Scaling-out**: The cluster is being scaled out.
        + **Scaling-in**: The cluster is being scaled in.
        + **scaling-error**: The cluster is in the running state and fails to be scaled in or out or the specifications
        fail to be scaled up for the last time.
        + **scaling-up**: The master node specifications are being scaled up.
        + **scaling_up_first**: The standby master node specifications are being scaled up.
        + **scaled_up_first**: The standby master node specifications have been scaled up.
        + **scaled-up-success**: The master node specifications have been scaled up.
        """
        return pulumi.get(self, "scale")

    @_builtins.property
    @pulumi.getter(name="securityGroupId")
    def security_group_id(self) -> _builtins.str:
        """
        Security group ID.
        """
        return pulumi.get(self, "security_group_id")

    @_builtins.property
    @pulumi.getter(name="slaveSecurityGroupId")
    def slave_security_group_id(self) -> _builtins.str:
        """
        Security group ID of a non-Master node.  
        Currently, one MRS cluster uses only one security group. Therefore, this field has been discarded.
        """
        return pulumi.get(self, "slave_security_group_id")

    @_builtins.property
    @pulumi.getter(name="stageDesc")
    def stage_desc(self) -> _builtins.str:
        """
        Cluster progress description.  
        The cluster installation progress includes:
        + **Verifying cluster parameters**: Cluster parameters are being verified.
        + **Applying for cluster resources**: Cluster resources are being applied for.
        + **Creating VMs**: The VMs are being created.
        + **Initializing VMs**: The VMs are being initialized.
        + **Installing MRS Manager**: MRS Manager is being installed.
        + **Deploying the cluster**: The cluster is being deployed.
        + **Cluster installation failed**: Failed to install the cluster.
        """
        return pulumi.get(self, "stage_desc")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        The status of cluster.  
        The following options are supported:
        + **existing**: Query existing clusters, including all clusters except those in the deleted state
        and the yearly/monthly clusters in the Order processing or preparing state.
        + **history**: Quer historical clusters, including all the deleted clusters, clusters that fail to delete,
        clusters whose VMs fail to delete, and clusters whose database updates fail to delete.
        + **starting**: Query a list of clusters that are being started.
        + **running**: Query a list of running clusters.
        + **terminated**: Query a list of terminated clusters.
        + **failed**: Query a list of failed clusters.
        + **abnormal**: Query a list of abnormal clusters.
        + **terminating**: Query a list of clusters that are being terminated.
        + **frozen**: Query a list of frozen clusters.
        + **scaling-out**: Query a list of clusters that are being scaled out.
        + **scaling-in**: Query a list of clusters that are being scaled in.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> _builtins.str:
        """
        Subnet ID.
        """
        return pulumi.get(self, "subnet_id")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Mapping[str, _builtins.str]:
        """
        You can search for a cluster by its tags.  
        If you specify multiple tags, the relationship between them is **AND**.
        The format of the tags parameter is **tags=k1\\*v1,k2\\*v2,k3\\*v3**.
        When the values of some tags are null, the format is **tags=k1,k2,k3\\*v3**.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter(name="taskNodeGroups")
    def task_node_groups(self) -> Sequence['outputs.GetClustersClusterTaskNodeGroupResult']:
        """
        List of Task nodes.
        The NodeGroup structure is documented below.
        """
        return pulumi.get(self, "task_node_groups")

    @_builtins.property
    @pulumi.getter(name="totalNodeNum")
    def total_node_num(self) -> _builtins.str:
        """
        Total number of nodes deployed in a cluster.
        """
        return pulumi.get(self, "total_node_num")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.int:
        """
        Cluster type.  
        The following options are supported:
        + **0**: analysis cluster.
        + **1**: streaming cluster.
        + **2**: hybrid cluster.
        + **3**: custom cluster.
        + **4**: Offline cluster.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter
    def version(self) -> _builtins.str:
        """
        Cluster version.
        """
        return pulumi.get(self, "version")

    @_builtins.property
    @pulumi.getter
    def vnc(self) -> _builtins.str:
        """
        URI for remotely logging in to an ECS.
        """
        return pulumi.get(self, "vnc")

    @_builtins.property
    @pulumi.getter(name="volumeSize")
    def volume_size(self) -> _builtins.int:
        """
        Disk storage space.
        """
        return pulumi.get(self, "volume_size")

    @_builtins.property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> _builtins.str:
        """
        Disk type.
        """
        return pulumi.get(self, "volume_type")

    @_builtins.property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> _builtins.str:
        """
        VPC ID.
        """
        return pulumi.get(self, "vpc_id")


@pulumi.output_type
class GetClustersClusterComponentListResult(dict):
    def __init__(__self__, *,
                 component_desc: _builtins.str,
                 component_id: _builtins.str,
                 component_name: _builtins.str,
                 component_version: _builtins.str):
        """
        :param _builtins.str component_desc: Component description.
        :param _builtins.str component_id: Component ID  
               For example, the component_id of Hadoop is MRS 3.0.2_001, MRS 2.1.0_001, MRS 1.9.2_001, MRS 1.8.10_001.
        :param _builtins.str component_name: Component name.
        :param _builtins.str component_version: Component version.
        """
        pulumi.set(__self__, "component_desc", component_desc)
        pulumi.set(__self__, "component_id", component_id)
        pulumi.set(__self__, "component_name", component_name)
        pulumi.set(__self__, "component_version", component_version)

    @_builtins.property
    @pulumi.getter(name="componentDesc")
    def component_desc(self) -> _builtins.str:
        """
        Component description.
        """
        return pulumi.get(self, "component_desc")

    @_builtins.property
    @pulumi.getter(name="componentId")
    def component_id(self) -> _builtins.str:
        """
        Component ID  
        For example, the component_id of Hadoop is MRS 3.0.2_001, MRS 2.1.0_001, MRS 1.9.2_001, MRS 1.8.10_001.
        """
        return pulumi.get(self, "component_id")

    @_builtins.property
    @pulumi.getter(name="componentName")
    def component_name(self) -> _builtins.str:
        """
        Component name.
        """
        return pulumi.get(self, "component_name")

    @_builtins.property
    @pulumi.getter(name="componentVersion")
    def component_version(self) -> _builtins.str:
        """
        Component version.
        """
        return pulumi.get(self, "component_version")


@pulumi.output_type
class GetClustersClusterNodeGroupResult(dict):
    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 data_volume_product_id: _builtins.str,
                 data_volume_resource_spec_code: _builtins.str,
                 data_volume_resource_type: _builtins.str,
                 data_volume_size: _builtins.int,
                 data_volume_type: _builtins.str,
                 group_name: _builtins.str,
                 node_num: _builtins.int,
                 node_product_id: _builtins.str,
                 node_size: _builtins.str,
                 node_spec_id: _builtins.str,
                 root_volume_product_id: _builtins.str,
                 root_volume_resource_spec_code: _builtins.str,
                 root_volume_resource_type: _builtins.str,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 vm_product_id: _builtins.str,
                 vm_spec_code: _builtins.str):
        """
        :param _builtins.int data_volume_count: Number of data disks of a node group.
        :param _builtins.str data_volume_product_id: Data disk product ID of a node group.
        :param _builtins.str data_volume_resource_spec_code: Data disk specification code of a node group.
        :param _builtins.str data_volume_resource_type: Data disk product type of a node group.
        :param _builtins.int data_volume_size: Data disk storage space of a node group.
        :param _builtins.str data_volume_type: Data disk storage type of a node group.  
               The following options are supported:
               + **SATA**: Common I/O.
               + **SAS**: High I/O.
               + **SSD**: Ultra-high I/O.
        :param _builtins.str group_name: Node group name.
        :param _builtins.int node_num: Number of nodes in a node group.
        :param _builtins.str node_product_id: Instance product ID of a node group.
        :param _builtins.str node_size: Instance specifications of a node group.
        :param _builtins.str node_spec_id: Instance specification ID of a node group.
        :param _builtins.str root_volume_product_id: Root disk product ID of a node group.
        :param _builtins.str root_volume_resource_spec_code: Root disk specification code of a node group.
        :param _builtins.str root_volume_resource_type: System disk product type of a node group.
        :param _builtins.int root_volume_size: Root disk storage space of a node group.
        :param _builtins.str root_volume_type: Root disk storage type of a node group.
        :param _builtins.str vm_product_id: VM product ID of a node group.
        :param _builtins.str vm_spec_code: VM specification code of a node group.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "data_volume_product_id", data_volume_product_id)
        pulumi.set(__self__, "data_volume_resource_spec_code", data_volume_resource_spec_code)
        pulumi.set(__self__, "data_volume_resource_type", data_volume_resource_type)
        pulumi.set(__self__, "data_volume_size", data_volume_size)
        pulumi.set(__self__, "data_volume_type", data_volume_type)
        pulumi.set(__self__, "group_name", group_name)
        pulumi.set(__self__, "node_num", node_num)
        pulumi.set(__self__, "node_product_id", node_product_id)
        pulumi.set(__self__, "node_size", node_size)
        pulumi.set(__self__, "node_spec_id", node_spec_id)
        pulumi.set(__self__, "root_volume_product_id", root_volume_product_id)
        pulumi.set(__self__, "root_volume_resource_spec_code", root_volume_resource_spec_code)
        pulumi.set(__self__, "root_volume_resource_type", root_volume_resource_type)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        pulumi.set(__self__, "vm_product_id", vm_product_id)
        pulumi.set(__self__, "vm_spec_code", vm_spec_code)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Number of data disks of a node group.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter(name="dataVolumeProductId")
    def data_volume_product_id(self) -> _builtins.str:
        """
        Data disk product ID of a node group.
        """
        return pulumi.get(self, "data_volume_product_id")

    @_builtins.property
    @pulumi.getter(name="dataVolumeResourceSpecCode")
    def data_volume_resource_spec_code(self) -> _builtins.str:
        """
        Data disk specification code of a node group.
        """
        return pulumi.get(self, "data_volume_resource_spec_code")

    @_builtins.property
    @pulumi.getter(name="dataVolumeResourceType")
    def data_volume_resource_type(self) -> _builtins.str:
        """
        Data disk product type of a node group.
        """
        return pulumi.get(self, "data_volume_resource_type")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> _builtins.int:
        """
        Data disk storage space of a node group.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> _builtins.str:
        """
        Data disk storage type of a node group.  
        The following options are supported:
        + **SATA**: Common I/O.
        + **SAS**: High I/O.
        + **SSD**: Ultra-high I/O.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="groupName")
    def group_name(self) -> _builtins.str:
        """
        Node group name.
        """
        return pulumi.get(self, "group_name")

    @_builtins.property
    @pulumi.getter(name="nodeNum")
    def node_num(self) -> _builtins.int:
        """
        Number of nodes in a node group.
        """
        return pulumi.get(self, "node_num")

    @_builtins.property
    @pulumi.getter(name="nodeProductId")
    def node_product_id(self) -> _builtins.str:
        """
        Instance product ID of a node group.
        """
        return pulumi.get(self, "node_product_id")

    @_builtins.property
    @pulumi.getter(name="nodeSize")
    def node_size(self) -> _builtins.str:
        """
        Instance specifications of a node group.
        """
        return pulumi.get(self, "node_size")

    @_builtins.property
    @pulumi.getter(name="nodeSpecId")
    def node_spec_id(self) -> _builtins.str:
        """
        Instance specification ID of a node group.
        """
        return pulumi.get(self, "node_spec_id")

    @_builtins.property
    @pulumi.getter(name="rootVolumeProductId")
    def root_volume_product_id(self) -> _builtins.str:
        """
        Root disk product ID of a node group.
        """
        return pulumi.get(self, "root_volume_product_id")

    @_builtins.property
    @pulumi.getter(name="rootVolumeResourceSpecCode")
    def root_volume_resource_spec_code(self) -> _builtins.str:
        """
        Root disk specification code of a node group.
        """
        return pulumi.get(self, "root_volume_resource_spec_code")

    @_builtins.property
    @pulumi.getter(name="rootVolumeResourceType")
    def root_volume_resource_type(self) -> _builtins.str:
        """
        System disk product type of a node group.
        """
        return pulumi.get(self, "root_volume_resource_type")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Root disk storage space of a node group.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Root disk storage type of a node group.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="vmProductId")
    def vm_product_id(self) -> _builtins.str:
        """
        VM product ID of a node group.
        """
        return pulumi.get(self, "vm_product_id")

    @_builtins.property
    @pulumi.getter(name="vmSpecCode")
    def vm_spec_code(self) -> _builtins.str:
        """
        VM specification code of a node group.
        """
        return pulumi.get(self, "vm_spec_code")


@pulumi.output_type
class GetClustersClusterTaskNodeGroupResult(dict):
    def __init__(__self__, *,
                 data_volume_count: _builtins.int,
                 data_volume_product_id: _builtins.str,
                 data_volume_resource_spec_code: _builtins.str,
                 data_volume_resource_type: _builtins.str,
                 data_volume_size: _builtins.int,
                 data_volume_type: _builtins.str,
                 group_name: _builtins.str,
                 node_num: _builtins.int,
                 node_product_id: _builtins.str,
                 node_size: _builtins.str,
                 node_spec_id: _builtins.str,
                 root_volume_product_id: _builtins.str,
                 root_volume_resource_spec_code: _builtins.str,
                 root_volume_resource_type: _builtins.str,
                 root_volume_size: _builtins.int,
                 root_volume_type: _builtins.str,
                 vm_product_id: _builtins.str,
                 vm_spec_code: _builtins.str):
        """
        :param _builtins.int data_volume_count: Number of data disks of a node group.
        :param _builtins.str data_volume_product_id: Data disk product ID of a node group.
        :param _builtins.str data_volume_resource_spec_code: Data disk specification code of a node group.
        :param _builtins.str data_volume_resource_type: Data disk product type of a node group.
        :param _builtins.int data_volume_size: Data disk storage space of a node group.
        :param _builtins.str data_volume_type: Data disk storage type of a node group.  
               The following options are supported:
               + **SATA**: Common I/O.
               + **SAS**: High I/O.
               + **SSD**: Ultra-high I/O.
        :param _builtins.str group_name: Node group name.
        :param _builtins.int node_num: Number of nodes in a node group.
        :param _builtins.str node_product_id: Instance product ID of a node group.
        :param _builtins.str node_size: Instance specifications of a node group.
        :param _builtins.str node_spec_id: Instance specification ID of a node group.
        :param _builtins.str root_volume_product_id: Root disk product ID of a node group.
        :param _builtins.str root_volume_resource_spec_code: Root disk specification code of a node group.
        :param _builtins.str root_volume_resource_type: System disk product type of a node group.
        :param _builtins.int root_volume_size: Root disk storage space of a node group.
        :param _builtins.str root_volume_type: Root disk storage type of a node group.
        :param _builtins.str vm_product_id: VM product ID of a node group.
        :param _builtins.str vm_spec_code: VM specification code of a node group.
        """
        pulumi.set(__self__, "data_volume_count", data_volume_count)
        pulumi.set(__self__, "data_volume_product_id", data_volume_product_id)
        pulumi.set(__self__, "data_volume_resource_spec_code", data_volume_resource_spec_code)
        pulumi.set(__self__, "data_volume_resource_type", data_volume_resource_type)
        pulumi.set(__self__, "data_volume_size", data_volume_size)
        pulumi.set(__self__, "data_volume_type", data_volume_type)
        pulumi.set(__self__, "group_name", group_name)
        pulumi.set(__self__, "node_num", node_num)
        pulumi.set(__self__, "node_product_id", node_product_id)
        pulumi.set(__self__, "node_size", node_size)
        pulumi.set(__self__, "node_spec_id", node_spec_id)
        pulumi.set(__self__, "root_volume_product_id", root_volume_product_id)
        pulumi.set(__self__, "root_volume_resource_spec_code", root_volume_resource_spec_code)
        pulumi.set(__self__, "root_volume_resource_type", root_volume_resource_type)
        pulumi.set(__self__, "root_volume_size", root_volume_size)
        pulumi.set(__self__, "root_volume_type", root_volume_type)
        pulumi.set(__self__, "vm_product_id", vm_product_id)
        pulumi.set(__self__, "vm_spec_code", vm_spec_code)

    @_builtins.property
    @pulumi.getter(name="dataVolumeCount")
    def data_volume_count(self) -> _builtins.int:
        """
        Number of data disks of a node group.
        """
        return pulumi.get(self, "data_volume_count")

    @_builtins.property
    @pulumi.getter(name="dataVolumeProductId")
    def data_volume_product_id(self) -> _builtins.str:
        """
        Data disk product ID of a node group.
        """
        return pulumi.get(self, "data_volume_product_id")

    @_builtins.property
    @pulumi.getter(name="dataVolumeResourceSpecCode")
    def data_volume_resource_spec_code(self) -> _builtins.str:
        """
        Data disk specification code of a node group.
        """
        return pulumi.get(self, "data_volume_resource_spec_code")

    @_builtins.property
    @pulumi.getter(name="dataVolumeResourceType")
    def data_volume_resource_type(self) -> _builtins.str:
        """
        Data disk product type of a node group.
        """
        return pulumi.get(self, "data_volume_resource_type")

    @_builtins.property
    @pulumi.getter(name="dataVolumeSize")
    def data_volume_size(self) -> _builtins.int:
        """
        Data disk storage space of a node group.
        """
        return pulumi.get(self, "data_volume_size")

    @_builtins.property
    @pulumi.getter(name="dataVolumeType")
    def data_volume_type(self) -> _builtins.str:
        """
        Data disk storage type of a node group.  
        The following options are supported:
        + **SATA**: Common I/O.
        + **SAS**: High I/O.
        + **SSD**: Ultra-high I/O.
        """
        return pulumi.get(self, "data_volume_type")

    @_builtins.property
    @pulumi.getter(name="groupName")
    def group_name(self) -> _builtins.str:
        """
        Node group name.
        """
        return pulumi.get(self, "group_name")

    @_builtins.property
    @pulumi.getter(name="nodeNum")
    def node_num(self) -> _builtins.int:
        """
        Number of nodes in a node group.
        """
        return pulumi.get(self, "node_num")

    @_builtins.property
    @pulumi.getter(name="nodeProductId")
    def node_product_id(self) -> _builtins.str:
        """
        Instance product ID of a node group.
        """
        return pulumi.get(self, "node_product_id")

    @_builtins.property
    @pulumi.getter(name="nodeSize")
    def node_size(self) -> _builtins.str:
        """
        Instance specifications of a node group.
        """
        return pulumi.get(self, "node_size")

    @_builtins.property
    @pulumi.getter(name="nodeSpecId")
    def node_spec_id(self) -> _builtins.str:
        """
        Instance specification ID of a node group.
        """
        return pulumi.get(self, "node_spec_id")

    @_builtins.property
    @pulumi.getter(name="rootVolumeProductId")
    def root_volume_product_id(self) -> _builtins.str:
        """
        Root disk product ID of a node group.
        """
        return pulumi.get(self, "root_volume_product_id")

    @_builtins.property
    @pulumi.getter(name="rootVolumeResourceSpecCode")
    def root_volume_resource_spec_code(self) -> _builtins.str:
        """
        Root disk specification code of a node group.
        """
        return pulumi.get(self, "root_volume_resource_spec_code")

    @_builtins.property
    @pulumi.getter(name="rootVolumeResourceType")
    def root_volume_resource_type(self) -> _builtins.str:
        """
        System disk product type of a node group.
        """
        return pulumi.get(self, "root_volume_resource_type")

    @_builtins.property
    @pulumi.getter(name="rootVolumeSize")
    def root_volume_size(self) -> _builtins.int:
        """
        Root disk storage space of a node group.
        """
        return pulumi.get(self, "root_volume_size")

    @_builtins.property
    @pulumi.getter(name="rootVolumeType")
    def root_volume_type(self) -> _builtins.str:
        """
        Root disk storage type of a node group.
        """
        return pulumi.get(self, "root_volume_type")

    @_builtins.property
    @pulumi.getter(name="vmProductId")
    def vm_product_id(self) -> _builtins.str:
        """
        VM product ID of a node group.
        """
        return pulumi.get(self, "vm_product_id")

    @_builtins.property
    @pulumi.getter(name="vmSpecCode")
    def vm_spec_code(self) -> _builtins.str:
        """
        VM specification code of a node group.
        """
        return pulumi.get(self, "vm_spec_code")


