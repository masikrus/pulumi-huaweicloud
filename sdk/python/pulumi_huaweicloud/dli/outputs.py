# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs

__all__ = [
    'DatasourceConnectionHost',
    'DatasourceConnectionRoute',
    'QueueScalingPolicy',
    'QueueSparkDriver',
    'QueueV1ScalingPolicy',
    'QueueV1SparkDriver',
    'SparkJobDependentPackage',
    'SparkJobDependentPackagePackage',
    'SparkTemplateBody',
    'SparkTemplateBodyDependentPackage',
    'SparkTemplateBodyDependentPackageResource',
    'SparkTemplateBodyResource',
    'SqlJobConf',
    'TableColumn',
    'TemplateSparkBody',
    'TemplateSparkBodyDependentPackage',
    'TemplateSparkBodyDependentPackageResource',
    'TemplateSparkBodyResource',
    'GetDatasourceAuthsAuthResult',
    'GetDatasourceConnectionsConnectionResult',
    'GetDatasourceConnectionsConnectionElasticResourcePoolResult',
    'GetDatasourceConnectionsConnectionHostResult',
    'GetDatasourceConnectionsConnectionQueueResult',
    'GetDatasourceConnectionsConnectionRouteResult',
    'GetElasticResourcePoolsElasticResourcePoolResult',
    'GetFlinkTemplatesTemplateResult',
    'GetFlinkjarJobsJobResult',
    'GetFlinksqlJobsJobResult',
    'GetQuotasQuotaResult',
    'GetSparkTemplatesTemplateResult',
    'GetSparkTemplatesTemplateBodyResult',
    'GetSparkTemplatesTemplateBodyDependentPackageResult',
    'GetSparkTemplatesTemplateBodyDependentPackageResourceResult',
    'GetSparkTemplatesTemplateBodyResourceResult',
    'GetSqlJobsJobResult',
    'GetSqlTemplatesTemplateResult',
]

@pulumi.output_type
class DatasourceConnectionHost(dict):
    def __init__(__self__, *,
                 ip: _builtins.str,
                 name: _builtins.str):
        """
        :param _builtins.str ip: IPv4 address of the host.
               
               <a name="datasourceConnection_Route"></a>
               The `Route` block supports:
        :param _builtins.str name: The route name.  
               The valid length is limited from `1` to `64`.
        """
        pulumi.set(__self__, "ip", ip)
        pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter
    def ip(self) -> _builtins.str:
        """
        IPv4 address of the host.

        <a name="datasourceConnection_Route"></a>
        The `Route` block supports:
        """
        return pulumi.get(self, "ip")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        The route name.  
        The valid length is limited from `1` to `64`.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class DatasourceConnectionRoute(dict):
    def __init__(__self__, *,
                 cidr: _builtins.str,
                 name: _builtins.str):
        """
        :param _builtins.str cidr: The CIDR of the route.
        :param _builtins.str name: The route name.  
               The valid length is limited from `1` to `64`.
        """
        pulumi.set(__self__, "cidr", cidr)
        pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter
    def cidr(self) -> _builtins.str:
        """
        The CIDR of the route.
        """
        return pulumi.get(self, "cidr")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        The route name.  
        The valid length is limited from `1` to `64`.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class QueueScalingPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "impactStartTime":
            suggest = "impact_start_time"
        elif key == "impactStopTime":
            suggest = "impact_stop_time"
        elif key == "maxCu":
            suggest = "max_cu"
        elif key == "minCu":
            suggest = "min_cu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QueueScalingPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QueueScalingPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QueueScalingPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 impact_start_time: _builtins.str,
                 impact_stop_time: _builtins.str,
                 max_cu: _builtins.int,
                 min_cu: _builtins.int,
                 priority: _builtins.int):
        """
        :param _builtins.str impact_start_time: Specifies the effective time of the queue scaling policy.
               The value can be set only by hour.
        :param _builtins.str impact_stop_time: Specifies the expiration time of the queue scaling policy.
               The value can be set only by hour.
               
               > The time ranges of different scaling policies in the same queue cannot overlap.
               The time range includes the start time but not the end time, e.g. `[00:00, 24:00)`.
        :param _builtins.int max_cu: Specifies the maximum number of CUs allowed by the scaling policy.
               The number must be a multiple of `4`.
               
               > The maximum CUs of any queue in an elastic resource pool cannot be more than the maximum CUs of the pool.
               
               <a name="queue_spark_driver"></a>
               The `spark_driver` block supports:
        :param _builtins.int min_cu: Specifies the minimum number of CUs allowed by the scaling policy.
               The number must be a multiple of `4`.
               
               > The total minimum CUs of all queues in an elastic resource pool cannot be more than the minimum CUs of the pool.
        :param _builtins.int priority: Specifies the priority of the queue scaling policy.
               The valid value ranges from `1` to `100`. The larger value means the higher priority.
        """
        pulumi.set(__self__, "impact_start_time", impact_start_time)
        pulumi.set(__self__, "impact_stop_time", impact_stop_time)
        pulumi.set(__self__, "max_cu", max_cu)
        pulumi.set(__self__, "min_cu", min_cu)
        pulumi.set(__self__, "priority", priority)

    @_builtins.property
    @pulumi.getter(name="impactStartTime")
    def impact_start_time(self) -> _builtins.str:
        """
        Specifies the effective time of the queue scaling policy.
        The value can be set only by hour.
        """
        return pulumi.get(self, "impact_start_time")

    @_builtins.property
    @pulumi.getter(name="impactStopTime")
    def impact_stop_time(self) -> _builtins.str:
        """
        Specifies the expiration time of the queue scaling policy.
        The value can be set only by hour.

        > The time ranges of different scaling policies in the same queue cannot overlap.
        The time range includes the start time but not the end time, e.g. `[00:00, 24:00)`.
        """
        return pulumi.get(self, "impact_stop_time")

    @_builtins.property
    @pulumi.getter(name="maxCu")
    def max_cu(self) -> _builtins.int:
        """
        Specifies the maximum number of CUs allowed by the scaling policy.
        The number must be a multiple of `4`.

        > The maximum CUs of any queue in an elastic resource pool cannot be more than the maximum CUs of the pool.

        <a name="queue_spark_driver"></a>
        The `spark_driver` block supports:
        """
        return pulumi.get(self, "max_cu")

    @_builtins.property
    @pulumi.getter(name="minCu")
    def min_cu(self) -> _builtins.int:
        """
        Specifies the minimum number of CUs allowed by the scaling policy.
        The number must be a multiple of `4`.

        > The total minimum CUs of all queues in an elastic resource pool cannot be more than the minimum CUs of the pool.
        """
        return pulumi.get(self, "min_cu")

    @_builtins.property
    @pulumi.getter
    def priority(self) -> _builtins.int:
        """
        Specifies the priority of the queue scaling policy.
        The valid value ranges from `1` to `100`. The larger value means the higher priority.
        """
        return pulumi.get(self, "priority")


@pulumi.output_type
class QueueSparkDriver(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxConcurrent":
            suggest = "max_concurrent"
        elif key == "maxInstance":
            suggest = "max_instance"
        elif key == "maxPrefetchInstance":
            suggest = "max_prefetch_instance"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QueueSparkDriver. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QueueSparkDriver.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QueueSparkDriver.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_concurrent: Optional[_builtins.int] = None,
                 max_instance: Optional[_builtins.int] = None,
                 max_prefetch_instance: Optional[_builtins.str] = None):
        """
        :param _builtins.int max_concurrent: Specifies the maximum number of tasks that can be concurrently executed by a spark driver.
               The valid value ranges from `1` to `32`.
        :param _builtins.int max_instance: Specifies the maximum number of spark drivers that can be started on the queue.
               If the `cu_count` is `16`, the value can only be `2`.
               If The `cu_count` is greater than `16`, the minimum value is `2`, the maximum value is the number of queue CUs
               divided by `16`.
        :param _builtins.str max_prefetch_instance: Specifies the maximum number of spark drivers to be pre-started on the queue.
               The minimum value is `0`. If the `cu_count` is less than `32`, the maximum value is `1`.
               If the `cu_count` is greater than or equal to `32`, the maximum value is the number of queue CUs divided by `16`.
               
               > If the minimum CUs of the queue is less than `16` CUs, the `max_instance` and `max_prefetch_instance` parameters
               does not take effect.
        """
        if max_concurrent is not None:
            pulumi.set(__self__, "max_concurrent", max_concurrent)
        if max_instance is not None:
            pulumi.set(__self__, "max_instance", max_instance)
        if max_prefetch_instance is not None:
            pulumi.set(__self__, "max_prefetch_instance", max_prefetch_instance)

    @_builtins.property
    @pulumi.getter(name="maxConcurrent")
    def max_concurrent(self) -> Optional[_builtins.int]:
        """
        Specifies the maximum number of tasks that can be concurrently executed by a spark driver.
        The valid value ranges from `1` to `32`.
        """
        return pulumi.get(self, "max_concurrent")

    @_builtins.property
    @pulumi.getter(name="maxInstance")
    def max_instance(self) -> Optional[_builtins.int]:
        """
        Specifies the maximum number of spark drivers that can be started on the queue.
        If the `cu_count` is `16`, the value can only be `2`.
        If The `cu_count` is greater than `16`, the minimum value is `2`, the maximum value is the number of queue CUs
        divided by `16`.
        """
        return pulumi.get(self, "max_instance")

    @_builtins.property
    @pulumi.getter(name="maxPrefetchInstance")
    def max_prefetch_instance(self) -> Optional[_builtins.str]:
        """
        Specifies the maximum number of spark drivers to be pre-started on the queue.
        The minimum value is `0`. If the `cu_count` is less than `32`, the maximum value is `1`.
        If the `cu_count` is greater than or equal to `32`, the maximum value is the number of queue CUs divided by `16`.

        > If the minimum CUs of the queue is less than `16` CUs, the `max_instance` and `max_prefetch_instance` parameters
        does not take effect.
        """
        return pulumi.get(self, "max_prefetch_instance")


@pulumi.output_type
class QueueV1ScalingPolicy(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "impactStartTime":
            suggest = "impact_start_time"
        elif key == "impactStopTime":
            suggest = "impact_stop_time"
        elif key == "maxCu":
            suggest = "max_cu"
        elif key == "minCu":
            suggest = "min_cu"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QueueV1ScalingPolicy. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QueueV1ScalingPolicy.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QueueV1ScalingPolicy.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 impact_start_time: _builtins.str,
                 impact_stop_time: _builtins.str,
                 max_cu: _builtins.int,
                 min_cu: _builtins.int,
                 priority: _builtins.int):
        pulumi.set(__self__, "impact_start_time", impact_start_time)
        pulumi.set(__self__, "impact_stop_time", impact_stop_time)
        pulumi.set(__self__, "max_cu", max_cu)
        pulumi.set(__self__, "min_cu", min_cu)
        pulumi.set(__self__, "priority", priority)

    @_builtins.property
    @pulumi.getter(name="impactStartTime")
    def impact_start_time(self) -> _builtins.str:
        return pulumi.get(self, "impact_start_time")

    @_builtins.property
    @pulumi.getter(name="impactStopTime")
    def impact_stop_time(self) -> _builtins.str:
        return pulumi.get(self, "impact_stop_time")

    @_builtins.property
    @pulumi.getter(name="maxCu")
    def max_cu(self) -> _builtins.int:
        return pulumi.get(self, "max_cu")

    @_builtins.property
    @pulumi.getter(name="minCu")
    def min_cu(self) -> _builtins.int:
        return pulumi.get(self, "min_cu")

    @_builtins.property
    @pulumi.getter
    def priority(self) -> _builtins.int:
        return pulumi.get(self, "priority")


@pulumi.output_type
class QueueV1SparkDriver(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxConcurrent":
            suggest = "max_concurrent"
        elif key == "maxInstance":
            suggest = "max_instance"
        elif key == "maxPrefetchInstance":
            suggest = "max_prefetch_instance"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QueueV1SparkDriver. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QueueV1SparkDriver.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QueueV1SparkDriver.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_concurrent: Optional[_builtins.int] = None,
                 max_instance: Optional[_builtins.int] = None,
                 max_prefetch_instance: Optional[_builtins.str] = None):
        if max_concurrent is not None:
            pulumi.set(__self__, "max_concurrent", max_concurrent)
        if max_instance is not None:
            pulumi.set(__self__, "max_instance", max_instance)
        if max_prefetch_instance is not None:
            pulumi.set(__self__, "max_prefetch_instance", max_prefetch_instance)

    @_builtins.property
    @pulumi.getter(name="maxConcurrent")
    def max_concurrent(self) -> Optional[_builtins.int]:
        return pulumi.get(self, "max_concurrent")

    @_builtins.property
    @pulumi.getter(name="maxInstance")
    def max_instance(self) -> Optional[_builtins.int]:
        return pulumi.get(self, "max_instance")

    @_builtins.property
    @pulumi.getter(name="maxPrefetchInstance")
    def max_prefetch_instance(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "max_prefetch_instance")


@pulumi.output_type
class SparkJobDependentPackage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "groupName":
            suggest = "group_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SparkJobDependentPackage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SparkJobDependentPackage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SparkJobDependentPackage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 group_name: _builtins.str,
                 packages: Sequence['outputs.SparkJobDependentPackagePackage']):
        """
        :param _builtins.str group_name: Specifies the user group name.  
               Only letters, digits, dots (.), hyphens (-) and underscores (_) are allowed.
               Changing this parameter will submit a new spark job.
        :param Sequence['SparkJobDependentPackagePackageArgs'] packages: Specifies the user group resource for details.
               Changing this parameter will submit a new spark job.
               The object structure is documented below.
               
               <a name="dependent_packages_packages"></a>
               The `packages` block supports:
        """
        pulumi.set(__self__, "group_name", group_name)
        pulumi.set(__self__, "packages", packages)

    @_builtins.property
    @pulumi.getter(name="groupName")
    def group_name(self) -> _builtins.str:
        """
        Specifies the user group name.  
        Only letters, digits, dots (.), hyphens (-) and underscores (_) are allowed.
        Changing this parameter will submit a new spark job.
        """
        return pulumi.get(self, "group_name")

    @_builtins.property
    @pulumi.getter
    def packages(self) -> Sequence['outputs.SparkJobDependentPackagePackage']:
        """
        Specifies the user group resource for details.
        Changing this parameter will submit a new spark job.
        The object structure is documented below.

        <a name="dependent_packages_packages"></a>
        The `packages` block supports:
        """
        return pulumi.get(self, "packages")


@pulumi.output_type
class SparkJobDependentPackagePackage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "packageName":
            suggest = "package_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SparkJobDependentPackagePackage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SparkJobDependentPackagePackage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SparkJobDependentPackagePackage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 package_name: _builtins.str,
                 type: _builtins.str):
        """
        :param _builtins.str package_name: Specifies the resource name of the package.
               Changing this parameter will submit a new spark job.
        :param _builtins.str type: Specifies the resource type of the package.
               Changing this parameter will submit a new spark job.
        """
        pulumi.set(__self__, "package_name", package_name)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter(name="packageName")
    def package_name(self) -> _builtins.str:
        """
        Specifies the resource name of the package.
        Changing this parameter will submit a new spark job.
        """
        return pulumi.get(self, "package_name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Specifies the resource type of the package.
        Changing this parameter will submit a new spark job.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class SparkTemplateBody(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "appName":
            suggest = "app_name"
        elif key == "appParameters":
            suggest = "app_parameters"
        elif key == "autoRecovery":
            suggest = "auto_recovery"
        elif key == "dependentPackages":
            suggest = "dependent_packages"
        elif key == "driverCores":
            suggest = "driver_cores"
        elif key == "driverMemory":
            suggest = "driver_memory"
        elif key == "executorCores":
            suggest = "executor_cores"
        elif key == "executorMemory":
            suggest = "executor_memory"
        elif key == "mainClass":
            suggest = "main_class"
        elif key == "maxRetryTimes":
            suggest = "max_retry_times"
        elif key == "numExecutors":
            suggest = "num_executors"
        elif key == "obsBucket":
            suggest = "obs_bucket"
        elif key == "pythonFiles":
            suggest = "python_files"
        elif key == "queueName":
            suggest = "queue_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SparkTemplateBody. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SparkTemplateBody.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SparkTemplateBody.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 app_name: Optional[_builtins.str] = None,
                 app_parameters: Optional[Sequence[_builtins.str]] = None,
                 auto_recovery: Optional[_builtins.bool] = None,
                 configurations: Optional[Mapping[str, _builtins.str]] = None,
                 dependent_packages: Optional[Sequence['outputs.SparkTemplateBodyDependentPackage']] = None,
                 driver_cores: Optional[_builtins.int] = None,
                 driver_memory: Optional[_builtins.str] = None,
                 executor_cores: Optional[_builtins.int] = None,
                 executor_memory: Optional[_builtins.str] = None,
                 files: Optional[Sequence[_builtins.str]] = None,
                 jars: Optional[Sequence[_builtins.str]] = None,
                 main_class: Optional[_builtins.str] = None,
                 max_retry_times: Optional[_builtins.int] = None,
                 modules: Optional[Sequence[_builtins.str]] = None,
                 name: Optional[_builtins.str] = None,
                 num_executors: Optional[_builtins.int] = None,
                 obs_bucket: Optional[_builtins.str] = None,
                 python_files: Optional[Sequence[_builtins.str]] = None,
                 queue_name: Optional[_builtins.str] = None,
                 resources: Optional[Sequence['outputs.SparkTemplateBodyResource']] = None,
                 specification: Optional[_builtins.str] = None):
        """
        :param _builtins.str app_name: Name of the package that is of the JAR or pyFile type.  
               You can also specify an OBS path, for example, obs://Bucket name/Package name.
        :param Sequence[_builtins.str] app_parameters: Input parameters of the main class, that is application parameters.
        :param _builtins.bool auto_recovery: Whether to enable the retry function.  
               If enabled, Spark jobs will be automatically retried after an exception occurs.
               The default value is false.
        :param Mapping[str, _builtins.str] configurations: The configuration items of the DLI spark.  
               For details, see [Spark configuration](https://spark.apache.org/docs/latest/configuration.html)
               If you want to enable the **access metadata** of DLI spark in HuaweiCloud, please set
               **spark.dli.metaAccess.enable** to **true**.
        :param Sequence['SparkTemplateBodyDependentPackageArgs'] dependent_packages: The list of package resource objects.  
               The dependent_packages structure is documented below.
        :param _builtins.int driver_cores: Number of CPU cores of the Spark application driver.  
               This configuration item replaces the default parameter in **specification**.
        :param _builtins.str driver_memory: Driver memory of the Spark application, for example, 2 GB and 2048 MB.  
               This configuration item replaces the default parameter in **specification**.
               The unit must be provided. Otherwise, the startup fails.
        :param _builtins.int executor_cores: Number of CPU cores of each Executor in the Spark application.  
               This configuration item replaces the default parameter in **specification**.
        :param _builtins.str executor_memory: Executor memory of the Spark application, for example, 2 GB and 2048 MB.  
               This configuration item replaces the default parameter in **specification**.
               The unit must be provided. Otherwise, the startup fails.
        :param Sequence[_builtins.str] files: Name of the package that is of the file type and has been uploaded to the
               DLI resource management system. You can also specify an OBS path, for example, obs://Bucket name/Package name.
        :param Sequence[_builtins.str] jars: Name of the package that is of the JAR type and has been uploaded to the DLI
               resource management system. You can also specify an OBS path, for example, obs://Bucket name/Package name.
        :param _builtins.str main_class: Java/Spark main class of the template.
        :param _builtins.int max_retry_times: Maximum retry times.  
               The maximum value is 100, and the default value is 20.
               
               <a name="SparkTemplate_Resources"></a>
               The `resources` block supports:
        :param Sequence[_builtins.str] modules: Name of the dependent system resource module.
               DLI provides dependencies for executing datasource jobs.
               The dependent modules and corresponding services are as follows.
               + **sys.datasource.hbase**: CloudTable/MRS HBase
               + **sys.datasource.opentsdb**: CloudTable/MRS OpenTSDB
               + **sys.datasource.rds**: RDS MySQL
               + **sys.datasource.css**: CSS
        :param _builtins.str name: User group name.
        :param _builtins.int num_executors: Number of Executors in a Spark application.  
               This configuration item replaces the default parameter in **specification**.
        :param _builtins.str obs_bucket: OBS bucket for storing the Spark jobs.  
               Set this parameter when you need to save jobs.
        :param Sequence[_builtins.str] python_files: Name of the package that is of the PyFile type and has been uploaded to the DLI
               resource management system. You can also specify an OBS path, for example, obs://Bucket name/Package name.
        :param _builtins.str queue_name: The DLI queue name.
        :param Sequence['SparkTemplateBodyResourceArgs'] resources: User group resource.
               The resources structure is documented above.
        :param _builtins.str specification: Compute resource type. Currently, resource types A, B, and C are available.  
               The available types and related specifications are as follows, default to minimum configuration (type **A**).
               
               | type | resource | driver cores | executor cores | driver memory | executor memory | num executor |
               | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
               | A | 8 vCPUs, 32-GB memory | 2 | 1 | 7G | 4G | 6 |
               | B | 16 vCPUs, 64-GB memory | 2 | 2 | 7G | 8G | 7 |
               | C | 32 vCPUs, 128-GB memory | 4 | 2 | 12G | 8G | 14 |
        """
        if app_name is not None:
            pulumi.set(__self__, "app_name", app_name)
        if app_parameters is not None:
            pulumi.set(__self__, "app_parameters", app_parameters)
        if auto_recovery is not None:
            pulumi.set(__self__, "auto_recovery", auto_recovery)
        if configurations is not None:
            pulumi.set(__self__, "configurations", configurations)
        if dependent_packages is not None:
            pulumi.set(__self__, "dependent_packages", dependent_packages)
        if driver_cores is not None:
            pulumi.set(__self__, "driver_cores", driver_cores)
        if driver_memory is not None:
            pulumi.set(__self__, "driver_memory", driver_memory)
        if executor_cores is not None:
            pulumi.set(__self__, "executor_cores", executor_cores)
        if executor_memory is not None:
            pulumi.set(__self__, "executor_memory", executor_memory)
        if files is not None:
            pulumi.set(__self__, "files", files)
        if jars is not None:
            pulumi.set(__self__, "jars", jars)
        if main_class is not None:
            pulumi.set(__self__, "main_class", main_class)
        if max_retry_times is not None:
            pulumi.set(__self__, "max_retry_times", max_retry_times)
        if modules is not None:
            pulumi.set(__self__, "modules", modules)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if num_executors is not None:
            pulumi.set(__self__, "num_executors", num_executors)
        if obs_bucket is not None:
            pulumi.set(__self__, "obs_bucket", obs_bucket)
        if python_files is not None:
            pulumi.set(__self__, "python_files", python_files)
        if queue_name is not None:
            pulumi.set(__self__, "queue_name", queue_name)
        if resources is not None:
            pulumi.set(__self__, "resources", resources)
        if specification is not None:
            pulumi.set(__self__, "specification", specification)

    @_builtins.property
    @pulumi.getter(name="appName")
    def app_name(self) -> Optional[_builtins.str]:
        """
        Name of the package that is of the JAR or pyFile type.  
        You can also specify an OBS path, for example, obs://Bucket name/Package name.
        """
        return pulumi.get(self, "app_name")

    @_builtins.property
    @pulumi.getter(name="appParameters")
    def app_parameters(self) -> Optional[Sequence[_builtins.str]]:
        """
        Input parameters of the main class, that is application parameters.
        """
        return pulumi.get(self, "app_parameters")

    @_builtins.property
    @pulumi.getter(name="autoRecovery")
    def auto_recovery(self) -> Optional[_builtins.bool]:
        """
        Whether to enable the retry function.  
        If enabled, Spark jobs will be automatically retried after an exception occurs.
        The default value is false.
        """
        return pulumi.get(self, "auto_recovery")

    @_builtins.property
    @pulumi.getter
    def configurations(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The configuration items of the DLI spark.  
        For details, see [Spark configuration](https://spark.apache.org/docs/latest/configuration.html)
        If you want to enable the **access metadata** of DLI spark in HuaweiCloud, please set
        **spark.dli.metaAccess.enable** to **true**.
        """
        return pulumi.get(self, "configurations")

    @_builtins.property
    @pulumi.getter(name="dependentPackages")
    def dependent_packages(self) -> Optional[Sequence['outputs.SparkTemplateBodyDependentPackage']]:
        """
        The list of package resource objects.  
        The dependent_packages structure is documented below.
        """
        return pulumi.get(self, "dependent_packages")

    @_builtins.property
    @pulumi.getter(name="driverCores")
    def driver_cores(self) -> Optional[_builtins.int]:
        """
        Number of CPU cores of the Spark application driver.  
        This configuration item replaces the default parameter in **specification**.
        """
        return pulumi.get(self, "driver_cores")

    @_builtins.property
    @pulumi.getter(name="driverMemory")
    def driver_memory(self) -> Optional[_builtins.str]:
        """
        Driver memory of the Spark application, for example, 2 GB and 2048 MB.  
        This configuration item replaces the default parameter in **specification**.
        The unit must be provided. Otherwise, the startup fails.
        """
        return pulumi.get(self, "driver_memory")

    @_builtins.property
    @pulumi.getter(name="executorCores")
    def executor_cores(self) -> Optional[_builtins.int]:
        """
        Number of CPU cores of each Executor in the Spark application.  
        This configuration item replaces the default parameter in **specification**.
        """
        return pulumi.get(self, "executor_cores")

    @_builtins.property
    @pulumi.getter(name="executorMemory")
    def executor_memory(self) -> Optional[_builtins.str]:
        """
        Executor memory of the Spark application, for example, 2 GB and 2048 MB.  
        This configuration item replaces the default parameter in **specification**.
        The unit must be provided. Otherwise, the startup fails.
        """
        return pulumi.get(self, "executor_memory")

    @_builtins.property
    @pulumi.getter
    def files(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the package that is of the file type and has been uploaded to the
        DLI resource management system. You can also specify an OBS path, for example, obs://Bucket name/Package name.
        """
        return pulumi.get(self, "files")

    @_builtins.property
    @pulumi.getter
    def jars(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the package that is of the JAR type and has been uploaded to the DLI
        resource management system. You can also specify an OBS path, for example, obs://Bucket name/Package name.
        """
        return pulumi.get(self, "jars")

    @_builtins.property
    @pulumi.getter(name="mainClass")
    def main_class(self) -> Optional[_builtins.str]:
        """
        Java/Spark main class of the template.
        """
        return pulumi.get(self, "main_class")

    @_builtins.property
    @pulumi.getter(name="maxRetryTimes")
    def max_retry_times(self) -> Optional[_builtins.int]:
        """
        Maximum retry times.  
        The maximum value is 100, and the default value is 20.

        <a name="SparkTemplate_Resources"></a>
        The `resources` block supports:
        """
        return pulumi.get(self, "max_retry_times")

    @_builtins.property
    @pulumi.getter
    def modules(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the dependent system resource module.
        DLI provides dependencies for executing datasource jobs.
        The dependent modules and corresponding services are as follows.
        + **sys.datasource.hbase**: CloudTable/MRS HBase
        + **sys.datasource.opentsdb**: CloudTable/MRS OpenTSDB
        + **sys.datasource.rds**: RDS MySQL
        + **sys.datasource.css**: CSS
        """
        return pulumi.get(self, "modules")

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        User group name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="numExecutors")
    def num_executors(self) -> Optional[_builtins.int]:
        """
        Number of Executors in a Spark application.  
        This configuration item replaces the default parameter in **specification**.
        """
        return pulumi.get(self, "num_executors")

    @_builtins.property
    @pulumi.getter(name="obsBucket")
    def obs_bucket(self) -> Optional[_builtins.str]:
        """
        OBS bucket for storing the Spark jobs.  
        Set this parameter when you need to save jobs.
        """
        return pulumi.get(self, "obs_bucket")

    @_builtins.property
    @pulumi.getter(name="pythonFiles")
    def python_files(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the package that is of the PyFile type and has been uploaded to the DLI
        resource management system. You can also specify an OBS path, for example, obs://Bucket name/Package name.
        """
        return pulumi.get(self, "python_files")

    @_builtins.property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> Optional[_builtins.str]:
        """
        The DLI queue name.
        """
        return pulumi.get(self, "queue_name")

    @_builtins.property
    @pulumi.getter
    def resources(self) -> Optional[Sequence['outputs.SparkTemplateBodyResource']]:
        """
        User group resource.
        The resources structure is documented above.
        """
        return pulumi.get(self, "resources")

    @_builtins.property
    @pulumi.getter
    def specification(self) -> Optional[_builtins.str]:
        """
        Compute resource type. Currently, resource types A, B, and C are available.  
        The available types and related specifications are as follows, default to minimum configuration (type **A**).

        | type | resource | driver cores | executor cores | driver memory | executor memory | num executor |
        | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
        | A | 8 vCPUs, 32-GB memory | 2 | 1 | 7G | 4G | 6 |
        | B | 16 vCPUs, 64-GB memory | 2 | 2 | 7G | 8G | 7 |
        | C | 32 vCPUs, 128-GB memory | 4 | 2 | 12G | 8G | 14 |
        """
        return pulumi.get(self, "specification")


@pulumi.output_type
class SparkTemplateBodyDependentPackage(dict):
    def __init__(__self__, *,
                 name: Optional[_builtins.str] = None,
                 resources: Optional[Sequence['outputs.SparkTemplateBodyDependentPackageResource']] = None):
        """
        :param _builtins.str name: User group name.
        :param Sequence['SparkTemplateBodyDependentPackageResourceArgs'] resources: User group resource.
               The resources structure is documented above.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if resources is not None:
            pulumi.set(__self__, "resources", resources)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        User group name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def resources(self) -> Optional[Sequence['outputs.SparkTemplateBodyDependentPackageResource']]:
        """
        User group resource.
        The resources structure is documented above.
        """
        return pulumi.get(self, "resources")


@pulumi.output_type
class SparkTemplateBodyDependentPackageResource(dict):
    def __init__(__self__, *,
                 name: Optional[_builtins.str] = None,
                 type: Optional[_builtins.str] = None):
        """
        :param _builtins.str name: User group name.
        :param _builtins.str type: Resource type.
               
               <a name="SparkTemplate_Dependent_packages"></a>
               The `dependent_packages` block supports:
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        User group name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[_builtins.str]:
        """
        Resource type.

        <a name="SparkTemplate_Dependent_packages"></a>
        The `dependent_packages` block supports:
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class SparkTemplateBodyResource(dict):
    def __init__(__self__, *,
                 name: Optional[_builtins.str] = None,
                 type: Optional[_builtins.str] = None):
        """
        :param _builtins.str name: User group name.
        :param _builtins.str type: Resource type.
               
               <a name="SparkTemplate_Dependent_packages"></a>
               The `dependent_packages` block supports:
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        User group name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[_builtins.str]:
        """
        Resource type.

        <a name="SparkTemplate_Dependent_packages"></a>
        The `dependent_packages` block supports:
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class SqlJobConf(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dliSqlJobTimeout":
            suggest = "dli_sql_job_timeout"
        elif key == "dliSqlSqlasyncEnabled":
            suggest = "dli_sql_sqlasync_enabled"
        elif key == "sparkSqlAutoBroadcastJoinThreshold":
            suggest = "spark_sql_auto_broadcast_join_threshold"
        elif key == "sparkSqlBadRecordsPath":
            suggest = "spark_sql_bad_records_path"
        elif key == "sparkSqlDynamicPartitionOverwriteEnabled":
            suggest = "spark_sql_dynamic_partition_overwrite_enabled"
        elif key == "sparkSqlFilesMaxPartitionBytes":
            suggest = "spark_sql_files_max_partition_bytes"
        elif key == "sparkSqlMaxRecordsPerFile":
            suggest = "spark_sql_max_records_per_file"
        elif key == "sparkSqlShufflePartitions":
            suggest = "spark_sql_shuffle_partitions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlJobConf. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlJobConf.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlJobConf.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dli_sql_job_timeout: Optional[_builtins.int] = None,
                 dli_sql_sqlasync_enabled: Optional[_builtins.bool] = None,
                 spark_sql_auto_broadcast_join_threshold: Optional[_builtins.int] = None,
                 spark_sql_bad_records_path: Optional[_builtins.str] = None,
                 spark_sql_dynamic_partition_overwrite_enabled: Optional[_builtins.bool] = None,
                 spark_sql_files_max_partition_bytes: Optional[_builtins.int] = None,
                 spark_sql_max_records_per_file: Optional[_builtins.int] = None,
                 spark_sql_shuffle_partitions: Optional[_builtins.int] = None):
        """
        :param _builtins.int dli_sql_job_timeout: Sets the job running timeout interval. If the timeout interval
               expires, the job is canceled. Unit: `ms`. Changing this parameter will create a new resource.
        :param _builtins.bool dli_sql_sqlasync_enabled: Specifies whether DDL and DCL statements are executed
               asynchronously. The value true indicates that asynchronous execution is enabled. Default value is `false`.
               Changing this parameter will create a new resource.
        :param _builtins.int spark_sql_auto_broadcast_join_threshold: Maximum size of the table that
               displays all working nodes when a connection is executed. You can set this parameter to -1 to disable the display.
               Default value is `209715200`. Changing this parameter will create a new resource.
               
               > Currently, only the configuration unit metastore table that runs the ANALYZE TABLE COMPUTE statistics noscan
               command and the file-based data source table that directly calculates statistics based on data files are supported.
               Changing this parameter will create a new resource.
        :param _builtins.str spark_sql_bad_records_path: Path of bad records. Changing this parameter will create
               a new resource.
        :param _builtins.bool spark_sql_dynamic_partition_overwrite_enabled: In dynamic mode, Spark does not delete
               the previous partitions and only overwrites the partitions without data during execution. Default value is `false`.
               Changing this parameter will create a new resource.
        :param _builtins.int spark_sql_files_max_partition_bytes: Maximum number of bytes to be packed into a
               single partition when a file is read. Default value is `134217728`. Changing this parameter will create a new
               resource.
        :param _builtins.int spark_sql_max_records_per_file: Maximum number of records to be written
               into a single file. If the value is zero or negative, there is no limit. Default value is `0`.
               Changing this parameter will create a new resource.
        :param _builtins.int spark_sql_shuffle_partitions: Default number of partitions used to filter
               data for join or aggregation. Default value is `4096`. Changing this parameter will create a new resource.
        """
        if dli_sql_job_timeout is not None:
            pulumi.set(__self__, "dli_sql_job_timeout", dli_sql_job_timeout)
        if dli_sql_sqlasync_enabled is not None:
            pulumi.set(__self__, "dli_sql_sqlasync_enabled", dli_sql_sqlasync_enabled)
        if spark_sql_auto_broadcast_join_threshold is not None:
            pulumi.set(__self__, "spark_sql_auto_broadcast_join_threshold", spark_sql_auto_broadcast_join_threshold)
        if spark_sql_bad_records_path is not None:
            pulumi.set(__self__, "spark_sql_bad_records_path", spark_sql_bad_records_path)
        if spark_sql_dynamic_partition_overwrite_enabled is not None:
            pulumi.set(__self__, "spark_sql_dynamic_partition_overwrite_enabled", spark_sql_dynamic_partition_overwrite_enabled)
        if spark_sql_files_max_partition_bytes is not None:
            pulumi.set(__self__, "spark_sql_files_max_partition_bytes", spark_sql_files_max_partition_bytes)
        if spark_sql_max_records_per_file is not None:
            pulumi.set(__self__, "spark_sql_max_records_per_file", spark_sql_max_records_per_file)
        if spark_sql_shuffle_partitions is not None:
            pulumi.set(__self__, "spark_sql_shuffle_partitions", spark_sql_shuffle_partitions)

    @_builtins.property
    @pulumi.getter(name="dliSqlJobTimeout")
    def dli_sql_job_timeout(self) -> Optional[_builtins.int]:
        """
        Sets the job running timeout interval. If the timeout interval
        expires, the job is canceled. Unit: `ms`. Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "dli_sql_job_timeout")

    @_builtins.property
    @pulumi.getter(name="dliSqlSqlasyncEnabled")
    def dli_sql_sqlasync_enabled(self) -> Optional[_builtins.bool]:
        """
        Specifies whether DDL and DCL statements are executed
        asynchronously. The value true indicates that asynchronous execution is enabled. Default value is `false`.
        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "dli_sql_sqlasync_enabled")

    @_builtins.property
    @pulumi.getter(name="sparkSqlAutoBroadcastJoinThreshold")
    def spark_sql_auto_broadcast_join_threshold(self) -> Optional[_builtins.int]:
        """
        Maximum size of the table that
        displays all working nodes when a connection is executed. You can set this parameter to -1 to disable the display.
        Default value is `209715200`. Changing this parameter will create a new resource.

        > Currently, only the configuration unit metastore table that runs the ANALYZE TABLE COMPUTE statistics noscan
        command and the file-based data source table that directly calculates statistics based on data files are supported.
        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "spark_sql_auto_broadcast_join_threshold")

    @_builtins.property
    @pulumi.getter(name="sparkSqlBadRecordsPath")
    def spark_sql_bad_records_path(self) -> Optional[_builtins.str]:
        """
        Path of bad records. Changing this parameter will create
        a new resource.
        """
        return pulumi.get(self, "spark_sql_bad_records_path")

    @_builtins.property
    @pulumi.getter(name="sparkSqlDynamicPartitionOverwriteEnabled")
    def spark_sql_dynamic_partition_overwrite_enabled(self) -> Optional[_builtins.bool]:
        """
        In dynamic mode, Spark does not delete
        the previous partitions and only overwrites the partitions without data during execution. Default value is `false`.
        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "spark_sql_dynamic_partition_overwrite_enabled")

    @_builtins.property
    @pulumi.getter(name="sparkSqlFilesMaxPartitionBytes")
    def spark_sql_files_max_partition_bytes(self) -> Optional[_builtins.int]:
        """
        Maximum number of bytes to be packed into a
        single partition when a file is read. Default value is `134217728`. Changing this parameter will create a new
        resource.
        """
        return pulumi.get(self, "spark_sql_files_max_partition_bytes")

    @_builtins.property
    @pulumi.getter(name="sparkSqlMaxRecordsPerFile")
    def spark_sql_max_records_per_file(self) -> Optional[_builtins.int]:
        """
        Maximum number of records to be written
        into a single file. If the value is zero or negative, there is no limit. Default value is `0`.
        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "spark_sql_max_records_per_file")

    @_builtins.property
    @pulumi.getter(name="sparkSqlShufflePartitions")
    def spark_sql_shuffle_partitions(self) -> Optional[_builtins.int]:
        """
        Default number of partitions used to filter
        data for join or aggregation. Default value is `4096`. Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "spark_sql_shuffle_partitions")


@pulumi.output_type
class TableColumn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "isPartition":
            suggest = "is_partition"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in TableColumn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        TableColumn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        TableColumn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: _builtins.str,
                 type: _builtins.str,
                 description: Optional[_builtins.str] = None,
                 is_partition: Optional[_builtins.bool] = None):
        """
        :param _builtins.str name: Specifies the table name. The name can contain only digits, letters,
               and underscores, but cannot contain only digits or start with an underscore. Length range: 1 to 128 characters.
               Changing this parameter will create a new resource.
        :param _builtins.str type: Specifies data type of column. Changing this parameter will create a new
               resource.
        :param _builtins.str description: Specifies description of the table.
               Changing this parameter will create a new resource.
        :param _builtins.bool is_partition: Specifies whether the column is a partition column. The value
               `true` indicates a partition column, and the value false indicates a non-partition column. The default value
               is false. Changing this parameter will create a new resource.
               
               > When creating a partition table, ensure that at least one column in the table is a non-partition column.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "type", type)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if is_partition is not None:
            pulumi.set(__self__, "is_partition", is_partition)

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the table name. The name can contain only digits, letters,
        and underscores, but cannot contain only digits or start with an underscore. Length range: 1 to 128 characters.
        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Specifies data type of column. Changing this parameter will create a new
        resource.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter
    def description(self) -> Optional[_builtins.str]:
        """
        Specifies description of the table.
        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter(name="isPartition")
    def is_partition(self) -> Optional[_builtins.bool]:
        """
        Specifies whether the column is a partition column. The value
        `true` indicates a partition column, and the value false indicates a non-partition column. The default value
        is false. Changing this parameter will create a new resource.

        > When creating a partition table, ensure that at least one column in the table is a non-partition column.
        """
        return pulumi.get(self, "is_partition")


@pulumi.output_type
class TemplateSparkBody(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "appName":
            suggest = "app_name"
        elif key == "appParameters":
            suggest = "app_parameters"
        elif key == "autoRecovery":
            suggest = "auto_recovery"
        elif key == "dependentPackages":
            suggest = "dependent_packages"
        elif key == "driverCores":
            suggest = "driver_cores"
        elif key == "driverMemory":
            suggest = "driver_memory"
        elif key == "executorCores":
            suggest = "executor_cores"
        elif key == "executorMemory":
            suggest = "executor_memory"
        elif key == "mainClass":
            suggest = "main_class"
        elif key == "maxRetryTimes":
            suggest = "max_retry_times"
        elif key == "numExecutors":
            suggest = "num_executors"
        elif key == "obsBucket":
            suggest = "obs_bucket"
        elif key == "pythonFiles":
            suggest = "python_files"
        elif key == "queueName":
            suggest = "queue_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in TemplateSparkBody. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        TemplateSparkBody.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        TemplateSparkBody.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 app_name: Optional[_builtins.str] = None,
                 app_parameters: Optional[Sequence[_builtins.str]] = None,
                 auto_recovery: Optional[_builtins.bool] = None,
                 configurations: Optional[Mapping[str, _builtins.str]] = None,
                 dependent_packages: Optional[Sequence['outputs.TemplateSparkBodyDependentPackage']] = None,
                 driver_cores: Optional[_builtins.int] = None,
                 driver_memory: Optional[_builtins.str] = None,
                 executor_cores: Optional[_builtins.int] = None,
                 executor_memory: Optional[_builtins.str] = None,
                 files: Optional[Sequence[_builtins.str]] = None,
                 jars: Optional[Sequence[_builtins.str]] = None,
                 main_class: Optional[_builtins.str] = None,
                 max_retry_times: Optional[_builtins.int] = None,
                 modules: Optional[Sequence[_builtins.str]] = None,
                 name: Optional[_builtins.str] = None,
                 num_executors: Optional[_builtins.int] = None,
                 obs_bucket: Optional[_builtins.str] = None,
                 python_files: Optional[Sequence[_builtins.str]] = None,
                 queue_name: Optional[_builtins.str] = None,
                 resources: Optional[Sequence['outputs.TemplateSparkBodyResource']] = None,
                 specification: Optional[_builtins.str] = None):
        """
        :param _builtins.str app_name: Name of the package that is of the JAR or pyFile type.
        :param Sequence[_builtins.str] app_parameters: Input parameters of the main class, that is application parameters.
        :param _builtins.bool auto_recovery: Whether to enable the retry function.
        :param Mapping[str, _builtins.str] configurations: The configuration items of the DLI spark.
        :param Sequence['TemplateSparkBodyDependentPackageArgs'] dependent_packages: The list of package resource objects.
        :param _builtins.int driver_cores: Number of CPU cores of the Spark application driver.
        :param _builtins.str driver_memory: Driver memory of the Spark application, for example, 2 GB and 2048 MB.
        :param _builtins.int executor_cores: Number of CPU cores of each Executor in the Spark application.
        :param _builtins.str executor_memory: Executor memory of the Spark application, for example, 2 GB and 2048 MB.
        :param Sequence[_builtins.str] files: Name of the package that is of the file type and has been uploaded to the DLI resource management system.
        :param Sequence[_builtins.str] jars: Name of the package that is of the JAR type and has been uploaded to the DLI resource management system.
        :param _builtins.str main_class: Java/Spark main class of the template.
        :param _builtins.int max_retry_times: Maximum retry times.
        :param Sequence[_builtins.str] modules: Name of the dependent system resource module.
        :param _builtins.str name: The spark job name.
        :param _builtins.int num_executors: Number of Executors in a Spark application.
        :param _builtins.str obs_bucket: OBS bucket for storing the Spark jobs.
        :param Sequence[_builtins.str] python_files: Name of the package that is of the PyFile type and has been uploaded to the DLI resource management system.
        :param _builtins.str queue_name: The DLI queue name.
        :param Sequence['TemplateSparkBodyResourceArgs'] resources: The list of resource objects.
        :param _builtins.str specification: Compute resource type. Currently, resource types A, B, and C are available.
        """
        if app_name is not None:
            pulumi.set(__self__, "app_name", app_name)
        if app_parameters is not None:
            pulumi.set(__self__, "app_parameters", app_parameters)
        if auto_recovery is not None:
            pulumi.set(__self__, "auto_recovery", auto_recovery)
        if configurations is not None:
            pulumi.set(__self__, "configurations", configurations)
        if dependent_packages is not None:
            pulumi.set(__self__, "dependent_packages", dependent_packages)
        if driver_cores is not None:
            pulumi.set(__self__, "driver_cores", driver_cores)
        if driver_memory is not None:
            pulumi.set(__self__, "driver_memory", driver_memory)
        if executor_cores is not None:
            pulumi.set(__self__, "executor_cores", executor_cores)
        if executor_memory is not None:
            pulumi.set(__self__, "executor_memory", executor_memory)
        if files is not None:
            pulumi.set(__self__, "files", files)
        if jars is not None:
            pulumi.set(__self__, "jars", jars)
        if main_class is not None:
            pulumi.set(__self__, "main_class", main_class)
        if max_retry_times is not None:
            pulumi.set(__self__, "max_retry_times", max_retry_times)
        if modules is not None:
            pulumi.set(__self__, "modules", modules)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if num_executors is not None:
            pulumi.set(__self__, "num_executors", num_executors)
        if obs_bucket is not None:
            pulumi.set(__self__, "obs_bucket", obs_bucket)
        if python_files is not None:
            pulumi.set(__self__, "python_files", python_files)
        if queue_name is not None:
            pulumi.set(__self__, "queue_name", queue_name)
        if resources is not None:
            pulumi.set(__self__, "resources", resources)
        if specification is not None:
            pulumi.set(__self__, "specification", specification)

    @_builtins.property
    @pulumi.getter(name="appName")
    def app_name(self) -> Optional[_builtins.str]:
        """
        Name of the package that is of the JAR or pyFile type.
        """
        return pulumi.get(self, "app_name")

    @_builtins.property
    @pulumi.getter(name="appParameters")
    def app_parameters(self) -> Optional[Sequence[_builtins.str]]:
        """
        Input parameters of the main class, that is application parameters.
        """
        return pulumi.get(self, "app_parameters")

    @_builtins.property
    @pulumi.getter(name="autoRecovery")
    def auto_recovery(self) -> Optional[_builtins.bool]:
        """
        Whether to enable the retry function.
        """
        return pulumi.get(self, "auto_recovery")

    @_builtins.property
    @pulumi.getter
    def configurations(self) -> Optional[Mapping[str, _builtins.str]]:
        """
        The configuration items of the DLI spark.
        """
        return pulumi.get(self, "configurations")

    @_builtins.property
    @pulumi.getter(name="dependentPackages")
    def dependent_packages(self) -> Optional[Sequence['outputs.TemplateSparkBodyDependentPackage']]:
        """
        The list of package resource objects.
        """
        return pulumi.get(self, "dependent_packages")

    @_builtins.property
    @pulumi.getter(name="driverCores")
    def driver_cores(self) -> Optional[_builtins.int]:
        """
        Number of CPU cores of the Spark application driver.
        """
        return pulumi.get(self, "driver_cores")

    @_builtins.property
    @pulumi.getter(name="driverMemory")
    def driver_memory(self) -> Optional[_builtins.str]:
        """
        Driver memory of the Spark application, for example, 2 GB and 2048 MB.
        """
        return pulumi.get(self, "driver_memory")

    @_builtins.property
    @pulumi.getter(name="executorCores")
    def executor_cores(self) -> Optional[_builtins.int]:
        """
        Number of CPU cores of each Executor in the Spark application.
        """
        return pulumi.get(self, "executor_cores")

    @_builtins.property
    @pulumi.getter(name="executorMemory")
    def executor_memory(self) -> Optional[_builtins.str]:
        """
        Executor memory of the Spark application, for example, 2 GB and 2048 MB.
        """
        return pulumi.get(self, "executor_memory")

    @_builtins.property
    @pulumi.getter
    def files(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the package that is of the file type and has been uploaded to the DLI resource management system.
        """
        return pulumi.get(self, "files")

    @_builtins.property
    @pulumi.getter
    def jars(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the package that is of the JAR type and has been uploaded to the DLI resource management system.
        """
        return pulumi.get(self, "jars")

    @_builtins.property
    @pulumi.getter(name="mainClass")
    def main_class(self) -> Optional[_builtins.str]:
        """
        Java/Spark main class of the template.
        """
        return pulumi.get(self, "main_class")

    @_builtins.property
    @pulumi.getter(name="maxRetryTimes")
    def max_retry_times(self) -> Optional[_builtins.int]:
        """
        Maximum retry times.
        """
        return pulumi.get(self, "max_retry_times")

    @_builtins.property
    @pulumi.getter
    def modules(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the dependent system resource module.
        """
        return pulumi.get(self, "modules")

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        The spark job name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="numExecutors")
    def num_executors(self) -> Optional[_builtins.int]:
        """
        Number of Executors in a Spark application.
        """
        return pulumi.get(self, "num_executors")

    @_builtins.property
    @pulumi.getter(name="obsBucket")
    def obs_bucket(self) -> Optional[_builtins.str]:
        """
        OBS bucket for storing the Spark jobs.
        """
        return pulumi.get(self, "obs_bucket")

    @_builtins.property
    @pulumi.getter(name="pythonFiles")
    def python_files(self) -> Optional[Sequence[_builtins.str]]:
        """
        Name of the package that is of the PyFile type and has been uploaded to the DLI resource management system.
        """
        return pulumi.get(self, "python_files")

    @_builtins.property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> Optional[_builtins.str]:
        """
        The DLI queue name.
        """
        return pulumi.get(self, "queue_name")

    @_builtins.property
    @pulumi.getter
    def resources(self) -> Optional[Sequence['outputs.TemplateSparkBodyResource']]:
        """
        The list of resource objects.
        """
        return pulumi.get(self, "resources")

    @_builtins.property
    @pulumi.getter
    def specification(self) -> Optional[_builtins.str]:
        """
        Compute resource type. Currently, resource types A, B, and C are available.
        """
        return pulumi.get(self, "specification")


@pulumi.output_type
class TemplateSparkBodyDependentPackage(dict):
    def __init__(__self__, *,
                 name: Optional[_builtins.str] = None,
                 resources: Optional[Sequence['outputs.TemplateSparkBodyDependentPackageResource']] = None):
        """
        :param _builtins.str name: User group name.
        :param Sequence['TemplateSparkBodyDependentPackageResourceArgs'] resources: User group resource.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if resources is not None:
            pulumi.set(__self__, "resources", resources)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        User group name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def resources(self) -> Optional[Sequence['outputs.TemplateSparkBodyDependentPackageResource']]:
        """
        User group resource.
        """
        return pulumi.get(self, "resources")


@pulumi.output_type
class TemplateSparkBodyDependentPackageResource(dict):
    def __init__(__self__, *,
                 name: Optional[_builtins.str] = None,
                 type: Optional[_builtins.str] = None):
        """
        :param _builtins.str name: Resource name.
        :param _builtins.str type: Resource type.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        Resource name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[_builtins.str]:
        """
        Resource type.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class TemplateSparkBodyResource(dict):
    def __init__(__self__, *,
                 name: Optional[_builtins.str] = None,
                 type: Optional[_builtins.str] = None):
        """
        :param _builtins.str name: Resource name.
        :param _builtins.str type: Resource type.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        Resource name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[_builtins.str]:
        """
        Resource type.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetDatasourceAuthsAuthResult(dict):
    def __init__(__self__, *,
                 certificate_location: _builtins.str,
                 created_at: _builtins.str,
                 keystore_location: _builtins.str,
                 keytab: _builtins.str,
                 krb5_conf: _builtins.str,
                 name: _builtins.str,
                 owner: _builtins.str,
                 truststore_location: _builtins.str,
                 type: _builtins.str,
                 updated_at: _builtins.str,
                 username: _builtins.str):
        """
        :param _builtins.str certificate_location: The OBS path of the security cluster certificate.
        :param _builtins.str created_at: The creation time of the datasource authentication.
        :param _builtins.str keystore_location: The OBS path of the **keystore** configuration file.
        :param _builtins.str keytab: The OBS path of the **keytab** configuration file.
        :param _builtins.str krb5_conf: The OBS path of the **krb5** configuration file.
        :param _builtins.str name: Specifies the name of the datasource authentication.
        :param _builtins.str owner: The user name of owner.
        :param _builtins.str truststore_location: The OBS path of the **truststore** configuration file.
        :param _builtins.str type: The type of the datasource authentication.
        :param _builtins.str updated_at: The latest update time of the datasource authentication.
        :param _builtins.str username: The login user name of the security cluster.
        """
        pulumi.set(__self__, "certificate_location", certificate_location)
        pulumi.set(__self__, "created_at", created_at)
        pulumi.set(__self__, "keystore_location", keystore_location)
        pulumi.set(__self__, "keytab", keytab)
        pulumi.set(__self__, "krb5_conf", krb5_conf)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "owner", owner)
        pulumi.set(__self__, "truststore_location", truststore_location)
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "updated_at", updated_at)
        pulumi.set(__self__, "username", username)

    @_builtins.property
    @pulumi.getter(name="certificateLocation")
    def certificate_location(self) -> _builtins.str:
        """
        The OBS path of the security cluster certificate.
        """
        return pulumi.get(self, "certificate_location")

    @_builtins.property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> _builtins.str:
        """
        The creation time of the datasource authentication.
        """
        return pulumi.get(self, "created_at")

    @_builtins.property
    @pulumi.getter(name="keystoreLocation")
    def keystore_location(self) -> _builtins.str:
        """
        The OBS path of the **keystore** configuration file.
        """
        return pulumi.get(self, "keystore_location")

    @_builtins.property
    @pulumi.getter
    def keytab(self) -> _builtins.str:
        """
        The OBS path of the **keytab** configuration file.
        """
        return pulumi.get(self, "keytab")

    @_builtins.property
    @pulumi.getter(name="krb5Conf")
    def krb5_conf(self) -> _builtins.str:
        """
        The OBS path of the **krb5** configuration file.
        """
        return pulumi.get(self, "krb5_conf")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the datasource authentication.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def owner(self) -> _builtins.str:
        """
        The user name of owner.
        """
        return pulumi.get(self, "owner")

    @_builtins.property
    @pulumi.getter(name="truststoreLocation")
    def truststore_location(self) -> _builtins.str:
        """
        The OBS path of the **truststore** configuration file.
        """
        return pulumi.get(self, "truststore_location")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The type of the datasource authentication.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> _builtins.str:
        """
        The latest update time of the datasource authentication.
        """
        return pulumi.get(self, "updated_at")

    @_builtins.property
    @pulumi.getter
    def username(self) -> _builtins.str:
        """
        The login user name of the security cluster.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class GetDatasourceConnectionsConnectionResult(dict):
    def __init__(__self__, *,
                 created_at: _builtins.str,
                 elastic_resource_pools: Sequence['outputs.GetDatasourceConnectionsConnectionElasticResourcePoolResult'],
                 hosts: Sequence['outputs.GetDatasourceConnectionsConnectionHostResult'],
                 id: _builtins.str,
                 is_privis: _builtins.bool,
                 name: _builtins.str,
                 queues: Sequence['outputs.GetDatasourceConnectionsConnectionQueueResult'],
                 routes: Sequence['outputs.GetDatasourceConnectionsConnectionRouteResult'],
                 status: _builtins.str,
                 subnet_id: _builtins.str,
                 vpc_id: _builtins.str):
        """
        :param _builtins.str created_at: The creation time of the route.
        :param Sequence['GetDatasourceConnectionsConnectionElasticResourcePoolArgs'] elastic_resource_pools: List of resource pools associated with the datasource connection.
               The elastic_resource_pools structure is documented below.
        :param Sequence['GetDatasourceConnectionsConnectionHostArgs'] hosts: List of the user-defined hosts information.
               The hosts structure is documented below.
        :param _builtins.str id: The peer ID of the datasource connection.
        :param _builtins.bool is_privis: Whether the data source connection has setted project permissions. The valid values are as follows:
               + **false**: Indicates that the project permission is granted.
               + **true**: Indicates that the project permission is not granted.
        :param _builtins.str name: Specifies the name of the datasource connection.
        :param Sequence['GetDatasourceConnectionsConnectionQueueArgs'] queues: List of queues associated with the datasource connection.
               The queues structure is documented below.
        :param Sequence['GetDatasourceConnectionsConnectionRouteArgs'] routes: List of routes.
               The routes structure is documented below.
        :param _builtins.str status: The status of the peering connection to which the datasource connection belongs.
        :param _builtins.str subnet_id: The subnet ID associated with the datasource connection.
        :param _builtins.str vpc_id: The VPC ID associated with the datasource connection.
        """
        pulumi.set(__self__, "created_at", created_at)
        pulumi.set(__self__, "elastic_resource_pools", elastic_resource_pools)
        pulumi.set(__self__, "hosts", hosts)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "is_privis", is_privis)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "queues", queues)
        pulumi.set(__self__, "routes", routes)
        pulumi.set(__self__, "status", status)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "vpc_id", vpc_id)

    @_builtins.property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> _builtins.str:
        """
        The creation time of the route.
        """
        return pulumi.get(self, "created_at")

    @_builtins.property
    @pulumi.getter(name="elasticResourcePools")
    def elastic_resource_pools(self) -> Sequence['outputs.GetDatasourceConnectionsConnectionElasticResourcePoolResult']:
        """
        List of resource pools associated with the datasource connection.
        The elastic_resource_pools structure is documented below.
        """
        return pulumi.get(self, "elastic_resource_pools")

    @_builtins.property
    @pulumi.getter
    def hosts(self) -> Sequence['outputs.GetDatasourceConnectionsConnectionHostResult']:
        """
        List of the user-defined hosts information.
        The hosts structure is documented below.
        """
        return pulumi.get(self, "hosts")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The peer ID of the datasource connection.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter(name="isPrivis")
    def is_privis(self) -> _builtins.bool:
        """
        Whether the data source connection has setted project permissions. The valid values are as follows:
        + **false**: Indicates that the project permission is granted.
        + **true**: Indicates that the project permission is not granted.
        """
        return pulumi.get(self, "is_privis")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the datasource connection.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def queues(self) -> Sequence['outputs.GetDatasourceConnectionsConnectionQueueResult']:
        """
        List of queues associated with the datasource connection.
        The queues structure is documented below.
        """
        return pulumi.get(self, "queues")

    @_builtins.property
    @pulumi.getter
    def routes(self) -> Sequence['outputs.GetDatasourceConnectionsConnectionRouteResult']:
        """
        List of routes.
        The routes structure is documented below.
        """
        return pulumi.get(self, "routes")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        The status of the peering connection to which the datasource connection belongs.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> _builtins.str:
        """
        The subnet ID associated with the datasource connection.
        """
        return pulumi.get(self, "subnet_id")

    @_builtins.property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> _builtins.str:
        """
        The VPC ID associated with the datasource connection.
        """
        return pulumi.get(self, "vpc_id")


@pulumi.output_type
class GetDatasourceConnectionsConnectionElasticResourcePoolResult(dict):
    def __init__(__self__, *,
                 error_msg: _builtins.str,
                 id: _builtins.str,
                 name: _builtins.str,
                 status: _builtins.str,
                 updated_at: _builtins.str):
        """
        :param _builtins.str error_msg: Error message when the Peering connection status status is falied.
        :param _builtins.str id: The peer ID of the datasource connection.
        :param _builtins.str name: Specifies the name of the datasource connection.
        :param _builtins.str status: The status of the peering connection to which the datasource connection belongs.
        :param _builtins.str updated_at: The latest update time of the elastic resource pool.
        """
        pulumi.set(__self__, "error_msg", error_msg)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "status", status)
        pulumi.set(__self__, "updated_at", updated_at)

    @_builtins.property
    @pulumi.getter(name="errorMsg")
    def error_msg(self) -> _builtins.str:
        """
        Error message when the Peering connection status status is falied.
        """
        return pulumi.get(self, "error_msg")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The peer ID of the datasource connection.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the datasource connection.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        The status of the peering connection to which the datasource connection belongs.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> _builtins.str:
        """
        The latest update time of the elastic resource pool.
        """
        return pulumi.get(self, "updated_at")


@pulumi.output_type
class GetDatasourceConnectionsConnectionHostResult(dict):
    def __init__(__self__, *,
                 ip: _builtins.str,
                 name: _builtins.str):
        """
        :param _builtins.str ip: IPv4 address of the host.
        :param _builtins.str name: Specifies the name of the datasource connection.
        """
        pulumi.set(__self__, "ip", ip)
        pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter
    def ip(self) -> _builtins.str:
        """
        IPv4 address of the host.
        """
        return pulumi.get(self, "ip")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the datasource connection.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetDatasourceConnectionsConnectionQueueResult(dict):
    def __init__(__self__, *,
                 error_msg: _builtins.str,
                 id: _builtins.str,
                 name: _builtins.str,
                 status: _builtins.str,
                 updated_at: _builtins.str):
        """
        :param _builtins.str error_msg: Error message when the Peering connection status status is falied.
        :param _builtins.str id: The peer ID of the datasource connection.
        :param _builtins.str name: Specifies the name of the datasource connection.
        :param _builtins.str status: The status of the peering connection to which the datasource connection belongs.
        :param _builtins.str updated_at: The latest update time of the elastic resource pool.
        """
        pulumi.set(__self__, "error_msg", error_msg)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "status", status)
        pulumi.set(__self__, "updated_at", updated_at)

    @_builtins.property
    @pulumi.getter(name="errorMsg")
    def error_msg(self) -> _builtins.str:
        """
        Error message when the Peering connection status status is falied.
        """
        return pulumi.get(self, "error_msg")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The peer ID of the datasource connection.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the datasource connection.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        The status of the peering connection to which the datasource connection belongs.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> _builtins.str:
        """
        The latest update time of the elastic resource pool.
        """
        return pulumi.get(self, "updated_at")


@pulumi.output_type
class GetDatasourceConnectionsConnectionRouteResult(dict):
    def __init__(__self__, *,
                 cidr: _builtins.str,
                 created_at: _builtins.str,
                 name: _builtins.str):
        """
        :param _builtins.str cidr: The CIDR of the route.
        :param _builtins.str created_at: The creation time of the route.
        :param _builtins.str name: Specifies the name of the datasource connection.
        """
        pulumi.set(__self__, "cidr", cidr)
        pulumi.set(__self__, "created_at", created_at)
        pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter
    def cidr(self) -> _builtins.str:
        """
        The CIDR of the route.
        """
        return pulumi.get(self, "cidr")

    @_builtins.property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> _builtins.str:
        """
        The creation time of the route.
        """
        return pulumi.get(self, "created_at")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the datasource connection.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetElasticResourcePoolsElasticResourcePoolResult(dict):
    def __init__(__self__, *,
                 actual_cu: _builtins.int,
                 cidr: _builtins.str,
                 created_at: _builtins.str,
                 current_cu: _builtins.int,
                 description: _builtins.str,
                 enterprise_project_id: _builtins.str,
                 fail_reason: _builtins.str,
                 id: _builtins.int,
                 manager: _builtins.str,
                 max_cu: _builtins.int,
                 min_cu: _builtins.int,
                 name: _builtins.str,
                 owner: _builtins.str,
                 queues: Sequence[_builtins.str],
                 resource_id: _builtins.str,
                 status: _builtins.str):
        """
        :param _builtins.int actual_cu: The actual CUs number of the elastic resource pool.
        :param _builtins.str cidr: The CIDR block of network to associate with the elastic resource pool.
        :param _builtins.str created_at: The creation time of the elastic resource pool.
        :param _builtins.int current_cu: The current CUs number of the elastic resource pool.
        :param _builtins.str description: The description of the elastic resource pool.
        :param _builtins.str enterprise_project_id: The enterprise project ID corresponding to the elastic resource pool.
        :param _builtins.str fail_reason: The reason of elastic resource pool creation failed.
        :param _builtins.int id: The elastic resource pool ID.
        :param _builtins.str manager: The type of the elastic resource pool.
        :param _builtins.int max_cu: The maximum CUs number of the elastic resource pool.
        :param _builtins.int min_cu: The minimum CUs number of the elastic resource pool.
        :param _builtins.str name: Specifies the name of the elastic resource pool.
        :param _builtins.str owner: The account name for creating elastic resource pool.
        :param Sequence[_builtins.str] queues: The list of queues association with the elastic resource pool.
        :param _builtins.str resource_id: The resource ID of the elastic resource pool.
        :param _builtins.str status: Specifies the status of the elastic resource pool.
               The valid values are as follows:
               + **available**
               + **failed**
        """
        pulumi.set(__self__, "actual_cu", actual_cu)
        pulumi.set(__self__, "cidr", cidr)
        pulumi.set(__self__, "created_at", created_at)
        pulumi.set(__self__, "current_cu", current_cu)
        pulumi.set(__self__, "description", description)
        pulumi.set(__self__, "enterprise_project_id", enterprise_project_id)
        pulumi.set(__self__, "fail_reason", fail_reason)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "manager", manager)
        pulumi.set(__self__, "max_cu", max_cu)
        pulumi.set(__self__, "min_cu", min_cu)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "owner", owner)
        pulumi.set(__self__, "queues", queues)
        pulumi.set(__self__, "resource_id", resource_id)
        pulumi.set(__self__, "status", status)

    @_builtins.property
    @pulumi.getter(name="actualCu")
    def actual_cu(self) -> _builtins.int:
        """
        The actual CUs number of the elastic resource pool.
        """
        return pulumi.get(self, "actual_cu")

    @_builtins.property
    @pulumi.getter
    def cidr(self) -> _builtins.str:
        """
        The CIDR block of network to associate with the elastic resource pool.
        """
        return pulumi.get(self, "cidr")

    @_builtins.property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> _builtins.str:
        """
        The creation time of the elastic resource pool.
        """
        return pulumi.get(self, "created_at")

    @_builtins.property
    @pulumi.getter(name="currentCu")
    def current_cu(self) -> _builtins.int:
        """
        The current CUs number of the elastic resource pool.
        """
        return pulumi.get(self, "current_cu")

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        The description of the elastic resource pool.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter(name="enterpriseProjectId")
    def enterprise_project_id(self) -> _builtins.str:
        """
        The enterprise project ID corresponding to the elastic resource pool.
        """
        return pulumi.get(self, "enterprise_project_id")

    @_builtins.property
    @pulumi.getter(name="failReason")
    def fail_reason(self) -> _builtins.str:
        """
        The reason of elastic resource pool creation failed.
        """
        return pulumi.get(self, "fail_reason")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.int:
        """
        The elastic resource pool ID.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def manager(self) -> _builtins.str:
        """
        The type of the elastic resource pool.
        """
        return pulumi.get(self, "manager")

    @_builtins.property
    @pulumi.getter(name="maxCu")
    def max_cu(self) -> _builtins.int:
        """
        The maximum CUs number of the elastic resource pool.
        """
        return pulumi.get(self, "max_cu")

    @_builtins.property
    @pulumi.getter(name="minCu")
    def min_cu(self) -> _builtins.int:
        """
        The minimum CUs number of the elastic resource pool.
        """
        return pulumi.get(self, "min_cu")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the elastic resource pool.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def owner(self) -> _builtins.str:
        """
        The account name for creating elastic resource pool.
        """
        return pulumi.get(self, "owner")

    @_builtins.property
    @pulumi.getter
    def queues(self) -> Sequence[_builtins.str]:
        """
        The list of queues association with the elastic resource pool.
        """
        return pulumi.get(self, "queues")

    @_builtins.property
    @pulumi.getter(name="resourceId")
    def resource_id(self) -> _builtins.str:
        """
        The resource ID of the elastic resource pool.
        """
        return pulumi.get(self, "resource_id")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        Specifies the status of the elastic resource pool.
        The valid values are as follows:
        + **available**
        + **failed**
        """
        return pulumi.get(self, "status")


@pulumi.output_type
class GetFlinkTemplatesTemplateResult(dict):
    def __init__(__self__, *,
                 created_at: _builtins.str,
                 description: _builtins.str,
                 id: _builtins.str,
                 name: _builtins.str,
                 sql: _builtins.str,
                 type: _builtins.str,
                 updated_at: _builtins.str):
        """
        :param _builtins.str created_at: The creation time of the template.
        :param _builtins.str description: The description of template.
        :param _builtins.str id: The ID of template.
        :param _builtins.str name: Specifies the name of the flink template to be queried.
        :param _builtins.str sql: The stream SQL statement.
        :param _builtins.str type: Specifies the type of the flink template to be queried.
        :param _builtins.str updated_at: The latest update time of the template.
        """
        pulumi.set(__self__, "created_at", created_at)
        pulumi.set(__self__, "description", description)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "sql", sql)
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "updated_at", updated_at)

    @_builtins.property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> _builtins.str:
        """
        The creation time of the template.
        """
        return pulumi.get(self, "created_at")

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        The description of template.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The ID of template.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the flink template to be queried.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def sql(self) -> _builtins.str:
        """
        The stream SQL statement.
        """
        return pulumi.get(self, "sql")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Specifies the type of the flink template to be queried.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> _builtins.str:
        """
        The latest update time of the template.
        """
        return pulumi.get(self, "updated_at")


@pulumi.output_type
class GetFlinkjarJobsJobResult(dict):
    def __init__(__self__, *,
                 checkpoint_path: _builtins.str,
                 cu_num: _builtins.int,
                 dependency_files: Sequence[_builtins.str],
                 dependency_jars: Sequence[_builtins.str],
                 description: _builtins.str,
                 entrypoint: _builtins.str,
                 entrypoint_args: _builtins.str,
                 feature: _builtins.str,
                 flink_version: _builtins.str,
                 id: _builtins.str,
                 image: _builtins.str,
                 log_enabled: _builtins.bool,
                 main_class: _builtins.str,
                 manager_cu_num: _builtins.int,
                 name: _builtins.str,
                 obs_bucket: _builtins.str,
                 parallel_num: _builtins.int,
                 queue_name: _builtins.str,
                 restart_when_exception: _builtins.bool,
                 resume_checkpoint: _builtins.bool,
                 resume_max_num: _builtins.int,
                 runtime_config: _builtins.str,
                 smn_topic: _builtins.str,
                 status: _builtins.str,
                 tm_cu_num: _builtins.int,
                 tm_slot_num: _builtins.int):
        """
        :param _builtins.str checkpoint_path: The checkpoint save path.
        :param _builtins.int cu_num: Specifies number of CUs to be queried.
        :param Sequence[_builtins.str] dependency_files: The dependency files. It is the name of the package that has been uploaded to the DLI.
        :param Sequence[_builtins.str] dependency_jars: The other dependency jars. It is the name of the package that has been uploaded to the DLI.
        :param _builtins.str description: The description of the job.
        :param _builtins.str entrypoint: The JAR file where the job main class is located.
               It is the name of the package that has been uploaded to the DLI.
        :param _builtins.str entrypoint_args: The job entry arguments.
        :param _builtins.str feature: The custom job features. Type of the Flink image used by a job.
               + **basic**: indicates that the basic Flink image provided by DLI is used.
               + **custom**: indicates that the user-defined Flink image is used.
        :param _builtins.str flink_version: The flink version.
        :param _builtins.str id: The ID of the job.
        :param _builtins.str image: The custom image.
        :param _builtins.bool log_enabled: The whether to enable the function of uploading job logs to users' OBS buckets.
        :param _builtins.str main_class: The jar package main class.
        :param _builtins.int manager_cu_num: Specifies number of CUs in the job manager to be queried.
        :param _builtins.str name: The name of the job.
        :param _builtins.str obs_bucket: The name of OBS bucket.
        :param _builtins.int parallel_num: Specifies number of parallel to be queried.
        :param _builtins.str queue_name: Specifies the name of DLI queue which this job to be queried.
        :param _builtins.bool restart_when_exception: The whether to enable the function of restart upon exceptions.
        :param _builtins.bool resume_checkpoint: The whether the abnormal restart is recovered from the checkpoint.
        :param _builtins.int resume_max_num: The maximum number of retry times upon exceptions.
        :param _builtins.str runtime_config: The customize optimization parameters during flink job runtime.
        :param _builtins.str smn_topic: The SMN topic. If a job fails, the system will send a message to users subscribed to the SMN topic.
        :param _builtins.str status: The status of the job.
        :param _builtins.int tm_cu_num: Specifies number of CUs occupied by a single TM to be queried.
        :param _builtins.int tm_slot_num: Specifies number of single TM slots to be queried.
        """
        pulumi.set(__self__, "checkpoint_path", checkpoint_path)
        pulumi.set(__self__, "cu_num", cu_num)
        pulumi.set(__self__, "dependency_files", dependency_files)
        pulumi.set(__self__, "dependency_jars", dependency_jars)
        pulumi.set(__self__, "description", description)
        pulumi.set(__self__, "entrypoint", entrypoint)
        pulumi.set(__self__, "entrypoint_args", entrypoint_args)
        pulumi.set(__self__, "feature", feature)
        pulumi.set(__self__, "flink_version", flink_version)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "image", image)
        pulumi.set(__self__, "log_enabled", log_enabled)
        pulumi.set(__self__, "main_class", main_class)
        pulumi.set(__self__, "manager_cu_num", manager_cu_num)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "obs_bucket", obs_bucket)
        pulumi.set(__self__, "parallel_num", parallel_num)
        pulumi.set(__self__, "queue_name", queue_name)
        pulumi.set(__self__, "restart_when_exception", restart_when_exception)
        pulumi.set(__self__, "resume_checkpoint", resume_checkpoint)
        pulumi.set(__self__, "resume_max_num", resume_max_num)
        pulumi.set(__self__, "runtime_config", runtime_config)
        pulumi.set(__self__, "smn_topic", smn_topic)
        pulumi.set(__self__, "status", status)
        pulumi.set(__self__, "tm_cu_num", tm_cu_num)
        pulumi.set(__self__, "tm_slot_num", tm_slot_num)

    @_builtins.property
    @pulumi.getter(name="checkpointPath")
    def checkpoint_path(self) -> _builtins.str:
        """
        The checkpoint save path.
        """
        return pulumi.get(self, "checkpoint_path")

    @_builtins.property
    @pulumi.getter(name="cuNum")
    def cu_num(self) -> _builtins.int:
        """
        Specifies number of CUs to be queried.
        """
        return pulumi.get(self, "cu_num")

    @_builtins.property
    @pulumi.getter(name="dependencyFiles")
    def dependency_files(self) -> Sequence[_builtins.str]:
        """
        The dependency files. It is the name of the package that has been uploaded to the DLI.
        """
        return pulumi.get(self, "dependency_files")

    @_builtins.property
    @pulumi.getter(name="dependencyJars")
    def dependency_jars(self) -> Sequence[_builtins.str]:
        """
        The other dependency jars. It is the name of the package that has been uploaded to the DLI.
        """
        return pulumi.get(self, "dependency_jars")

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        The description of the job.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter
    def entrypoint(self) -> _builtins.str:
        """
        The JAR file where the job main class is located.
        It is the name of the package that has been uploaded to the DLI.
        """
        return pulumi.get(self, "entrypoint")

    @_builtins.property
    @pulumi.getter(name="entrypointArgs")
    def entrypoint_args(self) -> _builtins.str:
        """
        The job entry arguments.
        """
        return pulumi.get(self, "entrypoint_args")

    @_builtins.property
    @pulumi.getter
    def feature(self) -> _builtins.str:
        """
        The custom job features. Type of the Flink image used by a job.
        + **basic**: indicates that the basic Flink image provided by DLI is used.
        + **custom**: indicates that the user-defined Flink image is used.
        """
        return pulumi.get(self, "feature")

    @_builtins.property
    @pulumi.getter(name="flinkVersion")
    def flink_version(self) -> _builtins.str:
        """
        The flink version.
        """
        return pulumi.get(self, "flink_version")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The ID of the job.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def image(self) -> _builtins.str:
        """
        The custom image.
        """
        return pulumi.get(self, "image")

    @_builtins.property
    @pulumi.getter(name="logEnabled")
    def log_enabled(self) -> _builtins.bool:
        """
        The whether to enable the function of uploading job logs to users' OBS buckets.
        """
        return pulumi.get(self, "log_enabled")

    @_builtins.property
    @pulumi.getter(name="mainClass")
    def main_class(self) -> _builtins.str:
        """
        The jar package main class.
        """
        return pulumi.get(self, "main_class")

    @_builtins.property
    @pulumi.getter(name="managerCuNum")
    def manager_cu_num(self) -> _builtins.int:
        """
        Specifies number of CUs in the job manager to be queried.
        """
        return pulumi.get(self, "manager_cu_num")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        The name of the job.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="obsBucket")
    def obs_bucket(self) -> _builtins.str:
        """
        The name of OBS bucket.
        """
        return pulumi.get(self, "obs_bucket")

    @_builtins.property
    @pulumi.getter(name="parallelNum")
    def parallel_num(self) -> _builtins.int:
        """
        Specifies number of parallel to be queried.
        """
        return pulumi.get(self, "parallel_num")

    @_builtins.property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> _builtins.str:
        """
        Specifies the name of DLI queue which this job to be queried.
        """
        return pulumi.get(self, "queue_name")

    @_builtins.property
    @pulumi.getter(name="restartWhenException")
    def restart_when_exception(self) -> _builtins.bool:
        """
        The whether to enable the function of restart upon exceptions.
        """
        return pulumi.get(self, "restart_when_exception")

    @_builtins.property
    @pulumi.getter(name="resumeCheckpoint")
    def resume_checkpoint(self) -> _builtins.bool:
        """
        The whether the abnormal restart is recovered from the checkpoint.
        """
        return pulumi.get(self, "resume_checkpoint")

    @_builtins.property
    @pulumi.getter(name="resumeMaxNum")
    def resume_max_num(self) -> _builtins.int:
        """
        The maximum number of retry times upon exceptions.
        """
        return pulumi.get(self, "resume_max_num")

    @_builtins.property
    @pulumi.getter(name="runtimeConfig")
    def runtime_config(self) -> _builtins.str:
        """
        The customize optimization parameters during flink job runtime.
        """
        return pulumi.get(self, "runtime_config")

    @_builtins.property
    @pulumi.getter(name="smnTopic")
    def smn_topic(self) -> _builtins.str:
        """
        The SMN topic. If a job fails, the system will send a message to users subscribed to the SMN topic.
        """
        return pulumi.get(self, "smn_topic")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        The status of the job.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter(name="tmCuNum")
    def tm_cu_num(self) -> _builtins.int:
        """
        Specifies number of CUs occupied by a single TM to be queried.
        """
        return pulumi.get(self, "tm_cu_num")

    @_builtins.property
    @pulumi.getter(name="tmSlotNum")
    def tm_slot_num(self) -> _builtins.int:
        """
        Specifies number of single TM slots to be queried.
        """
        return pulumi.get(self, "tm_slot_num")


@pulumi.output_type
class GetFlinksqlJobsJobResult(dict):
    def __init__(__self__, *,
                 checkpoint_enabled: _builtins.bool,
                 checkpoint_interval: _builtins.int,
                 checkpoint_mode: _builtins.str,
                 cu_num: _builtins.int,
                 description: _builtins.str,
                 dirty_data_strategy: _builtins.str,
                 edge_group_ids: Sequence[_builtins.str],
                 flink_version: _builtins.str,
                 id: _builtins.str,
                 idle_state_retention: _builtins.int,
                 log_enabled: _builtins.bool,
                 manager_cu_num: _builtins.int,
                 name: _builtins.str,
                 obs_bucket: _builtins.str,
                 operator_config: _builtins.str,
                 parallel_num: _builtins.int,
                 queue_name: _builtins.str,
                 restart_when_exception: _builtins.bool,
                 resume_checkpoint: _builtins.bool,
                 resume_max_num: _builtins.int,
                 run_mode: _builtins.str,
                 runtime_config: _builtins.str,
                 smn_topic: _builtins.str,
                 sql: _builtins.str,
                 static_estimator_config: _builtins.str,
                 status: _builtins.str,
                 tm_cu_num: _builtins.int,
                 tm_slot_num: _builtins.int,
                 type: _builtins.str,
                 udf_jar_url: _builtins.str):
        """
        :param _builtins.bool checkpoint_enabled: The whether to enable the automatic job snapshot function.
        :param _builtins.int checkpoint_interval: The snapshot interval. The unit is second.
        :param _builtins.str checkpoint_mode: The snapshot mode.
        :param _builtins.int cu_num: Specifies number of CUs to be queried.
        :param _builtins.str description: The description of the job.
        :param _builtins.str dirty_data_strategy: The dirty data policy of a job.
        :param Sequence[_builtins.str] edge_group_ids: The edge computing group IDs.
        :param _builtins.str flink_version: The version of the flink.
        :param _builtins.str id: The ID of the job.
        :param _builtins.int idle_state_retention: The retention time of the idle state. The unit is hour.
        :param _builtins.bool log_enabled: The whether to enable the function of uploading job logs to users' OBS buckets.
        :param _builtins.int manager_cu_num: Specifies number of CUs in the job manager to be queried.
        :param _builtins.str name: The name of the job.
        :param _builtins.str obs_bucket: The name of OBS bucket.
        :param _builtins.str operator_config: The degree of parallelism configuration of an operator, in JSON format.
        :param _builtins.int parallel_num: Specifies number of parallel to be queried.
        :param _builtins.str queue_name: Specifies the name of DLI queue which this job to be queried.
        :param _builtins.bool restart_when_exception: The whether to enable the function of restart upon exceptions.
        :param _builtins.bool resume_checkpoint: The whether the abnormal restart is recovered from the checkpoint.
        :param _builtins.int resume_max_num: The maximum number of retry times upon exceptions.
        :param _builtins.str run_mode: The job running mode.
        :param _builtins.str runtime_config: The customize optimization parameters during flink job runtime.
        :param _builtins.str smn_topic: The SMN topic. If a job fails, the system will send a message to users subscribed to the SMN topic.
        :param _builtins.str sql: The stream SQL statement.
        :param _builtins.str static_estimator_config: The static flow chart resource estimation parameters, in JSON format.
        :param _builtins.str status: The status of the job.
        :param _builtins.int tm_cu_num: Specifies number of CUs occupied by a single TM to be queried.
        :param _builtins.int tm_slot_num: Specifies number of single TM slots to be queried.
        :param _builtins.str type: The type of the job.
        :param _builtins.str udf_jar_url: The name of the resource package that has been uploaded to the
               DLI resource management system. The UDF Jar file of the SQL job is specified by this parameter.
        """
        pulumi.set(__self__, "checkpoint_enabled", checkpoint_enabled)
        pulumi.set(__self__, "checkpoint_interval", checkpoint_interval)
        pulumi.set(__self__, "checkpoint_mode", checkpoint_mode)
        pulumi.set(__self__, "cu_num", cu_num)
        pulumi.set(__self__, "description", description)
        pulumi.set(__self__, "dirty_data_strategy", dirty_data_strategy)
        pulumi.set(__self__, "edge_group_ids", edge_group_ids)
        pulumi.set(__self__, "flink_version", flink_version)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "idle_state_retention", idle_state_retention)
        pulumi.set(__self__, "log_enabled", log_enabled)
        pulumi.set(__self__, "manager_cu_num", manager_cu_num)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "obs_bucket", obs_bucket)
        pulumi.set(__self__, "operator_config", operator_config)
        pulumi.set(__self__, "parallel_num", parallel_num)
        pulumi.set(__self__, "queue_name", queue_name)
        pulumi.set(__self__, "restart_when_exception", restart_when_exception)
        pulumi.set(__self__, "resume_checkpoint", resume_checkpoint)
        pulumi.set(__self__, "resume_max_num", resume_max_num)
        pulumi.set(__self__, "run_mode", run_mode)
        pulumi.set(__self__, "runtime_config", runtime_config)
        pulumi.set(__self__, "smn_topic", smn_topic)
        pulumi.set(__self__, "sql", sql)
        pulumi.set(__self__, "static_estimator_config", static_estimator_config)
        pulumi.set(__self__, "status", status)
        pulumi.set(__self__, "tm_cu_num", tm_cu_num)
        pulumi.set(__self__, "tm_slot_num", tm_slot_num)
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "udf_jar_url", udf_jar_url)

    @_builtins.property
    @pulumi.getter(name="checkpointEnabled")
    def checkpoint_enabled(self) -> _builtins.bool:
        """
        The whether to enable the automatic job snapshot function.
        """
        return pulumi.get(self, "checkpoint_enabled")

    @_builtins.property
    @pulumi.getter(name="checkpointInterval")
    def checkpoint_interval(self) -> _builtins.int:
        """
        The snapshot interval. The unit is second.
        """
        return pulumi.get(self, "checkpoint_interval")

    @_builtins.property
    @pulumi.getter(name="checkpointMode")
    def checkpoint_mode(self) -> _builtins.str:
        """
        The snapshot mode.
        """
        return pulumi.get(self, "checkpoint_mode")

    @_builtins.property
    @pulumi.getter(name="cuNum")
    def cu_num(self) -> _builtins.int:
        """
        Specifies number of CUs to be queried.
        """
        return pulumi.get(self, "cu_num")

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        The description of the job.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter(name="dirtyDataStrategy")
    def dirty_data_strategy(self) -> _builtins.str:
        """
        The dirty data policy of a job.
        """
        return pulumi.get(self, "dirty_data_strategy")

    @_builtins.property
    @pulumi.getter(name="edgeGroupIds")
    def edge_group_ids(self) -> Sequence[_builtins.str]:
        """
        The edge computing group IDs.
        """
        return pulumi.get(self, "edge_group_ids")

    @_builtins.property
    @pulumi.getter(name="flinkVersion")
    def flink_version(self) -> _builtins.str:
        """
        The version of the flink.
        """
        return pulumi.get(self, "flink_version")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The ID of the job.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter(name="idleStateRetention")
    def idle_state_retention(self) -> _builtins.int:
        """
        The retention time of the idle state. The unit is hour.
        """
        return pulumi.get(self, "idle_state_retention")

    @_builtins.property
    @pulumi.getter(name="logEnabled")
    def log_enabled(self) -> _builtins.bool:
        """
        The whether to enable the function of uploading job logs to users' OBS buckets.
        """
        return pulumi.get(self, "log_enabled")

    @_builtins.property
    @pulumi.getter(name="managerCuNum")
    def manager_cu_num(self) -> _builtins.int:
        """
        Specifies number of CUs in the job manager to be queried.
        """
        return pulumi.get(self, "manager_cu_num")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        The name of the job.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="obsBucket")
    def obs_bucket(self) -> _builtins.str:
        """
        The name of OBS bucket.
        """
        return pulumi.get(self, "obs_bucket")

    @_builtins.property
    @pulumi.getter(name="operatorConfig")
    def operator_config(self) -> _builtins.str:
        """
        The degree of parallelism configuration of an operator, in JSON format.
        """
        return pulumi.get(self, "operator_config")

    @_builtins.property
    @pulumi.getter(name="parallelNum")
    def parallel_num(self) -> _builtins.int:
        """
        Specifies number of parallel to be queried.
        """
        return pulumi.get(self, "parallel_num")

    @_builtins.property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> _builtins.str:
        """
        Specifies the name of DLI queue which this job to be queried.
        """
        return pulumi.get(self, "queue_name")

    @_builtins.property
    @pulumi.getter(name="restartWhenException")
    def restart_when_exception(self) -> _builtins.bool:
        """
        The whether to enable the function of restart upon exceptions.
        """
        return pulumi.get(self, "restart_when_exception")

    @_builtins.property
    @pulumi.getter(name="resumeCheckpoint")
    def resume_checkpoint(self) -> _builtins.bool:
        """
        The whether the abnormal restart is recovered from the checkpoint.
        """
        return pulumi.get(self, "resume_checkpoint")

    @_builtins.property
    @pulumi.getter(name="resumeMaxNum")
    def resume_max_num(self) -> _builtins.int:
        """
        The maximum number of retry times upon exceptions.
        """
        return pulumi.get(self, "resume_max_num")

    @_builtins.property
    @pulumi.getter(name="runMode")
    def run_mode(self) -> _builtins.str:
        """
        The job running mode.
        """
        return pulumi.get(self, "run_mode")

    @_builtins.property
    @pulumi.getter(name="runtimeConfig")
    def runtime_config(self) -> _builtins.str:
        """
        The customize optimization parameters during flink job runtime.
        """
        return pulumi.get(self, "runtime_config")

    @_builtins.property
    @pulumi.getter(name="smnTopic")
    def smn_topic(self) -> _builtins.str:
        """
        The SMN topic. If a job fails, the system will send a message to users subscribed to the SMN topic.
        """
        return pulumi.get(self, "smn_topic")

    @_builtins.property
    @pulumi.getter
    def sql(self) -> _builtins.str:
        """
        The stream SQL statement.
        """
        return pulumi.get(self, "sql")

    @_builtins.property
    @pulumi.getter(name="staticEstimatorConfig")
    def static_estimator_config(self) -> _builtins.str:
        """
        The static flow chart resource estimation parameters, in JSON format.
        """
        return pulumi.get(self, "static_estimator_config")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        The status of the job.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter(name="tmCuNum")
    def tm_cu_num(self) -> _builtins.int:
        """
        Specifies number of CUs occupied by a single TM to be queried.
        """
        return pulumi.get(self, "tm_cu_num")

    @_builtins.property
    @pulumi.getter(name="tmSlotNum")
    def tm_slot_num(self) -> _builtins.int:
        """
        Specifies number of single TM slots to be queried.
        """
        return pulumi.get(self, "tm_slot_num")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The type of the job.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="udfJarUrl")
    def udf_jar_url(self) -> _builtins.str:
        """
        The name of the resource package that has been uploaded to the
        DLI resource management system. The UDF Jar file of the SQL job is specified by this parameter.
        """
        return pulumi.get(self, "udf_jar_url")


@pulumi.output_type
class GetQuotasQuotaResult(dict):
    def __init__(__self__, *,
                 max: _builtins.int,
                 min: _builtins.int,
                 quota: _builtins.int,
                 type: _builtins.str,
                 used: _builtins.int):
        """
        :param _builtins.int max: The maximum quota of resource.
        :param _builtins.int min: The minimum quota of resource.
        :param _builtins.int quota: The current quota of resource.
        :param _builtins.str type: Specifies the resource type that used to query corresponding quota.
               Value options:
               + **CU**: Computing unit.
               + **QUEUE**: Resource queue.
               + **DATABASE**: Database.
               + **TABLE**: Table.
               + **TEMPLATE**: Template.
               + **SL_PKG_RESOURCE**: Spark job resource package.
               + **SL_SESSION**: Spark job table.
               + **JOB_CU**: Job computing unit.
               + **ELASTIC_RESOURCE_POOL**: Elastic resource pool.
        :param _builtins.int used: The used quota of resource.
        """
        pulumi.set(__self__, "max", max)
        pulumi.set(__self__, "min", min)
        pulumi.set(__self__, "quota", quota)
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "used", used)

    @_builtins.property
    @pulumi.getter
    def max(self) -> _builtins.int:
        """
        The maximum quota of resource.
        """
        return pulumi.get(self, "max")

    @_builtins.property
    @pulumi.getter
    def min(self) -> _builtins.int:
        """
        The minimum quota of resource.
        """
        return pulumi.get(self, "min")

    @_builtins.property
    @pulumi.getter
    def quota(self) -> _builtins.int:
        """
        The current quota of resource.
        """
        return pulumi.get(self, "quota")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Specifies the resource type that used to query corresponding quota.
        Value options:
        + **CU**: Computing unit.
        + **QUEUE**: Resource queue.
        + **DATABASE**: Database.
        + **TABLE**: Table.
        + **TEMPLATE**: Template.
        + **SL_PKG_RESOURCE**: Spark job resource package.
        + **SL_SESSION**: Spark job table.
        + **JOB_CU**: Job computing unit.
        + **ELASTIC_RESOURCE_POOL**: Elastic resource pool.
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter
    def used(self) -> _builtins.int:
        """
        The used quota of resource.
        """
        return pulumi.get(self, "used")


@pulumi.output_type
class GetSparkTemplatesTemplateResult(dict):
    def __init__(__self__, *,
                 bodies: Sequence['outputs.GetSparkTemplatesTemplateBodyResult'],
                 description: _builtins.str,
                 group: _builtins.str,
                 id: _builtins.str,
                 name: _builtins.str):
        """
        :param Sequence['GetSparkTemplatesTemplateBodyArgs'] bodies: The body of template.
        :param _builtins.str description: The description of template.
        :param _builtins.str group: Specifies the group name to which the spark templates belong.
        :param _builtins.str id: The ID of template.
        :param _builtins.str name: Specifies the name of the spark template to be queried.
        """
        pulumi.set(__self__, "bodies", bodies)
        pulumi.set(__self__, "description", description)
        pulumi.set(__self__, "group", group)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter
    def bodies(self) -> Sequence['outputs.GetSparkTemplatesTemplateBodyResult']:
        """
        The body of template.
        """
        return pulumi.get(self, "bodies")

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        The description of template.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter
    def group(self) -> _builtins.str:
        """
        Specifies the group name to which the spark templates belong.
        """
        return pulumi.get(self, "group")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The ID of template.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the spark template to be queried.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetSparkTemplatesTemplateBodyResult(dict):
    def __init__(__self__, *,
                 app_name: _builtins.str,
                 app_parameters: Sequence[_builtins.str],
                 auto_recovery: _builtins.bool,
                 configurations: Mapping[str, _builtins.str],
                 dependent_packages: Sequence['outputs.GetSparkTemplatesTemplateBodyDependentPackageResult'],
                 driver_cores: _builtins.int,
                 driver_memory: _builtins.str,
                 executor_cores: _builtins.int,
                 executor_memory: _builtins.str,
                 files: Sequence[_builtins.str],
                 jars: Sequence[_builtins.str],
                 main_class: _builtins.str,
                 max_retry_times: _builtins.int,
                 modules: Sequence[_builtins.str],
                 name: _builtins.str,
                 num_executors: _builtins.int,
                 obs_bucket: _builtins.str,
                 python_files: Sequence[_builtins.str],
                 queue_name: _builtins.str,
                 resources: Sequence['outputs.GetSparkTemplatesTemplateBodyResourceResult'],
                 specification: _builtins.str):
        """
        :param _builtins.str app_name: The name of the uploaded JAR or pyFile type package.
        :param Sequence[_builtins.str] app_parameters: The input parameters of the main class, that is application parameters.
        :param _builtins.bool auto_recovery: Indicates whether to enable the retry function.
        :param Mapping[str, _builtins.str] configurations: The configuration items of the DLI spark.
        :param Sequence['GetSparkTemplatesTemplateBodyDependentPackageArgs'] dependent_packages: The list of package resource objects.
        :param _builtins.int driver_cores: The number of CPU cores of the spark application driver.
        :param _builtins.str driver_memory: The driver memory of the spark application.
        :param _builtins.int executor_cores: The number of CPU cores of each executor in the spark application.
        :param _builtins.str executor_memory: The executor memory of the spark application.
        :param Sequence[_builtins.str] files: The name of the resource package of type file upload to the DLI resource management system.
        :param Sequence[_builtins.str] jars: The name of the resource package of type jar upload to the DLI resource management system.
        :param _builtins.str main_class: The spark main class of the template.
        :param _builtins.int max_retry_times: The maximum number of retries.
        :param Sequence[_builtins.str] modules: The name of the dependent system resource module.
               DLI provides dependencies for executing datasource jobs.
               The dependent modules and corresponding services are as follows.
               + **sys.datasource.hbase**: CloudTable/MRS HBase
               + **sys.datasource.opentsdb**: CloudTable/MRS OpenTSDB
               + **sys.datasource.rds**: RDS MySQL
               + **sys.datasource.css**: CSS
        :param _builtins.str name: Specifies the name of the spark template to be queried.
        :param _builtins.int num_executors: The number of executors in a spark application.
        :param _builtins.str obs_bucket: The OBS bucket for storing the spark jobs.
        :param Sequence[_builtins.str] python_files: Name of the package that is of the PyFile type.
               And has been uploaded to the DLI resource management system.
        :param _builtins.str queue_name: The DLI queue name.
        :param Sequence['GetSparkTemplatesTemplateBodyResourceArgs'] resources: The resources of a user group.
        :param _builtins.str specification: The compute resource type. Currently, resource types A, B, and C are available.  
               The available types and related specifications are as follows, default to minimum configuration (type **A**).
        """
        pulumi.set(__self__, "app_name", app_name)
        pulumi.set(__self__, "app_parameters", app_parameters)
        pulumi.set(__self__, "auto_recovery", auto_recovery)
        pulumi.set(__self__, "configurations", configurations)
        pulumi.set(__self__, "dependent_packages", dependent_packages)
        pulumi.set(__self__, "driver_cores", driver_cores)
        pulumi.set(__self__, "driver_memory", driver_memory)
        pulumi.set(__self__, "executor_cores", executor_cores)
        pulumi.set(__self__, "executor_memory", executor_memory)
        pulumi.set(__self__, "files", files)
        pulumi.set(__self__, "jars", jars)
        pulumi.set(__self__, "main_class", main_class)
        pulumi.set(__self__, "max_retry_times", max_retry_times)
        pulumi.set(__self__, "modules", modules)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "num_executors", num_executors)
        pulumi.set(__self__, "obs_bucket", obs_bucket)
        pulumi.set(__self__, "python_files", python_files)
        pulumi.set(__self__, "queue_name", queue_name)
        pulumi.set(__self__, "resources", resources)
        pulumi.set(__self__, "specification", specification)

    @_builtins.property
    @pulumi.getter(name="appName")
    def app_name(self) -> _builtins.str:
        """
        The name of the uploaded JAR or pyFile type package.
        """
        return pulumi.get(self, "app_name")

    @_builtins.property
    @pulumi.getter(name="appParameters")
    def app_parameters(self) -> Sequence[_builtins.str]:
        """
        The input parameters of the main class, that is application parameters.
        """
        return pulumi.get(self, "app_parameters")

    @_builtins.property
    @pulumi.getter(name="autoRecovery")
    def auto_recovery(self) -> _builtins.bool:
        """
        Indicates whether to enable the retry function.
        """
        return pulumi.get(self, "auto_recovery")

    @_builtins.property
    @pulumi.getter
    def configurations(self) -> Mapping[str, _builtins.str]:
        """
        The configuration items of the DLI spark.
        """
        return pulumi.get(self, "configurations")

    @_builtins.property
    @pulumi.getter(name="dependentPackages")
    def dependent_packages(self) -> Sequence['outputs.GetSparkTemplatesTemplateBodyDependentPackageResult']:
        """
        The list of package resource objects.
        """
        return pulumi.get(self, "dependent_packages")

    @_builtins.property
    @pulumi.getter(name="driverCores")
    def driver_cores(self) -> _builtins.int:
        """
        The number of CPU cores of the spark application driver.
        """
        return pulumi.get(self, "driver_cores")

    @_builtins.property
    @pulumi.getter(name="driverMemory")
    def driver_memory(self) -> _builtins.str:
        """
        The driver memory of the spark application.
        """
        return pulumi.get(self, "driver_memory")

    @_builtins.property
    @pulumi.getter(name="executorCores")
    def executor_cores(self) -> _builtins.int:
        """
        The number of CPU cores of each executor in the spark application.
        """
        return pulumi.get(self, "executor_cores")

    @_builtins.property
    @pulumi.getter(name="executorMemory")
    def executor_memory(self) -> _builtins.str:
        """
        The executor memory of the spark application.
        """
        return pulumi.get(self, "executor_memory")

    @_builtins.property
    @pulumi.getter
    def files(self) -> Sequence[_builtins.str]:
        """
        The name of the resource package of type file upload to the DLI resource management system.
        """
        return pulumi.get(self, "files")

    @_builtins.property
    @pulumi.getter
    def jars(self) -> Sequence[_builtins.str]:
        """
        The name of the resource package of type jar upload to the DLI resource management system.
        """
        return pulumi.get(self, "jars")

    @_builtins.property
    @pulumi.getter(name="mainClass")
    def main_class(self) -> _builtins.str:
        """
        The spark main class of the template.
        """
        return pulumi.get(self, "main_class")

    @_builtins.property
    @pulumi.getter(name="maxRetryTimes")
    def max_retry_times(self) -> _builtins.int:
        """
        The maximum number of retries.
        """
        return pulumi.get(self, "max_retry_times")

    @_builtins.property
    @pulumi.getter
    def modules(self) -> Sequence[_builtins.str]:
        """
        The name of the dependent system resource module.
        DLI provides dependencies for executing datasource jobs.
        The dependent modules and corresponding services are as follows.
        + **sys.datasource.hbase**: CloudTable/MRS HBase
        + **sys.datasource.opentsdb**: CloudTable/MRS OpenTSDB
        + **sys.datasource.rds**: RDS MySQL
        + **sys.datasource.css**: CSS
        """
        return pulumi.get(self, "modules")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the spark template to be queried.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="numExecutors")
    def num_executors(self) -> _builtins.int:
        """
        The number of executors in a spark application.
        """
        return pulumi.get(self, "num_executors")

    @_builtins.property
    @pulumi.getter(name="obsBucket")
    def obs_bucket(self) -> _builtins.str:
        """
        The OBS bucket for storing the spark jobs.
        """
        return pulumi.get(self, "obs_bucket")

    @_builtins.property
    @pulumi.getter(name="pythonFiles")
    def python_files(self) -> Sequence[_builtins.str]:
        """
        Name of the package that is of the PyFile type.
        And has been uploaded to the DLI resource management system.
        """
        return pulumi.get(self, "python_files")

    @_builtins.property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> _builtins.str:
        """
        The DLI queue name.
        """
        return pulumi.get(self, "queue_name")

    @_builtins.property
    @pulumi.getter
    def resources(self) -> Sequence['outputs.GetSparkTemplatesTemplateBodyResourceResult']:
        """
        The resources of a user group.
        """
        return pulumi.get(self, "resources")

    @_builtins.property
    @pulumi.getter
    def specification(self) -> _builtins.str:
        """
        The compute resource type. Currently, resource types A, B, and C are available.  
        The available types and related specifications are as follows, default to minimum configuration (type **A**).
        """
        return pulumi.get(self, "specification")


@pulumi.output_type
class GetSparkTemplatesTemplateBodyDependentPackageResult(dict):
    def __init__(__self__, *,
                 name: _builtins.str,
                 resources: Sequence['outputs.GetSparkTemplatesTemplateBodyDependentPackageResourceResult']):
        """
        :param _builtins.str name: Specifies the name of the spark template to be queried.
        :param Sequence['GetSparkTemplatesTemplateBodyDependentPackageResourceArgs'] resources: The resources of a user group.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "resources", resources)

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the spark template to be queried.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def resources(self) -> Sequence['outputs.GetSparkTemplatesTemplateBodyDependentPackageResourceResult']:
        """
        The resources of a user group.
        """
        return pulumi.get(self, "resources")


@pulumi.output_type
class GetSparkTemplatesTemplateBodyDependentPackageResourceResult(dict):
    def __init__(__self__, *,
                 name: _builtins.str,
                 type: _builtins.str):
        """
        :param _builtins.str name: Specifies the name of the spark template to be queried.
        :param _builtins.str type: The type of resource.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the spark template to be queried.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The type of resource.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetSparkTemplatesTemplateBodyResourceResult(dict):
    def __init__(__self__, *,
                 name: _builtins.str,
                 type: _builtins.str):
        """
        :param _builtins.str name: Specifies the name of the spark template to be queried.
        :param _builtins.str type: The type of resource.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the spark template to be queried.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        The type of resource.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetSqlJobsJobResult(dict):
    def __init__(__self__, *,
                 database_name: _builtins.str,
                 duration: _builtins.int,
                 end_time: _builtins.str,
                 id: _builtins.str,
                 owner: _builtins.str,
                 queue_name: _builtins.str,
                 sql: _builtins.str,
                 start_time: _builtins.str,
                 status: _builtins.str,
                 tags: Mapping[str, _builtins.str],
                 type: _builtins.str):
        """
        :param _builtins.str database_name: The database name where the table that records its operations is located.
        :param _builtins.int duration: The job running duration (unit: millisecond).
        :param _builtins.str end_time: Specifies the time when a job is end to be queried.
               The format is `YYYY-MM-DDThh:mm:ss{timezone}`, e.g. `2024-01-01T08:00:00+08:00`.
        :param _builtins.str id: The ID of job.
        :param _builtins.str owner: The user who submits the job.
        :param _builtins.str queue_name: Specifies the queue name which the jobs to be submitted belong.
        :param _builtins.str sql: The SQL statement is executed by the job.
        :param _builtins.str start_time: Specifies the time when a job is start to be queried.
               The format is `YYYY-MM-DDThh:mm:ss{timezone}`, e.g. `2024-01-01T08:00:00+08:00`.
        :param _builtins.str status: Specifies the status of the job to be queried.
               The valid values are **FINISHED**, **FAILED** and **CANCELED**.
        :param Mapping[str, _builtins.str] tags: The key/value pairs to associate with the job.
        :param _builtins.str type: Specifies the type of the jobs to be queried.
        """
        pulumi.set(__self__, "database_name", database_name)
        pulumi.set(__self__, "duration", duration)
        pulumi.set(__self__, "end_time", end_time)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "owner", owner)
        pulumi.set(__self__, "queue_name", queue_name)
        pulumi.set(__self__, "sql", sql)
        pulumi.set(__self__, "start_time", start_time)
        pulumi.set(__self__, "status", status)
        pulumi.set(__self__, "tags", tags)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> _builtins.str:
        """
        The database name where the table that records its operations is located.
        """
        return pulumi.get(self, "database_name")

    @_builtins.property
    @pulumi.getter
    def duration(self) -> _builtins.int:
        """
        The job running duration (unit: millisecond).
        """
        return pulumi.get(self, "duration")

    @_builtins.property
    @pulumi.getter(name="endTime")
    def end_time(self) -> _builtins.str:
        """
        Specifies the time when a job is end to be queried.
        The format is `YYYY-MM-DDThh:mm:ss{timezone}`, e.g. `2024-01-01T08:00:00+08:00`.
        """
        return pulumi.get(self, "end_time")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The ID of job.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def owner(self) -> _builtins.str:
        """
        The user who submits the job.
        """
        return pulumi.get(self, "owner")

    @_builtins.property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> _builtins.str:
        """
        Specifies the queue name which the jobs to be submitted belong.
        """
        return pulumi.get(self, "queue_name")

    @_builtins.property
    @pulumi.getter
    def sql(self) -> _builtins.str:
        """
        The SQL statement is executed by the job.
        """
        return pulumi.get(self, "sql")

    @_builtins.property
    @pulumi.getter(name="startTime")
    def start_time(self) -> _builtins.str:
        """
        Specifies the time when a job is start to be queried.
        The format is `YYYY-MM-DDThh:mm:ss{timezone}`, e.g. `2024-01-01T08:00:00+08:00`.
        """
        return pulumi.get(self, "start_time")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        """
        Specifies the status of the job to be queried.
        The valid values are **FINISHED**, **FAILED** and **CANCELED**.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Mapping[str, _builtins.str]:
        """
        The key/value pairs to associate with the job.
        """
        return pulumi.get(self, "tags")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Specifies the type of the jobs to be queried.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetSqlTemplatesTemplateResult(dict):
    def __init__(__self__, *,
                 description: _builtins.str,
                 group: _builtins.str,
                 id: _builtins.str,
                 name: _builtins.str,
                 owner: _builtins.str,
                 sql: _builtins.str):
        """
        :param _builtins.str description: The description of the SQL template.
        :param _builtins.str group: Specifies the group name to which the SQL templates belong.
        :param _builtins.str id: The ID of SQL template.
        :param _builtins.str name: Specifies the name of the SQL template to be queried.
        :param _builtins.str owner: Specifies user ID of owner to be queried.
        :param _builtins.str sql: The SQL statement of SQL template.
        """
        pulumi.set(__self__, "description", description)
        pulumi.set(__self__, "group", group)
        pulumi.set(__self__, "id", id)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "owner", owner)
        pulumi.set(__self__, "sql", sql)

    @_builtins.property
    @pulumi.getter
    def description(self) -> _builtins.str:
        """
        The description of the SQL template.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter
    def group(self) -> _builtins.str:
        """
        Specifies the group name to which the SQL templates belong.
        """
        return pulumi.get(self, "group")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The ID of SQL template.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def name(self) -> _builtins.str:
        """
        Specifies the name of the SQL template to be queried.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def owner(self) -> _builtins.str:
        """
        Specifies user ID of owner to be queried.
        """
        return pulumi.get(self, "owner")

    @_builtins.property
    @pulumi.getter
    def sql(self) -> _builtins.str:
        """
        The SQL statement of SQL template.
        """
        return pulumi.get(self, "sql")


