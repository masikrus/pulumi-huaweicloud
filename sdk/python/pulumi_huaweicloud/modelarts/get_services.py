# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs

__all__ = [
    'GetServicesResult',
    'AwaitableGetServicesResult',
    'get_services',
    'get_services_output',
]

@pulumi.output_type
class GetServicesResult:
    """
    A collection of values returned by getServices.
    """
    def __init__(__self__, id=None, infer_type=None, model_id=None, name=None, region=None, service_id=None, services=None, status=None, workspace_id=None):
        if id and not isinstance(id, str):
            raise TypeError("Expected argument 'id' to be a str")
        pulumi.set(__self__, "id", id)
        if infer_type and not isinstance(infer_type, str):
            raise TypeError("Expected argument 'infer_type' to be a str")
        pulumi.set(__self__, "infer_type", infer_type)
        if model_id and not isinstance(model_id, str):
            raise TypeError("Expected argument 'model_id' to be a str")
        pulumi.set(__self__, "model_id", model_id)
        if name and not isinstance(name, str):
            raise TypeError("Expected argument 'name' to be a str")
        pulumi.set(__self__, "name", name)
        if region and not isinstance(region, str):
            raise TypeError("Expected argument 'region' to be a str")
        pulumi.set(__self__, "region", region)
        if service_id and not isinstance(service_id, str):
            raise TypeError("Expected argument 'service_id' to be a str")
        pulumi.set(__self__, "service_id", service_id)
        if services and not isinstance(services, list):
            raise TypeError("Expected argument 'services' to be a list")
        pulumi.set(__self__, "services", services)
        if status and not isinstance(status, str):
            raise TypeError("Expected argument 'status' to be a str")
        pulumi.set(__self__, "status", status)
        if workspace_id and not isinstance(workspace_id, str):
            raise TypeError("Expected argument 'workspace_id' to be a str")
        pulumi.set(__self__, "workspace_id", workspace_id)

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The provider-assigned unique ID for this managed resource.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter(name="inferType")
    def infer_type(self) -> Optional[_builtins.str]:
        """
        Inference mode of the service.  
        Value options are as follows:
        + **real-time**: A real-time service. A model is deployed as a web service and provides real-time test UI and monitoring.
        + **batch**: A batch service, which can perform inference on batch data and automatically stops after data is processed.
        + **edge**: An edge service, which uses Intelligent EdgeFabric (IEF) to deploy a model as a web service on an edge
        node created on IEF.
        """
        return pulumi.get(self, "infer_type")

    @_builtins.property
    @pulumi.getter(name="modelId")
    def model_id(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "model_id")

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[_builtins.str]:
        """
        Services name.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter
    def region(self) -> _builtins.str:
        return pulumi.get(self, "region")

    @_builtins.property
    @pulumi.getter(name="serviceId")
    def service_id(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "service_id")

    @_builtins.property
    @pulumi.getter
    def services(self) -> Sequence['outputs.GetServicesServiceResult']:
        """
        The list of services.
        The services structure is documented below.
        """
        return pulumi.get(self, "services")

    @_builtins.property
    @pulumi.getter
    def status(self) -> Optional[_builtins.str]:
        """
        Service status.  
        Value options are as follows:
        + **running**: The service is running properly.
        + **deploying**: The service is being deployed, including image creation and resource scheduling deployment.
        + **concerning**: An alarm has been generated, indicating that some backend instances malfunction.
        + **failed**: Deploying the service failed. For details about the failure cause, see the event and log tab pages.
        + **stopped**: The service has been stopped.
        + **finished**: Service running is completed. This status is available only for batch services.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter(name="workspaceId")
    def workspace_id(self) -> Optional[_builtins.str]:
        """
        The workspace ID to which a service belongs.  
        The default value is 0, indicating the default workspace.
        """
        return pulumi.get(self, "workspace_id")


class AwaitableGetServicesResult(GetServicesResult):
    # pylint: disable=using-constant-test
    def __await__(self):
        if False:
            yield self
        return GetServicesResult(
            id=self.id,
            infer_type=self.infer_type,
            model_id=self.model_id,
            name=self.name,
            region=self.region,
            service_id=self.service_id,
            services=self.services,
            status=self.status,
            workspace_id=self.workspace_id)


def get_services(infer_type: Optional[_builtins.str] = None,
                 model_id: Optional[_builtins.str] = None,
                 name: Optional[_builtins.str] = None,
                 region: Optional[_builtins.str] = None,
                 service_id: Optional[_builtins.str] = None,
                 status: Optional[_builtins.str] = None,
                 workspace_id: Optional[_builtins.str] = None,
                 opts: Optional[pulumi.InvokeOptions] = None) -> AwaitableGetServicesResult:
    """
    Use this data source to get services of ModelArts.

    ## Example Usage

    ```python
    import pulumi
    import pulumi_huaweicloud as huaweicloud

    test = huaweicloud.ModelArts.get_services()
    ```


    :param _builtins.str infer_type: Inference mode of the service.  
           Value options are as follows:
           + **real-time**: A real-time service. A model is deployed as a web service and provides real-time test UI and monitoring.
           + **batch**: A batch service, which can perform inference on batch data and automatically stops after data is processed.
           + **edge**: An edge service, which uses Intelligent EdgeFabric (IEF) to deploy a model as a web service on an edge
           node created on IEF.
    :param _builtins.str model_id: The model ID which the service used.
    :param _builtins.str name: Service name.
    :param _builtins.str region: Specifies the region in which to query the data source.
           If omitted, the provider-level region will be used.
    :param _builtins.str service_id: Service ID.
    :param _builtins.str status: Service status.  
           Value options are as follows:
           + **running**: The service is running properly.
           + **deploying**: The service is being deployed, including image creation and resource scheduling deployment.
           + **concerning**: An alarm has been generated, indicating that some backend instances malfunction.
           + **failed**: Deploying the service failed. For details about the failure cause, see the event and log tab pages.
           + **stopped**: The service has been stopped.
           + **finished**: Service running is completed. This status is available only for batch services.
    :param _builtins.str workspace_id: The workspace ID to which a service belongs.  
           The default value is 0, indicating the default workspace.
    """
    __args__ = dict()
    __args__['inferType'] = infer_type
    __args__['modelId'] = model_id
    __args__['name'] = name
    __args__['region'] = region
    __args__['serviceId'] = service_id
    __args__['status'] = status
    __args__['workspaceId'] = workspace_id
    opts = pulumi.InvokeOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke('huaweicloud:ModelArts/getServices:getServices', __args__, opts=opts, typ=GetServicesResult).value

    return AwaitableGetServicesResult(
        id=pulumi.get(__ret__, 'id'),
        infer_type=pulumi.get(__ret__, 'infer_type'),
        model_id=pulumi.get(__ret__, 'model_id'),
        name=pulumi.get(__ret__, 'name'),
        region=pulumi.get(__ret__, 'region'),
        service_id=pulumi.get(__ret__, 'service_id'),
        services=pulumi.get(__ret__, 'services'),
        status=pulumi.get(__ret__, 'status'),
        workspace_id=pulumi.get(__ret__, 'workspace_id'))
def get_services_output(infer_type: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                        model_id: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                        name: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                        region: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                        service_id: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                        status: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                        workspace_id: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                        opts: Optional[Union[pulumi.InvokeOptions, pulumi.InvokeOutputOptions]] = None) -> pulumi.Output[GetServicesResult]:
    """
    Use this data source to get services of ModelArts.

    ## Example Usage

    ```python
    import pulumi
    import pulumi_huaweicloud as huaweicloud

    test = huaweicloud.ModelArts.get_services()
    ```


    :param _builtins.str infer_type: Inference mode of the service.  
           Value options are as follows:
           + **real-time**: A real-time service. A model is deployed as a web service and provides real-time test UI and monitoring.
           + **batch**: A batch service, which can perform inference on batch data and automatically stops after data is processed.
           + **edge**: An edge service, which uses Intelligent EdgeFabric (IEF) to deploy a model as a web service on an edge
           node created on IEF.
    :param _builtins.str model_id: The model ID which the service used.
    :param _builtins.str name: Service name.
    :param _builtins.str region: Specifies the region in which to query the data source.
           If omitted, the provider-level region will be used.
    :param _builtins.str service_id: Service ID.
    :param _builtins.str status: Service status.  
           Value options are as follows:
           + **running**: The service is running properly.
           + **deploying**: The service is being deployed, including image creation and resource scheduling deployment.
           + **concerning**: An alarm has been generated, indicating that some backend instances malfunction.
           + **failed**: Deploying the service failed. For details about the failure cause, see the event and log tab pages.
           + **stopped**: The service has been stopped.
           + **finished**: Service running is completed. This status is available only for batch services.
    :param _builtins.str workspace_id: The workspace ID to which a service belongs.  
           The default value is 0, indicating the default workspace.
    """
    __args__ = dict()
    __args__['inferType'] = infer_type
    __args__['modelId'] = model_id
    __args__['name'] = name
    __args__['region'] = region
    __args__['serviceId'] = service_id
    __args__['status'] = status
    __args__['workspaceId'] = workspace_id
    opts = pulumi.InvokeOutputOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke_output('huaweicloud:ModelArts/getServices:getServices', __args__, opts=opts, typ=GetServicesResult)
    return __ret__.apply(lambda __response__: GetServicesResult(
        id=pulumi.get(__response__, 'id'),
        infer_type=pulumi.get(__response__, 'infer_type'),
        model_id=pulumi.get(__response__, 'model_id'),
        name=pulumi.get(__response__, 'name'),
        region=pulumi.get(__response__, 'region'),
        service_id=pulumi.get(__response__, 'service_id'),
        services=pulumi.get(__response__, 'services'),
        status=pulumi.get(__response__, 'status'),
        workspace_id=pulumi.get(__response__, 'workspace_id')))
