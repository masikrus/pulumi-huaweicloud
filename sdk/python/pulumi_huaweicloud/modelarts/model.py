# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs
from ._inputs import *

__all__ = ['ModelArgs', 'Model']

@pulumi.input_type
class ModelArgs:
    def __init__(__self__, *,
                 model_type: pulumi.Input[_builtins.str],
                 source_location: pulumi.Input[_builtins.str],
                 version: pulumi.Input[_builtins.str],
                 dependencies: Optional[pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]]] = None,
                 description: Optional[pulumi.Input[_builtins.str]] = None,
                 execution_code: Optional[pulumi.Input[_builtins.str]] = None,
                 initial_config: Optional[pulumi.Input[_builtins.str]] = None,
                 install_types: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 metrics: Optional[pulumi.Input[_builtins.str]] = None,
                 model_algorithm: Optional[pulumi.Input[_builtins.str]] = None,
                 model_docs: Optional[pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]]] = None,
                 name: Optional[pulumi.Input[_builtins.str]] = None,
                 region: Optional[pulumi.Input[_builtins.str]] = None,
                 runtime: Optional[pulumi.Input[_builtins.str]] = None,
                 source_copy: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_id: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_version: Optional[pulumi.Input[_builtins.str]] = None,
                 source_type: Optional[pulumi.Input[_builtins.str]] = None,
                 template: Optional[pulumi.Input['ModelTemplateArgs']] = None,
                 workspace_id: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The set of arguments for constructing a Model resource.
        :param pulumi.Input[_builtins.str] model_type: Model type.  
               It can be **TensorFlow**, **MXNet**, **Caffe**, **Spark_MLlib**, **Scikit_Learn**,
               **XGBoost**, **Image**, **PyTorch**, or **Template** read from the configuration file.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_location: OBS path where the model is located or the SWR image location.  
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] version: Model version in the format of Digit.Digit.Digit.  
               Each digit is a one-digit or two-digit positive integer, but cannot start with 0.
               For example, 01.01.01 is not allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]] dependencies: Package required for inference code and model.  
               If the package is read from the configuration file, this parameter can be left blank.
               The Dependency structure is documented below.
               
               Changing this parameter will create a new resource.
               
               <a name="ModelartsModel_ModelDocs"></a>
               The `ModelDocs` block supports:
        :param pulumi.Input[_builtins.str] description: Model description that consists of 1 to 100 characters.  
               The following special characters cannot be contained: **&!'"<>=**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] execution_code: OBS path for storing the execution code.  
               The name of the execution code file is consistently to be **customize_service.py**.
               The inference code file must be stored in the model directory.
               This parameter can be left blank. Then, the system will automatically identify the inference
               code in the model directory.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] initial_config: The model configuration file describes the model usage,
               computing framework, precision, inference code dependency package, and model API.
               The fields such as `model_algorithm`, `model_type`, `runtime`, `swr_location`, `metrics`, `apis`,
               `dependencies`, and `health` in the configuration file config.json.
               For details, see [Specifications for Writing the Model Configuration File](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0056.html)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] install_types: Deployment type. Only lowercase letters are supported.
               The value can be **real-time**, **edge**, or **batch**. Default value: [real-time, edge, batch].
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] metrics: Model precision.  
               If the value is read from the configuration file, this parameter can be left blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] model_algorithm: Model algorithm.  
               If the algorithm is read from the configuration file, this parameter can be left blank.
               The value can be **predict_analysis**, **object_detection**, **image_classification**, or **unknown_algorithm**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]] model_docs: List of model description documents. A maximum of three documents are supported.
               
               Changing this parameter will create a new resource.
               The ModelDocs structure is documented below.
        :param pulumi.Input[_builtins.str] name: Model name, which consists of 1 to 64 characters.  
               Only letters, digits, hyphens (-), and underscores (_) are allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] region: Specifies the region in which to create the resource.
               If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] runtime: Model runtime environment.  
               Its possible values are determined based on model_type.
               For details, see [Supported AI engines and their runtime](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0003.html#section3)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_copy: Whether to enable image replication.  
               This parameter is valid only when `model_type` is set to **Image**.
               Value options are as follows:
               + **true**: Default value, indicating that image replication is enabled.
               After this function is enabled, AI applications cannot be rapidly created, and modifying
               or deleting an image in the SWR source directory will not affect service deployment.
               + **false**: Image replication is not enabled.
               After this function is disabled, AI applications can be rapidly created, but modifying
               or deleting an image in the SWR source directory will affect service deployment.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_id: ID of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_version: Version of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_type: Model source type, which can only be **auto**,
               indicating an ExeML model (model download is not allowed).
               If the model is obtained from a training job, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input['ModelTemplateArgs'] template: Configuration items in a template.  
               This parameter is mandatory when `model_type` is set to **Template**.
               
               Changing this parameter will create a new resource.
               The Template structure is documented below.
        :param pulumi.Input[_builtins.str] workspace_id: Workspace ID, which defaults to 0.  
               
               Changing this parameter will create a new resource.
        """
        pulumi.set(__self__, "model_type", model_type)
        pulumi.set(__self__, "source_location", source_location)
        pulumi.set(__self__, "version", version)
        if dependencies is not None:
            pulumi.set(__self__, "dependencies", dependencies)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if execution_code is not None:
            pulumi.set(__self__, "execution_code", execution_code)
        if initial_config is not None:
            pulumi.set(__self__, "initial_config", initial_config)
        if install_types is not None:
            pulumi.set(__self__, "install_types", install_types)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)
        if model_algorithm is not None:
            pulumi.set(__self__, "model_algorithm", model_algorithm)
        if model_docs is not None:
            pulumi.set(__self__, "model_docs", model_docs)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if runtime is not None:
            pulumi.set(__self__, "runtime", runtime)
        if source_copy is not None:
            pulumi.set(__self__, "source_copy", source_copy)
        if source_job_id is not None:
            pulumi.set(__self__, "source_job_id", source_job_id)
        if source_job_version is not None:
            pulumi.set(__self__, "source_job_version", source_job_version)
        if source_type is not None:
            pulumi.set(__self__, "source_type", source_type)
        if template is not None:
            pulumi.set(__self__, "template", template)
        if workspace_id is not None:
            pulumi.set(__self__, "workspace_id", workspace_id)

    @_builtins.property
    @pulumi.getter(name="modelType")
    def model_type(self) -> pulumi.Input[_builtins.str]:
        """
        Model type.  
        It can be **TensorFlow**, **MXNet**, **Caffe**, **Spark_MLlib**, **Scikit_Learn**,
        **XGBoost**, **Image**, **PyTorch**, or **Template** read from the configuration file.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "model_type")

    @model_type.setter
    def model_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "model_type", value)

    @_builtins.property
    @pulumi.getter(name="sourceLocation")
    def source_location(self) -> pulumi.Input[_builtins.str]:
        """
        OBS path where the model is located or the SWR image location.  

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_location")

    @source_location.setter
    def source_location(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "source_location", value)

    @_builtins.property
    @pulumi.getter
    def version(self) -> pulumi.Input[_builtins.str]:
        """
        Model version in the format of Digit.Digit.Digit.  
        Each digit is a one-digit or two-digit positive integer, but cannot start with 0.
        For example, 01.01.01 is not allowed.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "version", value)

    @_builtins.property
    @pulumi.getter
    def dependencies(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]]]:
        """
        Package required for inference code and model.  
        If the package is read from the configuration file, this parameter can be left blank.
        The Dependency structure is documented below.

        Changing this parameter will create a new resource.

        <a name="ModelartsModel_ModelDocs"></a>
        The `ModelDocs` block supports:
        """
        return pulumi.get(self, "dependencies")

    @dependencies.setter
    def dependencies(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]]]):
        pulumi.set(self, "dependencies", value)

    @_builtins.property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model description that consists of 1 to 100 characters.  
        The following special characters cannot be contained: **&!'"<>=**.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "description", value)

    @_builtins.property
    @pulumi.getter(name="executionCode")
    def execution_code(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        OBS path for storing the execution code.  
        The name of the execution code file is consistently to be **customize_service.py**.
        The inference code file must be stored in the model directory.
        This parameter can be left blank. Then, the system will automatically identify the inference
        code in the model directory.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "execution_code")

    @execution_code.setter
    def execution_code(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "execution_code", value)

    @_builtins.property
    @pulumi.getter(name="initialConfig")
    def initial_config(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The model configuration file describes the model usage,
        computing framework, precision, inference code dependency package, and model API.
        The fields such as `model_algorithm`, `model_type`, `runtime`, `swr_location`, `metrics`, `apis`,
        `dependencies`, and `health` in the configuration file config.json.
        For details, see [Specifications for Writing the Model Configuration File](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0056.html)

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "initial_config")

    @initial_config.setter
    def initial_config(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "initial_config", value)

    @_builtins.property
    @pulumi.getter(name="installTypes")
    def install_types(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Deployment type. Only lowercase letters are supported.
        The value can be **real-time**, **edge**, or **batch**. Default value: [real-time, edge, batch].

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "install_types")

    @install_types.setter
    def install_types(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "install_types", value)

    @_builtins.property
    @pulumi.getter
    def metrics(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model precision.  
        If the value is read from the configuration file, this parameter can be left blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "metrics")

    @metrics.setter
    def metrics(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "metrics", value)

    @_builtins.property
    @pulumi.getter(name="modelAlgorithm")
    def model_algorithm(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model algorithm.  
        If the algorithm is read from the configuration file, this parameter can be left blank.
        The value can be **predict_analysis**, **object_detection**, **image_classification**, or **unknown_algorithm**.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "model_algorithm")

    @model_algorithm.setter
    def model_algorithm(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_algorithm", value)

    @_builtins.property
    @pulumi.getter(name="modelDocs")
    def model_docs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]]]:
        """
        List of model description documents. A maximum of three documents are supported.

        Changing this parameter will create a new resource.
        The ModelDocs structure is documented below.
        """
        return pulumi.get(self, "model_docs")

    @model_docs.setter
    def model_docs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]]]):
        pulumi.set(self, "model_docs", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model name, which consists of 1 to 64 characters.  
        Only letters, digits, hyphens (-), and underscores (_) are allowed.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def region(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the region in which to create the resource.
        If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "region", value)

    @_builtins.property
    @pulumi.getter
    def runtime(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model runtime environment.  
        Its possible values are determined based on model_type.
        For details, see [Supported AI engines and their runtime](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0003.html#section3)

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "runtime")

    @runtime.setter
    def runtime(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "runtime", value)

    @_builtins.property
    @pulumi.getter(name="sourceCopy")
    def source_copy(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Whether to enable image replication.  
        This parameter is valid only when `model_type` is set to **Image**.
        Value options are as follows:
        + **true**: Default value, indicating that image replication is enabled.
        After this function is enabled, AI applications cannot be rapidly created, and modifying
        or deleting an image in the SWR source directory will not affect service deployment.
        + **false**: Image replication is not enabled.
        After this function is disabled, AI applications can be rapidly created, but modifying
        or deleting an image in the SWR source directory will affect service deployment.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_copy")

    @source_copy.setter
    def source_copy(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_copy", value)

    @_builtins.property
    @pulumi.getter(name="sourceJobId")
    def source_job_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        ID of the source training job.  
        If the model is generated from a training job, input this parameter for source tracing.
        If the model is imported from a third-party meta model, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_job_id")

    @source_job_id.setter
    def source_job_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_job_id", value)

    @_builtins.property
    @pulumi.getter(name="sourceJobVersion")
    def source_job_version(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Version of the source training job.  
        If the model is generated from a training job, input this parameter for source tracing.
        If the model is imported from a third-party meta model, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_job_version")

    @source_job_version.setter
    def source_job_version(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_job_version", value)

    @_builtins.property
    @pulumi.getter(name="sourceType")
    def source_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model source type, which can only be **auto**,
        indicating an ExeML model (model download is not allowed).
        If the model is obtained from a training job, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_type")

    @source_type.setter
    def source_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_type", value)

    @_builtins.property
    @pulumi.getter
    def template(self) -> Optional[pulumi.Input['ModelTemplateArgs']]:
        """
        Configuration items in a template.  
        This parameter is mandatory when `model_type` is set to **Template**.

        Changing this parameter will create a new resource.
        The Template structure is documented below.
        """
        return pulumi.get(self, "template")

    @template.setter
    def template(self, value: Optional[pulumi.Input['ModelTemplateArgs']]):
        pulumi.set(self, "template", value)

    @_builtins.property
    @pulumi.getter(name="workspaceId")
    def workspace_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Workspace ID, which defaults to 0.  

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "workspace_id")

    @workspace_id.setter
    def workspace_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "workspace_id", value)


@pulumi.input_type
class _ModelState:
    def __init__(__self__, *,
                 dependencies: Optional[pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]]] = None,
                 description: Optional[pulumi.Input[_builtins.str]] = None,
                 execution_code: Optional[pulumi.Input[_builtins.str]] = None,
                 image_address: Optional[pulumi.Input[_builtins.str]] = None,
                 initial_config: Optional[pulumi.Input[_builtins.str]] = None,
                 install_types: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 market_flag: Optional[pulumi.Input[_builtins.bool]] = None,
                 metrics: Optional[pulumi.Input[_builtins.str]] = None,
                 model_algorithm: Optional[pulumi.Input[_builtins.str]] = None,
                 model_docs: Optional[pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]]] = None,
                 model_size: Optional[pulumi.Input[_builtins.int]] = None,
                 model_source: Optional[pulumi.Input[_builtins.str]] = None,
                 model_type: Optional[pulumi.Input[_builtins.str]] = None,
                 name: Optional[pulumi.Input[_builtins.str]] = None,
                 publishable_flag: Optional[pulumi.Input[_builtins.bool]] = None,
                 region: Optional[pulumi.Input[_builtins.str]] = None,
                 runtime: Optional[pulumi.Input[_builtins.str]] = None,
                 schema_doc: Optional[pulumi.Input[_builtins.str]] = None,
                 source_copy: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_id: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_version: Optional[pulumi.Input[_builtins.str]] = None,
                 source_location: Optional[pulumi.Input[_builtins.str]] = None,
                 source_type: Optional[pulumi.Input[_builtins.str]] = None,
                 status: Optional[pulumi.Input[_builtins.str]] = None,
                 template: Optional[pulumi.Input['ModelTemplateArgs']] = None,
                 tunable: Optional[pulumi.Input[_builtins.bool]] = None,
                 version: Optional[pulumi.Input[_builtins.str]] = None,
                 workspace_id: Optional[pulumi.Input[_builtins.str]] = None):
        """
        Input properties used for looking up and filtering Model resources.
        :param pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]] dependencies: Package required for inference code and model.  
               If the package is read from the configuration file, this parameter can be left blank.
               The Dependency structure is documented below.
               
               Changing this parameter will create a new resource.
               
               <a name="ModelartsModel_ModelDocs"></a>
               The `ModelDocs` block supports:
        :param pulumi.Input[_builtins.str] description: Model description that consists of 1 to 100 characters.  
               The following special characters cannot be contained: **&!'"<>=**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] execution_code: OBS path for storing the execution code.  
               The name of the execution code file is consistently to be **customize_service.py**.
               The inference code file must be stored in the model directory.
               This parameter can be left blank. Then, the system will automatically identify the inference
               code in the model directory.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] image_address: Image path generated after model packaging.
        :param pulumi.Input[_builtins.str] initial_config: The model configuration file describes the model usage,
               computing framework, precision, inference code dependency package, and model API.
               The fields such as `model_algorithm`, `model_type`, `runtime`, `swr_location`, `metrics`, `apis`,
               `dependencies`, and `health` in the configuration file config.json.
               For details, see [Specifications for Writing the Model Configuration File](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0056.html)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] install_types: Deployment type. Only lowercase letters are supported.
               The value can be **real-time**, **edge**, or **batch**. Default value: [real-time, edge, batch].
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.bool] market_flag: Whether a model is subscribed from AI Gallery.
        :param pulumi.Input[_builtins.str] metrics: Model precision.  
               If the value is read from the configuration file, this parameter can be left blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] model_algorithm: Model algorithm.  
               If the algorithm is read from the configuration file, this parameter can be left blank.
               The value can be **predict_analysis**, **object_detection**, **image_classification**, or **unknown_algorithm**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]] model_docs: List of model description documents. A maximum of three documents are supported.
               
               Changing this parameter will create a new resource.
               The ModelDocs structure is documented below.
        :param pulumi.Input[_builtins.int] model_size: Model size, in bytes.
        :param pulumi.Input[_builtins.str] model_source: Model source.  
               Value options are as follows:
               + **auto**: ExeML.
               + **algos**: built-in algorithm.
               + **custom**: custom model.
        :param pulumi.Input[_builtins.str] model_type: Model type.  
               It can be **TensorFlow**, **MXNet**, **Caffe**, **Spark_MLlib**, **Scikit_Learn**,
               **XGBoost**, **Image**, **PyTorch**, or **Template** read from the configuration file.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] name: Model name, which consists of 1 to 64 characters.  
               Only letters, digits, hyphens (-), and underscores (_) are allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.bool] publishable_flag: Whether a model is subscribed from AI Gallery.
        :param pulumi.Input[_builtins.str] region: Specifies the region in which to create the resource.
               If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] runtime: Model runtime environment.  
               Its possible values are determined based on model_type.
               For details, see [Supported AI engines and their runtime](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0003.html#section3)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] schema_doc: Download address of the model schema file.
        :param pulumi.Input[_builtins.str] source_copy: Whether to enable image replication.  
               This parameter is valid only when `model_type` is set to **Image**.
               Value options are as follows:
               + **true**: Default value, indicating that image replication is enabled.
               After this function is enabled, AI applications cannot be rapidly created, and modifying
               or deleting an image in the SWR source directory will not affect service deployment.
               + **false**: Image replication is not enabled.
               After this function is disabled, AI applications can be rapidly created, but modifying
               or deleting an image in the SWR source directory will affect service deployment.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_id: ID of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_version: Version of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_location: OBS path where the model is located or the SWR image location.  
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_type: Model source type, which can only be **auto**,
               indicating an ExeML model (model download is not allowed).
               If the model is obtained from a training job, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] status: Model status.
        :param pulumi.Input['ModelTemplateArgs'] template: Configuration items in a template.  
               This parameter is mandatory when `model_type` is set to **Template**.
               
               Changing this parameter will create a new resource.
               The Template structure is documented below.
        :param pulumi.Input[_builtins.bool] tunable: Whether a model can be tuned.
        :param pulumi.Input[_builtins.str] version: Model version in the format of Digit.Digit.Digit.  
               Each digit is a one-digit or two-digit positive integer, but cannot start with 0.
               For example, 01.01.01 is not allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] workspace_id: Workspace ID, which defaults to 0.  
               
               Changing this parameter will create a new resource.
        """
        if dependencies is not None:
            pulumi.set(__self__, "dependencies", dependencies)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if execution_code is not None:
            pulumi.set(__self__, "execution_code", execution_code)
        if image_address is not None:
            pulumi.set(__self__, "image_address", image_address)
        if initial_config is not None:
            pulumi.set(__self__, "initial_config", initial_config)
        if install_types is not None:
            pulumi.set(__self__, "install_types", install_types)
        if market_flag is not None:
            pulumi.set(__self__, "market_flag", market_flag)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)
        if model_algorithm is not None:
            pulumi.set(__self__, "model_algorithm", model_algorithm)
        if model_docs is not None:
            pulumi.set(__self__, "model_docs", model_docs)
        if model_size is not None:
            pulumi.set(__self__, "model_size", model_size)
        if model_source is not None:
            pulumi.set(__self__, "model_source", model_source)
        if model_type is not None:
            pulumi.set(__self__, "model_type", model_type)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if publishable_flag is not None:
            pulumi.set(__self__, "publishable_flag", publishable_flag)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if runtime is not None:
            pulumi.set(__self__, "runtime", runtime)
        if schema_doc is not None:
            pulumi.set(__self__, "schema_doc", schema_doc)
        if source_copy is not None:
            pulumi.set(__self__, "source_copy", source_copy)
        if source_job_id is not None:
            pulumi.set(__self__, "source_job_id", source_job_id)
        if source_job_version is not None:
            pulumi.set(__self__, "source_job_version", source_job_version)
        if source_location is not None:
            pulumi.set(__self__, "source_location", source_location)
        if source_type is not None:
            pulumi.set(__self__, "source_type", source_type)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if template is not None:
            pulumi.set(__self__, "template", template)
        if tunable is not None:
            pulumi.set(__self__, "tunable", tunable)
        if version is not None:
            pulumi.set(__self__, "version", version)
        if workspace_id is not None:
            pulumi.set(__self__, "workspace_id", workspace_id)

    @_builtins.property
    @pulumi.getter
    def dependencies(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]]]:
        """
        Package required for inference code and model.  
        If the package is read from the configuration file, this parameter can be left blank.
        The Dependency structure is documented below.

        Changing this parameter will create a new resource.

        <a name="ModelartsModel_ModelDocs"></a>
        The `ModelDocs` block supports:
        """
        return pulumi.get(self, "dependencies")

    @dependencies.setter
    def dependencies(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ModelDependencyArgs']]]]):
        pulumi.set(self, "dependencies", value)

    @_builtins.property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model description that consists of 1 to 100 characters.  
        The following special characters cannot be contained: **&!'"<>=**.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "description", value)

    @_builtins.property
    @pulumi.getter(name="executionCode")
    def execution_code(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        OBS path for storing the execution code.  
        The name of the execution code file is consistently to be **customize_service.py**.
        The inference code file must be stored in the model directory.
        This parameter can be left blank. Then, the system will automatically identify the inference
        code in the model directory.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "execution_code")

    @execution_code.setter
    def execution_code(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "execution_code", value)

    @_builtins.property
    @pulumi.getter(name="imageAddress")
    def image_address(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Image path generated after model packaging.
        """
        return pulumi.get(self, "image_address")

    @image_address.setter
    def image_address(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "image_address", value)

    @_builtins.property
    @pulumi.getter(name="initialConfig")
    def initial_config(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The model configuration file describes the model usage,
        computing framework, precision, inference code dependency package, and model API.
        The fields such as `model_algorithm`, `model_type`, `runtime`, `swr_location`, `metrics`, `apis`,
        `dependencies`, and `health` in the configuration file config.json.
        For details, see [Specifications for Writing the Model Configuration File](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0056.html)

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "initial_config")

    @initial_config.setter
    def initial_config(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "initial_config", value)

    @_builtins.property
    @pulumi.getter(name="installTypes")
    def install_types(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Deployment type. Only lowercase letters are supported.
        The value can be **real-time**, **edge**, or **batch**. Default value: [real-time, edge, batch].

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "install_types")

    @install_types.setter
    def install_types(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "install_types", value)

    @_builtins.property
    @pulumi.getter(name="marketFlag")
    def market_flag(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Whether a model is subscribed from AI Gallery.
        """
        return pulumi.get(self, "market_flag")

    @market_flag.setter
    def market_flag(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "market_flag", value)

    @_builtins.property
    @pulumi.getter
    def metrics(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model precision.  
        If the value is read from the configuration file, this parameter can be left blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "metrics")

    @metrics.setter
    def metrics(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "metrics", value)

    @_builtins.property
    @pulumi.getter(name="modelAlgorithm")
    def model_algorithm(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model algorithm.  
        If the algorithm is read from the configuration file, this parameter can be left blank.
        The value can be **predict_analysis**, **object_detection**, **image_classification**, or **unknown_algorithm**.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "model_algorithm")

    @model_algorithm.setter
    def model_algorithm(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_algorithm", value)

    @_builtins.property
    @pulumi.getter(name="modelDocs")
    def model_docs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]]]:
        """
        List of model description documents. A maximum of three documents are supported.

        Changing this parameter will create a new resource.
        The ModelDocs structure is documented below.
        """
        return pulumi.get(self, "model_docs")

    @model_docs.setter
    def model_docs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ModelModelDocArgs']]]]):
        pulumi.set(self, "model_docs", value)

    @_builtins.property
    @pulumi.getter(name="modelSize")
    def model_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Model size, in bytes.
        """
        return pulumi.get(self, "model_size")

    @model_size.setter
    def model_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "model_size", value)

    @_builtins.property
    @pulumi.getter(name="modelSource")
    def model_source(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model source.  
        Value options are as follows:
        + **auto**: ExeML.
        + **algos**: built-in algorithm.
        + **custom**: custom model.
        """
        return pulumi.get(self, "model_source")

    @model_source.setter
    def model_source(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_source", value)

    @_builtins.property
    @pulumi.getter(name="modelType")
    def model_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model type.  
        It can be **TensorFlow**, **MXNet**, **Caffe**, **Spark_MLlib**, **Scikit_Learn**,
        **XGBoost**, **Image**, **PyTorch**, or **Template** read from the configuration file.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "model_type")

    @model_type.setter
    def model_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_type", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model name, which consists of 1 to 64 characters.  
        Only letters, digits, hyphens (-), and underscores (_) are allowed.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter(name="publishableFlag")
    def publishable_flag(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Whether a model is subscribed from AI Gallery.
        """
        return pulumi.get(self, "publishable_flag")

    @publishable_flag.setter
    def publishable_flag(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "publishable_flag", value)

    @_builtins.property
    @pulumi.getter
    def region(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specifies the region in which to create the resource.
        If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "region", value)

    @_builtins.property
    @pulumi.getter
    def runtime(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model runtime environment.  
        Its possible values are determined based on model_type.
        For details, see [Supported AI engines and their runtime](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0003.html#section3)

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "runtime")

    @runtime.setter
    def runtime(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "runtime", value)

    @_builtins.property
    @pulumi.getter(name="schemaDoc")
    def schema_doc(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Download address of the model schema file.
        """
        return pulumi.get(self, "schema_doc")

    @schema_doc.setter
    def schema_doc(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "schema_doc", value)

    @_builtins.property
    @pulumi.getter(name="sourceCopy")
    def source_copy(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Whether to enable image replication.  
        This parameter is valid only when `model_type` is set to **Image**.
        Value options are as follows:
        + **true**: Default value, indicating that image replication is enabled.
        After this function is enabled, AI applications cannot be rapidly created, and modifying
        or deleting an image in the SWR source directory will not affect service deployment.
        + **false**: Image replication is not enabled.
        After this function is disabled, AI applications can be rapidly created, but modifying
        or deleting an image in the SWR source directory will affect service deployment.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_copy")

    @source_copy.setter
    def source_copy(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_copy", value)

    @_builtins.property
    @pulumi.getter(name="sourceJobId")
    def source_job_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        ID of the source training job.  
        If the model is generated from a training job, input this parameter for source tracing.
        If the model is imported from a third-party meta model, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_job_id")

    @source_job_id.setter
    def source_job_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_job_id", value)

    @_builtins.property
    @pulumi.getter(name="sourceJobVersion")
    def source_job_version(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Version of the source training job.  
        If the model is generated from a training job, input this parameter for source tracing.
        If the model is imported from a third-party meta model, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_job_version")

    @source_job_version.setter
    def source_job_version(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_job_version", value)

    @_builtins.property
    @pulumi.getter(name="sourceLocation")
    def source_location(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        OBS path where the model is located or the SWR image location.  

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_location")

    @source_location.setter
    def source_location(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_location", value)

    @_builtins.property
    @pulumi.getter(name="sourceType")
    def source_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model source type, which can only be **auto**,
        indicating an ExeML model (model download is not allowed).
        If the model is obtained from a training job, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_type")

    @source_type.setter
    def source_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_type", value)

    @_builtins.property
    @pulumi.getter
    def status(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model status.
        """
        return pulumi.get(self, "status")

    @status.setter
    def status(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "status", value)

    @_builtins.property
    @pulumi.getter
    def template(self) -> Optional[pulumi.Input['ModelTemplateArgs']]:
        """
        Configuration items in a template.  
        This parameter is mandatory when `model_type` is set to **Template**.

        Changing this parameter will create a new resource.
        The Template structure is documented below.
        """
        return pulumi.get(self, "template")

    @template.setter
    def template(self, value: Optional[pulumi.Input['ModelTemplateArgs']]):
        pulumi.set(self, "template", value)

    @_builtins.property
    @pulumi.getter
    def tunable(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Whether a model can be tuned.
        """
        return pulumi.get(self, "tunable")

    @tunable.setter
    def tunable(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "tunable", value)

    @_builtins.property
    @pulumi.getter
    def version(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Model version in the format of Digit.Digit.Digit.  
        Each digit is a one-digit or two-digit positive integer, but cannot start with 0.
        For example, 01.01.01 is not allowed.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "version")

    @version.setter
    def version(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "version", value)

    @_builtins.property
    @pulumi.getter(name="workspaceId")
    def workspace_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Workspace ID, which defaults to 0.  

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "workspace_id")

    @workspace_id.setter
    def workspace_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "workspace_id", value)


@pulumi.type_token("huaweicloud:ModelArts/model:Model")
class Model(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 dependencies: Optional[pulumi.Input[Sequence[pulumi.Input[Union['ModelDependencyArgs', 'ModelDependencyArgsDict']]]]] = None,
                 description: Optional[pulumi.Input[_builtins.str]] = None,
                 execution_code: Optional[pulumi.Input[_builtins.str]] = None,
                 initial_config: Optional[pulumi.Input[_builtins.str]] = None,
                 install_types: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 metrics: Optional[pulumi.Input[_builtins.str]] = None,
                 model_algorithm: Optional[pulumi.Input[_builtins.str]] = None,
                 model_docs: Optional[pulumi.Input[Sequence[pulumi.Input[Union['ModelModelDocArgs', 'ModelModelDocArgsDict']]]]] = None,
                 model_type: Optional[pulumi.Input[_builtins.str]] = None,
                 name: Optional[pulumi.Input[_builtins.str]] = None,
                 region: Optional[pulumi.Input[_builtins.str]] = None,
                 runtime: Optional[pulumi.Input[_builtins.str]] = None,
                 source_copy: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_id: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_version: Optional[pulumi.Input[_builtins.str]] = None,
                 source_location: Optional[pulumi.Input[_builtins.str]] = None,
                 source_type: Optional[pulumi.Input[_builtins.str]] = None,
                 template: Optional[pulumi.Input[Union['ModelTemplateArgs', 'ModelTemplateArgsDict']]] = None,
                 version: Optional[pulumi.Input[_builtins.str]] = None,
                 workspace_id: Optional[pulumi.Input[_builtins.str]] = None,
                 __props__=None):
        """
        Manages a Modelarts model resource within HuaweiCloud.

        ## Example Usage

        ### Import a model from OBS

        ```python
        import pulumi
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        source_obs_path = config.require_object("sourceObsPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo",
            version="0.0.2",
            description="This is a demo",
            source_location=source_obs_path,
            model_type="TensorFlow",
            runtime="python3.6")
        ```

        ### Import a model from OBS and override the configuration file

        ```python
        import pulumi
        import json
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        source_obs_path = config.require_object("sourceObsPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo",
            version="0.0.2",
            description="This is a demo",
            source_location=source_obs_path,
            model_type="TensorFlow",
            runtime="python3.6",
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }],
            initial_config=json.dumps({
                "model_algorithm": "object_detection",
                "metrics": {},
                "apis": [{
                    "url": "/",
                    "method": "post",
                    "request": {
                        "Content-type": "multipart/form-data",
                        "data": {
                            "type": "object",
                            "properties": {
                                "images": {
                                    "type": "file",
                                },
                            },
                        },
                    },
                    "response": {
                        "Content-type": "application/json",
                        "data": {
                            "type": "object",
                            "properties": {
                                "mnist_result": {
                                    "type": "array",
                                    "item": [{
                                        "type": "string",
                                    }],
                                },
                            },
                        },
                    },
                }],
            }))
        ```

        ### Import a model from template

        ```python
        import pulumi
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        template_id = config.require_object("templateId")
        infer_format = config.require_object("inferFormat")
        template_obs_path = config.require_object("templateObsPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo",
            version="0.0.1",
            description="This is a demo",
            model_type="Template",
            template={
                "template_id": template_id,
                "infer_format": infer_format,
                "template_inputs": [{
                    "input_id": "model_folder",
                    "input": template_obs_path,
                }],
            },
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }])
        ```

        ### Import a model trained by a ModelArts training job

        ```python
        import pulumi
        import json
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        source_obs_path = config.require_object("sourceObsPath")
        execution_code_path = config.require_object("executionCodePath")
        source_job_id = config.require_object("sourceJobId")
        test = huaweicloud.modelarts.Model("test",
            name="demo_train_model",
            version="0.0.1",
            description="This is a demo import from train",
            source_location=source_obs_path,
            source_job_id=source_job_id,
            model_type="TensorFlow",
            runtime="tf1.13-python3.7-cpu",
            execution_code=execution_code_path,
            install_types=[
                "real-time",
                "batch",
            ],
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }],
            initial_config=json.dumps({
                "model_algorithm": "image_classification",
                "model_type": "TensorFlow",
                "metrics": {
                    "f1": 0.2,
                    "recall": 0,
                    "precision": 0,
                    "accuracy": 0,
                },
                "apis": [{
                    "url": "/",
                    "method": "post",
                    "request": {
                        "data": {
                            "type": "object",
                            "properties": {
                                "images": {
                                    "type": "file",
                                },
                            },
                        },
                        "Content-type": "multipart/form-data",
                    },
                    "response": {
                        "data": {
                            "type": "object",
                            "required": [
                                "predicted_label",
                                "scores",
                            ],
                            "properties": {
                                "predicted_label": {
                                    "type": "string",
                                },
                                "scores": {
                                    "type": "array",
                                    "items": {
                                        "type": "array",
                                        "minItems": 2,
                                        "maxItems": 2,
                                        "items": [
                                            {
                                                "type": "string",
                                            },
                                            {
                                                "type": "number",
                                            },
                                        ],
                                    },
                                },
                            },
                        },
                        "Content-type": "multipart/form-data",
                    },
                }],
                "dependencies": [{
                    "installer": "pip",
                    "packages": [
                        {
                            "package_name": "numpy",
                            "package_version": "1.17.0",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "h5py",
                            "package_version": "2.8.0",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "Pillow",
                            "package_version": "5.2.0",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "scipy",
                            "package_version": "1.2.1",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "resampy",
                            "package_version": "0.2.1",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "scikit-learn",
                            "package_version": "0.22.2",
                            "restraint": "EXACT",
                        },
                    ],
                }],
                "runtime": "tf1.13-python3.7-cpu",
                "model_source": "algos",
                "tunable": False,
            }))
        ```

        ### Import a model from a container image

        ```python
        import pulumi
        import json
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        swr_imag_path = config.require_object("swrImagPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo_swr",
            version="0.0.1",
            description="This is a demo import from swr",
            source_location=swr_imag_path,
            model_type="Image",
            source_copy="true",
            install_types=[
                "real-time",
                "batch",
            ],
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }],
            initial_config=json.dumps({
                "protocol": "https",
                "port": 90,
                "model_type": "Image",
                "algorithm": "unknown_algorithm",
                "health": {
                    "check_method": "EXEC",
                    "command": "echo 1",
                    "period_seconds": "1",
                    "failure_threshold": "2",
                    "initial_delay_seconds": "1",
                },
            }))
        ```

        ## Import

        The modelarts model can be imported using id, e.g.

        bash

        ```sh
        $ pulumi import huaweicloud:ModelArts/model:Model test 635a2d50-0546-469d-b45d-0204b9ad4f14
        ```

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[Sequence[pulumi.Input[Union['ModelDependencyArgs', 'ModelDependencyArgsDict']]]] dependencies: Package required for inference code and model.  
               If the package is read from the configuration file, this parameter can be left blank.
               The Dependency structure is documented below.
               
               Changing this parameter will create a new resource.
               
               <a name="ModelartsModel_ModelDocs"></a>
               The `ModelDocs` block supports:
        :param pulumi.Input[_builtins.str] description: Model description that consists of 1 to 100 characters.  
               The following special characters cannot be contained: **&!'"<>=**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] execution_code: OBS path for storing the execution code.  
               The name of the execution code file is consistently to be **customize_service.py**.
               The inference code file must be stored in the model directory.
               This parameter can be left blank. Then, the system will automatically identify the inference
               code in the model directory.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] initial_config: The model configuration file describes the model usage,
               computing framework, precision, inference code dependency package, and model API.
               The fields such as `model_algorithm`, `model_type`, `runtime`, `swr_location`, `metrics`, `apis`,
               `dependencies`, and `health` in the configuration file config.json.
               For details, see [Specifications for Writing the Model Configuration File](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0056.html)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] install_types: Deployment type. Only lowercase letters are supported.
               The value can be **real-time**, **edge**, or **batch**. Default value: [real-time, edge, batch].
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] metrics: Model precision.  
               If the value is read from the configuration file, this parameter can be left blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] model_algorithm: Model algorithm.  
               If the algorithm is read from the configuration file, this parameter can be left blank.
               The value can be **predict_analysis**, **object_detection**, **image_classification**, or **unknown_algorithm**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input[Union['ModelModelDocArgs', 'ModelModelDocArgsDict']]]] model_docs: List of model description documents. A maximum of three documents are supported.
               
               Changing this parameter will create a new resource.
               The ModelDocs structure is documented below.
        :param pulumi.Input[_builtins.str] model_type: Model type.  
               It can be **TensorFlow**, **MXNet**, **Caffe**, **Spark_MLlib**, **Scikit_Learn**,
               **XGBoost**, **Image**, **PyTorch**, or **Template** read from the configuration file.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] name: Model name, which consists of 1 to 64 characters.  
               Only letters, digits, hyphens (-), and underscores (_) are allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] region: Specifies the region in which to create the resource.
               If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] runtime: Model runtime environment.  
               Its possible values are determined based on model_type.
               For details, see [Supported AI engines and their runtime](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0003.html#section3)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_copy: Whether to enable image replication.  
               This parameter is valid only when `model_type` is set to **Image**.
               Value options are as follows:
               + **true**: Default value, indicating that image replication is enabled.
               After this function is enabled, AI applications cannot be rapidly created, and modifying
               or deleting an image in the SWR source directory will not affect service deployment.
               + **false**: Image replication is not enabled.
               After this function is disabled, AI applications can be rapidly created, but modifying
               or deleting an image in the SWR source directory will affect service deployment.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_id: ID of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_version: Version of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_location: OBS path where the model is located or the SWR image location.  
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_type: Model source type, which can only be **auto**,
               indicating an ExeML model (model download is not allowed).
               If the model is obtained from a training job, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Union['ModelTemplateArgs', 'ModelTemplateArgsDict']] template: Configuration items in a template.  
               This parameter is mandatory when `model_type` is set to **Template**.
               
               Changing this parameter will create a new resource.
               The Template structure is documented below.
        :param pulumi.Input[_builtins.str] version: Model version in the format of Digit.Digit.Digit.  
               Each digit is a one-digit or two-digit positive integer, but cannot start with 0.
               For example, 01.01.01 is not allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] workspace_id: Workspace ID, which defaults to 0.  
               
               Changing this parameter will create a new resource.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: ModelArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        Manages a Modelarts model resource within HuaweiCloud.

        ## Example Usage

        ### Import a model from OBS

        ```python
        import pulumi
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        source_obs_path = config.require_object("sourceObsPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo",
            version="0.0.2",
            description="This is a demo",
            source_location=source_obs_path,
            model_type="TensorFlow",
            runtime="python3.6")
        ```

        ### Import a model from OBS and override the configuration file

        ```python
        import pulumi
        import json
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        source_obs_path = config.require_object("sourceObsPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo",
            version="0.0.2",
            description="This is a demo",
            source_location=source_obs_path,
            model_type="TensorFlow",
            runtime="python3.6",
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }],
            initial_config=json.dumps({
                "model_algorithm": "object_detection",
                "metrics": {},
                "apis": [{
                    "url": "/",
                    "method": "post",
                    "request": {
                        "Content-type": "multipart/form-data",
                        "data": {
                            "type": "object",
                            "properties": {
                                "images": {
                                    "type": "file",
                                },
                            },
                        },
                    },
                    "response": {
                        "Content-type": "application/json",
                        "data": {
                            "type": "object",
                            "properties": {
                                "mnist_result": {
                                    "type": "array",
                                    "item": [{
                                        "type": "string",
                                    }],
                                },
                            },
                        },
                    },
                }],
            }))
        ```

        ### Import a model from template

        ```python
        import pulumi
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        template_id = config.require_object("templateId")
        infer_format = config.require_object("inferFormat")
        template_obs_path = config.require_object("templateObsPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo",
            version="0.0.1",
            description="This is a demo",
            model_type="Template",
            template={
                "template_id": template_id,
                "infer_format": infer_format,
                "template_inputs": [{
                    "input_id": "model_folder",
                    "input": template_obs_path,
                }],
            },
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }])
        ```

        ### Import a model trained by a ModelArts training job

        ```python
        import pulumi
        import json
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        source_obs_path = config.require_object("sourceObsPath")
        execution_code_path = config.require_object("executionCodePath")
        source_job_id = config.require_object("sourceJobId")
        test = huaweicloud.modelarts.Model("test",
            name="demo_train_model",
            version="0.0.1",
            description="This is a demo import from train",
            source_location=source_obs_path,
            source_job_id=source_job_id,
            model_type="TensorFlow",
            runtime="tf1.13-python3.7-cpu",
            execution_code=execution_code_path,
            install_types=[
                "real-time",
                "batch",
            ],
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }],
            initial_config=json.dumps({
                "model_algorithm": "image_classification",
                "model_type": "TensorFlow",
                "metrics": {
                    "f1": 0.2,
                    "recall": 0,
                    "precision": 0,
                    "accuracy": 0,
                },
                "apis": [{
                    "url": "/",
                    "method": "post",
                    "request": {
                        "data": {
                            "type": "object",
                            "properties": {
                                "images": {
                                    "type": "file",
                                },
                            },
                        },
                        "Content-type": "multipart/form-data",
                    },
                    "response": {
                        "data": {
                            "type": "object",
                            "required": [
                                "predicted_label",
                                "scores",
                            ],
                            "properties": {
                                "predicted_label": {
                                    "type": "string",
                                },
                                "scores": {
                                    "type": "array",
                                    "items": {
                                        "type": "array",
                                        "minItems": 2,
                                        "maxItems": 2,
                                        "items": [
                                            {
                                                "type": "string",
                                            },
                                            {
                                                "type": "number",
                                            },
                                        ],
                                    },
                                },
                            },
                        },
                        "Content-type": "multipart/form-data",
                    },
                }],
                "dependencies": [{
                    "installer": "pip",
                    "packages": [
                        {
                            "package_name": "numpy",
                            "package_version": "1.17.0",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "h5py",
                            "package_version": "2.8.0",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "Pillow",
                            "package_version": "5.2.0",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "scipy",
                            "package_version": "1.2.1",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "resampy",
                            "package_version": "0.2.1",
                            "restraint": "EXACT",
                        },
                        {
                            "package_name": "scikit-learn",
                            "package_version": "0.22.2",
                            "restraint": "EXACT",
                        },
                    ],
                }],
                "runtime": "tf1.13-python3.7-cpu",
                "model_source": "algos",
                "tunable": False,
            }))
        ```

        ### Import a model from a container image

        ```python
        import pulumi
        import json
        import pulumi_huaweicloud as huaweicloud

        config = pulumi.Config()
        swr_imag_path = config.require_object("swrImagPath")
        test = huaweicloud.modelarts.Model("test",
            name="demo_swr",
            version="0.0.1",
            description="This is a demo import from swr",
            source_location=swr_imag_path,
            model_type="Image",
            source_copy="true",
            install_types=[
                "real-time",
                "batch",
            ],
            model_docs=[{
                "doc_name": "guide",
                "doc_url": "https://doc.xxxx.yourdomain",
            }],
            initial_config=json.dumps({
                "protocol": "https",
                "port": 90,
                "model_type": "Image",
                "algorithm": "unknown_algorithm",
                "health": {
                    "check_method": "EXEC",
                    "command": "echo 1",
                    "period_seconds": "1",
                    "failure_threshold": "2",
                    "initial_delay_seconds": "1",
                },
            }))
        ```

        ## Import

        The modelarts model can be imported using id, e.g.

        bash

        ```sh
        $ pulumi import huaweicloud:ModelArts/model:Model test 635a2d50-0546-469d-b45d-0204b9ad4f14
        ```

        :param str resource_name: The name of the resource.
        :param ModelArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(ModelArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 dependencies: Optional[pulumi.Input[Sequence[pulumi.Input[Union['ModelDependencyArgs', 'ModelDependencyArgsDict']]]]] = None,
                 description: Optional[pulumi.Input[_builtins.str]] = None,
                 execution_code: Optional[pulumi.Input[_builtins.str]] = None,
                 initial_config: Optional[pulumi.Input[_builtins.str]] = None,
                 install_types: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 metrics: Optional[pulumi.Input[_builtins.str]] = None,
                 model_algorithm: Optional[pulumi.Input[_builtins.str]] = None,
                 model_docs: Optional[pulumi.Input[Sequence[pulumi.Input[Union['ModelModelDocArgs', 'ModelModelDocArgsDict']]]]] = None,
                 model_type: Optional[pulumi.Input[_builtins.str]] = None,
                 name: Optional[pulumi.Input[_builtins.str]] = None,
                 region: Optional[pulumi.Input[_builtins.str]] = None,
                 runtime: Optional[pulumi.Input[_builtins.str]] = None,
                 source_copy: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_id: Optional[pulumi.Input[_builtins.str]] = None,
                 source_job_version: Optional[pulumi.Input[_builtins.str]] = None,
                 source_location: Optional[pulumi.Input[_builtins.str]] = None,
                 source_type: Optional[pulumi.Input[_builtins.str]] = None,
                 template: Optional[pulumi.Input[Union['ModelTemplateArgs', 'ModelTemplateArgsDict']]] = None,
                 version: Optional[pulumi.Input[_builtins.str]] = None,
                 workspace_id: Optional[pulumi.Input[_builtins.str]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = ModelArgs.__new__(ModelArgs)

            __props__.__dict__["dependencies"] = dependencies
            __props__.__dict__["description"] = description
            __props__.__dict__["execution_code"] = execution_code
            __props__.__dict__["initial_config"] = initial_config
            __props__.__dict__["install_types"] = install_types
            __props__.__dict__["metrics"] = metrics
            __props__.__dict__["model_algorithm"] = model_algorithm
            __props__.__dict__["model_docs"] = model_docs
            if model_type is None and not opts.urn:
                raise TypeError("Missing required property 'model_type'")
            __props__.__dict__["model_type"] = model_type
            __props__.__dict__["name"] = name
            __props__.__dict__["region"] = region
            __props__.__dict__["runtime"] = runtime
            __props__.__dict__["source_copy"] = source_copy
            __props__.__dict__["source_job_id"] = source_job_id
            __props__.__dict__["source_job_version"] = source_job_version
            if source_location is None and not opts.urn:
                raise TypeError("Missing required property 'source_location'")
            __props__.__dict__["source_location"] = source_location
            __props__.__dict__["source_type"] = source_type
            __props__.__dict__["template"] = template
            if version is None and not opts.urn:
                raise TypeError("Missing required property 'version'")
            __props__.__dict__["version"] = version
            __props__.__dict__["workspace_id"] = workspace_id
            __props__.__dict__["image_address"] = None
            __props__.__dict__["market_flag"] = None
            __props__.__dict__["model_size"] = None
            __props__.__dict__["model_source"] = None
            __props__.__dict__["publishable_flag"] = None
            __props__.__dict__["schema_doc"] = None
            __props__.__dict__["status"] = None
            __props__.__dict__["tunable"] = None
        super(Model, __self__).__init__(
            'huaweicloud:ModelArts/model:Model',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            dependencies: Optional[pulumi.Input[Sequence[pulumi.Input[Union['ModelDependencyArgs', 'ModelDependencyArgsDict']]]]] = None,
            description: Optional[pulumi.Input[_builtins.str]] = None,
            execution_code: Optional[pulumi.Input[_builtins.str]] = None,
            image_address: Optional[pulumi.Input[_builtins.str]] = None,
            initial_config: Optional[pulumi.Input[_builtins.str]] = None,
            install_types: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
            market_flag: Optional[pulumi.Input[_builtins.bool]] = None,
            metrics: Optional[pulumi.Input[_builtins.str]] = None,
            model_algorithm: Optional[pulumi.Input[_builtins.str]] = None,
            model_docs: Optional[pulumi.Input[Sequence[pulumi.Input[Union['ModelModelDocArgs', 'ModelModelDocArgsDict']]]]] = None,
            model_size: Optional[pulumi.Input[_builtins.int]] = None,
            model_source: Optional[pulumi.Input[_builtins.str]] = None,
            model_type: Optional[pulumi.Input[_builtins.str]] = None,
            name: Optional[pulumi.Input[_builtins.str]] = None,
            publishable_flag: Optional[pulumi.Input[_builtins.bool]] = None,
            region: Optional[pulumi.Input[_builtins.str]] = None,
            runtime: Optional[pulumi.Input[_builtins.str]] = None,
            schema_doc: Optional[pulumi.Input[_builtins.str]] = None,
            source_copy: Optional[pulumi.Input[_builtins.str]] = None,
            source_job_id: Optional[pulumi.Input[_builtins.str]] = None,
            source_job_version: Optional[pulumi.Input[_builtins.str]] = None,
            source_location: Optional[pulumi.Input[_builtins.str]] = None,
            source_type: Optional[pulumi.Input[_builtins.str]] = None,
            status: Optional[pulumi.Input[_builtins.str]] = None,
            template: Optional[pulumi.Input[Union['ModelTemplateArgs', 'ModelTemplateArgsDict']]] = None,
            tunable: Optional[pulumi.Input[_builtins.bool]] = None,
            version: Optional[pulumi.Input[_builtins.str]] = None,
            workspace_id: Optional[pulumi.Input[_builtins.str]] = None) -> 'Model':
        """
        Get an existing Model resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[Sequence[pulumi.Input[Union['ModelDependencyArgs', 'ModelDependencyArgsDict']]]] dependencies: Package required for inference code and model.  
               If the package is read from the configuration file, this parameter can be left blank.
               The Dependency structure is documented below.
               
               Changing this parameter will create a new resource.
               
               <a name="ModelartsModel_ModelDocs"></a>
               The `ModelDocs` block supports:
        :param pulumi.Input[_builtins.str] description: Model description that consists of 1 to 100 characters.  
               The following special characters cannot be contained: **&!'"<>=**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] execution_code: OBS path for storing the execution code.  
               The name of the execution code file is consistently to be **customize_service.py**.
               The inference code file must be stored in the model directory.
               This parameter can be left blank. Then, the system will automatically identify the inference
               code in the model directory.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] image_address: Image path generated after model packaging.
        :param pulumi.Input[_builtins.str] initial_config: The model configuration file describes the model usage,
               computing framework, precision, inference code dependency package, and model API.
               The fields such as `model_algorithm`, `model_type`, `runtime`, `swr_location`, `metrics`, `apis`,
               `dependencies`, and `health` in the configuration file config.json.
               For details, see [Specifications for Writing the Model Configuration File](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0056.html)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] install_types: Deployment type. Only lowercase letters are supported.
               The value can be **real-time**, **edge**, or **batch**. Default value: [real-time, edge, batch].
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.bool] market_flag: Whether a model is subscribed from AI Gallery.
        :param pulumi.Input[_builtins.str] metrics: Model precision.  
               If the value is read from the configuration file, this parameter can be left blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] model_algorithm: Model algorithm.  
               If the algorithm is read from the configuration file, this parameter can be left blank.
               The value can be **predict_analysis**, **object_detection**, **image_classification**, or **unknown_algorithm**.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[Sequence[pulumi.Input[Union['ModelModelDocArgs', 'ModelModelDocArgsDict']]]] model_docs: List of model description documents. A maximum of three documents are supported.
               
               Changing this parameter will create a new resource.
               The ModelDocs structure is documented below.
        :param pulumi.Input[_builtins.int] model_size: Model size, in bytes.
        :param pulumi.Input[_builtins.str] model_source: Model source.  
               Value options are as follows:
               + **auto**: ExeML.
               + **algos**: built-in algorithm.
               + **custom**: custom model.
        :param pulumi.Input[_builtins.str] model_type: Model type.  
               It can be **TensorFlow**, **MXNet**, **Caffe**, **Spark_MLlib**, **Scikit_Learn**,
               **XGBoost**, **Image**, **PyTorch**, or **Template** read from the configuration file.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] name: Model name, which consists of 1 to 64 characters.  
               Only letters, digits, hyphens (-), and underscores (_) are allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.bool] publishable_flag: Whether a model is subscribed from AI Gallery.
        :param pulumi.Input[_builtins.str] region: Specifies the region in which to create the resource.
               If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] runtime: Model runtime environment.  
               Its possible values are determined based on model_type.
               For details, see [Supported AI engines and their runtime](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0003.html#section3)
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] schema_doc: Download address of the model schema file.
        :param pulumi.Input[_builtins.str] source_copy: Whether to enable image replication.  
               This parameter is valid only when `model_type` is set to **Image**.
               Value options are as follows:
               + **true**: Default value, indicating that image replication is enabled.
               After this function is enabled, AI applications cannot be rapidly created, and modifying
               or deleting an image in the SWR source directory will not affect service deployment.
               + **false**: Image replication is not enabled.
               After this function is disabled, AI applications can be rapidly created, but modifying
               or deleting an image in the SWR source directory will affect service deployment.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_id: ID of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_job_version: Version of the source training job.  
               If the model is generated from a training job, input this parameter for source tracing.
               If the model is imported from a third-party meta model, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_location: OBS path where the model is located or the SWR image location.  
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] source_type: Model source type, which can only be **auto**,
               indicating an ExeML model (model download is not allowed).
               If the model is obtained from a training job, leave this parameter blank.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] status: Model status.
        :param pulumi.Input[Union['ModelTemplateArgs', 'ModelTemplateArgsDict']] template: Configuration items in a template.  
               This parameter is mandatory when `model_type` is set to **Template**.
               
               Changing this parameter will create a new resource.
               The Template structure is documented below.
        :param pulumi.Input[_builtins.bool] tunable: Whether a model can be tuned.
        :param pulumi.Input[_builtins.str] version: Model version in the format of Digit.Digit.Digit.  
               Each digit is a one-digit or two-digit positive integer, but cannot start with 0.
               For example, 01.01.01 is not allowed.
               
               Changing this parameter will create a new resource.
        :param pulumi.Input[_builtins.str] workspace_id: Workspace ID, which defaults to 0.  
               
               Changing this parameter will create a new resource.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _ModelState.__new__(_ModelState)

        __props__.__dict__["dependencies"] = dependencies
        __props__.__dict__["description"] = description
        __props__.__dict__["execution_code"] = execution_code
        __props__.__dict__["image_address"] = image_address
        __props__.__dict__["initial_config"] = initial_config
        __props__.__dict__["install_types"] = install_types
        __props__.__dict__["market_flag"] = market_flag
        __props__.__dict__["metrics"] = metrics
        __props__.__dict__["model_algorithm"] = model_algorithm
        __props__.__dict__["model_docs"] = model_docs
        __props__.__dict__["model_size"] = model_size
        __props__.__dict__["model_source"] = model_source
        __props__.__dict__["model_type"] = model_type
        __props__.__dict__["name"] = name
        __props__.__dict__["publishable_flag"] = publishable_flag
        __props__.__dict__["region"] = region
        __props__.__dict__["runtime"] = runtime
        __props__.__dict__["schema_doc"] = schema_doc
        __props__.__dict__["source_copy"] = source_copy
        __props__.__dict__["source_job_id"] = source_job_id
        __props__.__dict__["source_job_version"] = source_job_version
        __props__.__dict__["source_location"] = source_location
        __props__.__dict__["source_type"] = source_type
        __props__.__dict__["status"] = status
        __props__.__dict__["template"] = template
        __props__.__dict__["tunable"] = tunable
        __props__.__dict__["version"] = version
        __props__.__dict__["workspace_id"] = workspace_id
        return Model(resource_name, opts=opts, __props__=__props__)

    @_builtins.property
    @pulumi.getter
    def dependencies(self) -> pulumi.Output[Sequence['outputs.ModelDependency']]:
        """
        Package required for inference code and model.  
        If the package is read from the configuration file, this parameter can be left blank.
        The Dependency structure is documented below.

        Changing this parameter will create a new resource.

        <a name="ModelartsModel_ModelDocs"></a>
        The `ModelDocs` block supports:
        """
        return pulumi.get(self, "dependencies")

    @_builtins.property
    @pulumi.getter
    def description(self) -> pulumi.Output[_builtins.str]:
        """
        Model description that consists of 1 to 100 characters.  
        The following special characters cannot be contained: **&!'"<>=**.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "description")

    @_builtins.property
    @pulumi.getter(name="executionCode")
    def execution_code(self) -> pulumi.Output[_builtins.str]:
        """
        OBS path for storing the execution code.  
        The name of the execution code file is consistently to be **customize_service.py**.
        The inference code file must be stored in the model directory.
        This parameter can be left blank. Then, the system will automatically identify the inference
        code in the model directory.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "execution_code")

    @_builtins.property
    @pulumi.getter(name="imageAddress")
    def image_address(self) -> pulumi.Output[_builtins.str]:
        """
        Image path generated after model packaging.
        """
        return pulumi.get(self, "image_address")

    @_builtins.property
    @pulumi.getter(name="initialConfig")
    def initial_config(self) -> pulumi.Output[_builtins.str]:
        """
        The model configuration file describes the model usage,
        computing framework, precision, inference code dependency package, and model API.
        The fields such as `model_algorithm`, `model_type`, `runtime`, `swr_location`, `metrics`, `apis`,
        `dependencies`, and `health` in the configuration file config.json.
        For details, see [Specifications for Writing the Model Configuration File](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0056.html)

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "initial_config")

    @_builtins.property
    @pulumi.getter(name="installTypes")
    def install_types(self) -> pulumi.Output[Sequence[_builtins.str]]:
        """
        Deployment type. Only lowercase letters are supported.
        The value can be **real-time**, **edge**, or **batch**. Default value: [real-time, edge, batch].

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "install_types")

    @_builtins.property
    @pulumi.getter(name="marketFlag")
    def market_flag(self) -> pulumi.Output[_builtins.bool]:
        """
        Whether a model is subscribed from AI Gallery.
        """
        return pulumi.get(self, "market_flag")

    @_builtins.property
    @pulumi.getter
    def metrics(self) -> pulumi.Output[_builtins.str]:
        """
        Model precision.  
        If the value is read from the configuration file, this parameter can be left blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "metrics")

    @_builtins.property
    @pulumi.getter(name="modelAlgorithm")
    def model_algorithm(self) -> pulumi.Output[_builtins.str]:
        """
        Model algorithm.  
        If the algorithm is read from the configuration file, this parameter can be left blank.
        The value can be **predict_analysis**, **object_detection**, **image_classification**, or **unknown_algorithm**.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "model_algorithm")

    @_builtins.property
    @pulumi.getter(name="modelDocs")
    def model_docs(self) -> pulumi.Output[Sequence['outputs.ModelModelDoc']]:
        """
        List of model description documents. A maximum of three documents are supported.

        Changing this parameter will create a new resource.
        The ModelDocs structure is documented below.
        """
        return pulumi.get(self, "model_docs")

    @_builtins.property
    @pulumi.getter(name="modelSize")
    def model_size(self) -> pulumi.Output[_builtins.int]:
        """
        Model size, in bytes.
        """
        return pulumi.get(self, "model_size")

    @_builtins.property
    @pulumi.getter(name="modelSource")
    def model_source(self) -> pulumi.Output[_builtins.str]:
        """
        Model source.  
        Value options are as follows:
        + **auto**: ExeML.
        + **algos**: built-in algorithm.
        + **custom**: custom model.
        """
        return pulumi.get(self, "model_source")

    @_builtins.property
    @pulumi.getter(name="modelType")
    def model_type(self) -> pulumi.Output[_builtins.str]:
        """
        Model type.  
        It can be **TensorFlow**, **MXNet**, **Caffe**, **Spark_MLlib**, **Scikit_Learn**,
        **XGBoost**, **Image**, **PyTorch**, or **Template** read from the configuration file.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "model_type")

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Output[_builtins.str]:
        """
        Model name, which consists of 1 to 64 characters.  
        Only letters, digits, hyphens (-), and underscores (_) are allowed.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "name")

    @_builtins.property
    @pulumi.getter(name="publishableFlag")
    def publishable_flag(self) -> pulumi.Output[_builtins.bool]:
        """
        Whether a model is subscribed from AI Gallery.
        """
        return pulumi.get(self, "publishable_flag")

    @_builtins.property
    @pulumi.getter
    def region(self) -> pulumi.Output[_builtins.str]:
        """
        Specifies the region in which to create the resource.
        If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "region")

    @_builtins.property
    @pulumi.getter
    def runtime(self) -> pulumi.Output[_builtins.str]:
        """
        Model runtime environment.  
        Its possible values are determined based on model_type.
        For details, see [Supported AI engines and their runtime](https://support.huaweicloud.com/intl/en-us/inference-modelarts/inference-modelarts-0003.html#section3)

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "runtime")

    @_builtins.property
    @pulumi.getter(name="schemaDoc")
    def schema_doc(self) -> pulumi.Output[_builtins.str]:
        """
        Download address of the model schema file.
        """
        return pulumi.get(self, "schema_doc")

    @_builtins.property
    @pulumi.getter(name="sourceCopy")
    def source_copy(self) -> pulumi.Output[_builtins.str]:
        """
        Whether to enable image replication.  
        This parameter is valid only when `model_type` is set to **Image**.
        Value options are as follows:
        + **true**: Default value, indicating that image replication is enabled.
        After this function is enabled, AI applications cannot be rapidly created, and modifying
        or deleting an image in the SWR source directory will not affect service deployment.
        + **false**: Image replication is not enabled.
        After this function is disabled, AI applications can be rapidly created, but modifying
        or deleting an image in the SWR source directory will affect service deployment.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_copy")

    @_builtins.property
    @pulumi.getter(name="sourceJobId")
    def source_job_id(self) -> pulumi.Output[_builtins.str]:
        """
        ID of the source training job.  
        If the model is generated from a training job, input this parameter for source tracing.
        If the model is imported from a third-party meta model, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_job_id")

    @_builtins.property
    @pulumi.getter(name="sourceJobVersion")
    def source_job_version(self) -> pulumi.Output[_builtins.str]:
        """
        Version of the source training job.  
        If the model is generated from a training job, input this parameter for source tracing.
        If the model is imported from a third-party meta model, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_job_version")

    @_builtins.property
    @pulumi.getter(name="sourceLocation")
    def source_location(self) -> pulumi.Output[_builtins.str]:
        """
        OBS path where the model is located or the SWR image location.  

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_location")

    @_builtins.property
    @pulumi.getter(name="sourceType")
    def source_type(self) -> pulumi.Output[_builtins.str]:
        """
        Model source type, which can only be **auto**,
        indicating an ExeML model (model download is not allowed).
        If the model is obtained from a training job, leave this parameter blank.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "source_type")

    @_builtins.property
    @pulumi.getter
    def status(self) -> pulumi.Output[_builtins.str]:
        """
        Model status.
        """
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter
    def template(self) -> pulumi.Output['outputs.ModelTemplate']:
        """
        Configuration items in a template.  
        This parameter is mandatory when `model_type` is set to **Template**.

        Changing this parameter will create a new resource.
        The Template structure is documented below.
        """
        return pulumi.get(self, "template")

    @_builtins.property
    @pulumi.getter
    def tunable(self) -> pulumi.Output[_builtins.bool]:
        """
        Whether a model can be tuned.
        """
        return pulumi.get(self, "tunable")

    @_builtins.property
    @pulumi.getter
    def version(self) -> pulumi.Output[_builtins.str]:
        """
        Model version in the format of Digit.Digit.Digit.  
        Each digit is a one-digit or two-digit positive integer, but cannot start with 0.
        For example, 01.01.01 is not allowed.

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "version")

    @_builtins.property
    @pulumi.getter(name="workspaceId")
    def workspace_id(self) -> pulumi.Output[_builtins.str]:
        """
        Workspace ID, which defaults to 0.  

        Changing this parameter will create a new resource.
        """
        return pulumi.get(self, "workspace_id")

